[{"categories":[],"content":"Mysql数据库 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:0:0","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"逻辑架构 MySQL基架大致包括如下几大模块组件: MySQL向外提供的交互接口（Connectors）: ​ Connectors组件，是MySQL向外提供的交互组件，如java,.net,php等语言可以通过该组件来操作SQL语句，实现与SQL的交互。 管理服务组件和工具组件(Management Service \u0026 Utilities): ​ 提供对MySQL的集成管理，如备份(Backup),恢复(Recovery),安全管理(Security)等 连接池组件(Connection Pool): ​ 负责监听对客户端向MySQL Server端的各种请求，接收请求，转发请求到目标模块。每个成功连接MySQL Server的客户请求都会被创建或分配一个线程，该线程负责客户端与MySQL Server端的通信，接收客户端发送的命令，传递服务端的结果信息等。 SQL接口组件(SQL Interface): ​ 接收用户SQL命令，如DML,DDL和存储过程等，并将最终结果返回给用户。 查询分析器组件(Parser): ​ 首先分析SQL命令语法的合法性，并尝试将SQL命令分解成数据结构，若分解失败，则提示SQL语句不合理。 优化器组件（Optimizer）: ​ 对SQL命令按照标准流程进行优化分析。 缓存主件（Caches \u0026 Buffers）: ​ 缓存和缓冲组件 MySQL存储引擎: ​ 关系型数据库的存储是以表的形式进行的，对于表的创建，数据的存储，检索，更新等都是由MySQL存储引擎完成的 物理文件（File System） ​ 实际存储MySQL 数据库文件和一些日志文件等的系统。 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:1:0","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"MySQL 执行查询的过程 客户端通过 TCP 连接发送连接请求到 MySQL 连接器，连接器会对该请求进行权限验证及连接资源分配 查缓存。（当判断缓存是否命中时，MySQL 不会进行解析查询语句，而是直接使用 SQL 语句和客户端发送过来的其他原始信息。所以，任何字符上的不同，例如空格、注解等都会导致缓存的不命中。） 语法分析。 如何把语句给到预处理器(分析器)，检查数据表和数据列是否存在，解析别名看是否存在歧义。 优化器。是否使用索引，生成执行计划。 交给执行器，将数据保存到结果集中，同时会逐步将数据缓存到查询缓存中，最终将结果集返回给客户端。 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:1:1","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"MySQL存储引擎 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:1:2","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"InnoDB存储引擎 ​ MySQL5.5版本之后，MySQL的默认内置存储引擎已经是InnoDB了. 主要特点: 支持ACID事务。默认的事务隔离级别为可重复度，通过MVCC（并发版本控制）来实现的。 使用的锁粒度为行级锁，可以支持更高的并发； 支持外键 在InnoDB中存在着缓冲管理，通过缓冲池，将索引和数据全部缓存起来，加快查询的速度； 主键索引采用聚集索引(索引的数据域存储数据文件本身),二级索引的数据域存储主键的值;因此从二级索引查找数据，需要先通过二级索引找到主键值，再访问聚集索引；最好使用自增主键，防止插入数据时，为维持B+树结构，文件的大调整。 InnoDB四大特性 插入缓存（insert buffer) ​ 索引数据存储在磁盘上，主键索引由于天然自增，无须磁盘的随机 I/O，只需不断追加即可。但普通索引大概率无序，默认情况下需要进行随机磁盘 I/O 操作，效率极差.为了解决普通索引插入效率低下的问题，InnoDB 存储引擎引入 Insert Buffer 的概念. 原理: 对于普通索引（非聚集索引）不是直接插入到索引页中，而是先判断插入的非聚集索引页是否在缓存池中，如果在直接插入，否则先放入 Insert buffer 对象中，然后以一定频率和辅助索引页子节点进行合并操作，此时通常能将多个插入合并到一个操作中，提高插入性能 使用前提: 非聚集索引, 且索引不唯一 ​ 因为如果要保证索引唯一, 每次操作还得去判断当前索引值是否已存在，而判断又涉及到磁盘随机 I/O，从而发挥不出插入缓存的优势. 二次写(double write) ​ InnoDB 索引页一般 16KB 大小，而操作系统写文件以 4KB 为单位，这就导致同一页需要分四块分别写入。此时就存在写完一块系统崩溃或者断电等特殊情况，此时就导致写入数据不完整的问题. ​ 二次写就是为了解决该问题，double write 分为两部分，一部分 doublewrite buffer，其大小 2MB，另一部分是磁盘上共享表空间中连续的 128 个页，也是2MB 原理: 先将脏数据写入 doublewrite buffer，doublewrite buffer 每次 1MB 写入共享表空间的磁盘上，完成以上两步后调用 fsync 函数，将数据同步到各个表空间. ​ 如果操作系统在将页写入磁盘的过程中崩溃，InnoDB 重启发现页数据损坏后，可以从共享表的 doublewrite 中找到副本，用于数据恢复. 自适应哈希索引(ahi) ​ InnoDB 虽然主要使用 B+ 树作为索引结构，但在某些特殊场景下用到哈希索引。InnoDB 会监控对表上索引的查找，如果发现某个索引频繁被访问，则建立哈希索引。InnoDB 会自动根据访问的频率和模式来为某些页建立哈希索引. 预读(read ahead) ​ 请求一页的数据时，可以把后面几页的数据也一起返回，放到数据缓冲池中，这样如果下次刚好需要下一页的数据，就不再需要到磁盘读取 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:1:3","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"MyISAM存储引擎 ​ 一个MyISAM表三个文件: 表结构.frm、索引.myi、数据 .myd, ​ 主要特点为： 不支持事务 不支持外键;如果强行增加外键,不会提示错误,只是外键不其作用; 对数据的查询缓存只会缓存索引，不会像InnoDB一样缓存数据，而且是利用操作系统本身的缓存； 默认的锁粒度为表级锁，所以并发度很差，加锁快，锁冲突较少，所以不太容易发生死锁； 采用非聚集索引,索引文件的数据存储指向数据文件的指针; 存储表的总行数, count(*) 速度快 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:1:4","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"MyISAM 和InnoDB区别 InnoDB 支持事务、外键，MyISAM 都不支持 InnoDB 是聚集索引，数据文件是和索引绑在一起的，必须要有主键，通过主键索引效率很高；MyISAM 是非聚集索引，数据文件是分离的，索引保存的是数据文件的指针，主键索引和辅助索引是独立的。 Innodb 不支持全文索引，而 MyISAM 支持全文索引，查询效率上 MyISAM 要高； InnoDB 不保存表的具体行数，MyISAM 用一个变量保存了整个表的行数。(select count(*)) MyISAM 采用表级锁(table-level locking)；InnoDB 支持行级锁(row-level locking)和表级锁,默认为行级锁。所以InnoDB相对于MyISAM来说，更容易发生死锁，锁冲突的概率更大，而且上锁的开销也更大，因为需要为每一行加锁； InnoDB比MyISAM支持更高的并发 InnoDB数据与索引一起保存.ibd，MyISAM表结构.frm 索引.myi 数据.myd ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:1:5","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"引擎的选择(使用的场景) MyISAM：以读写插入为主的应用程序，比如博客系统、新闻门户网站。 Innodb：更新（删除）操作频率也高，或者要保证数据的完整性；并发量高，支持事务和外键。 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:1:6","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"索引 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:2:0","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"什么是索引 ​ 索引是一种特殊的文件(InnoDB数据表上的索引是表空间的一个组成部分)，它们包含着对数据表里所有记录的引用指针。索引是一种数据结构。数据库索引，是数据库管理系统中一个排序的数据结构，以协助快速查询、更新数据 库表中数据。索引的实现通常使用 B树及其变种 B+树。 ​ 更通俗的说，索引就相当于目录。为了方便查找书中的内容，通过对内容建立索引形成目录。索引是一个文件，它是要占据物理空间的。 优点 可以大大加快数据的检索速度，这也是创建索引的最主要的原因。 通过使用索引，可以在查询的过程中，使用优化隐藏器，提高系统的性能。 缺点 时间方面:创建索引和维护索引要耗费时间，具体地，当对表中的数据进行增加、删除和修改的时候，索引也 要动态的维护，会降低增/改/删的执行效率; 空间方面:索引需要占物理空间。 索引类型 主键索引(聚集索引) 数据列不允许重复，不允许为 NULL，一个表只能有一个主键。 唯一索引 数据列不允许重复，允许为 NULL值，一个表允许多个列创建唯一索引。 普通索引 基本的索引类型，没有唯一性的限制，允许为 NULL值。 全文索引 是目前搜索引擎使用的一种关键技术。 联合索引 hash索引:(InnoDB和myIsam都不支持hash索引) ​ 适用于快速找到等值比较查询的数据, 但是不适合范围查询和排序 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:2:1","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"数据结构: B+树 ​ 在数据库中，B+Tree的高度一般都在2~4层。mysql的innoDB存储引擎在设计时是将根节点常驻内存的，也就是说查找某一键值的行记录时最多只需要1~3次磁盘I/O操作。 B+树的非叶子节点不保存关键字记录的指针,只进行数据索引，这样使得B+树每个非叶子节点所能保存的关键字大大增加 B+树叶子节点保存了父节点的所有关键字记录的指针，所有数据地址必须要到叶子节点才能获取到。所以每次数据查询的次数都一样； 为什么使用B+树,而不是B树 B+数的层级更少: 相较于B树B+每个非叶子节点存储的关键字数更多，树的层级更少所以查询数据更快； B+树查询速度更稳定：B+所有关键字数据地址都存在叶子节点上，所以每次查找的次数都相同所以查询速度要比B树更稳定; B+树天然具备排序功能：B+树所有的叶子节点数据构成了一个有序链表，在查询大小区间的数据时候更方便，数据紧密性很高，缓存的命中率也会比B树高。 B+树全节点遍历更快：B+树遍历整棵树只需要遍历所有的叶子节点即可，而不需要像B树一样需要对每一层进行遍历，这有利于数据库做全表扫描。 B树相对于B+树的优点是，如果经常访问的数据离根节点很近，而B树的非叶子节点本身存有关键字其数据的地址，所以这种数据检索的时候会要比B+树快。 B+树和红黑树对比 B+数查询次数更少: 数高更低 磁盘预读: 为了减少IO操作,往往不严格按需读取,而是预读.B+树叶子结点存储相临，读取会快一些。 存储更多索引结点: B+树只在叶子结点储存数据，非叶子结点存索引，而一个结点就是磁盘一个内存页，内存页大小固定，那么相比B树这些可以存更多的索引结点，出度更大，树高矮，查询次数少，磁盘IO少。 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:2:2","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"使用索引一定会提高性能吗? ​ 通常，通过索引查询数据比全表扫描要快。但是我们也必须注意到它的代价。 ​ 索引需要空间来存储，也需要定期维护，每当有记录在表中增减或索引列被修改时，索引本身也会被修改。这意味着每条记录的 INSERT，DELETE， UPDATE 将为此多付出4，5 次的磁盘 I/O。因为索引需要额外的存储空间和处理，那些不必要的索引反而会使查询 反应时间变慢。 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:2:3","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"聚簇索引和非聚簇索引 聚簇索引 ​ 将数据存储与索引放到了同一个文件中，找到索引也就找到了数据(即索引的叶子结点存储真正的数据) 特点 聚簇索引具有唯一性: 由于聚簇索引是将数据跟索引结构放到一块，因此一个表仅有一个聚簇索引。 表中行的物理顺序和索引中行的物理顺序是相同的: 在创建任何非聚簇索引之前创建聚簇索引，这是因为聚簇索引改变了表中行的物理顺序，数据行 按照一定的顺序排列，并且自动维护这个顺序； 聚簇索引默认是主键; 如果表中没有定义主键，InnoDB 会选择一个唯一且非空的索引代替。 MyISAM使用的是非聚簇索引 优点 索引和数据存储在一起, 同一页会有多刚数据, 可以一次加载一页到缓存中, 节省再次访问和范围访问的IO次数, 提高效率 建议使用自增ID作为主键: ​ 当使用主键为聚簇索引时，主键最好不要使用uuid，因为uuid的值太过离散，不适合排序且可能出线新增加记录的uuid，会插入在索引树中间的位置，导致索引树调整复杂度变大，消耗更多的时间和资源。 ​ 聚簇索引的数据的物理存放顺序最好与索引顺序是一致的, 这样能够一页一页写入物理数据, 索引结构相对紧凑，磁盘碎片少，效率也高. 非聚簇索引 将数据存储与索引分开，索引结构的叶子节点指向了数据的对应行，myisam通过 key_buffer 把索引先缓存到内存中，当需要访问数据时(通过索引访问数据)，在内存中直接搜索索引，然 后通过索引找到磁盘相应数据，这也就是为什么索引不在 key buffer 命中时，速度慢的原因。 联合索引 ​ 当有多个查询条件时，我们推荐使用复合索引。索引的组合使用（索引合并）效率是低于复合索引的。 ​ 比如：我们经常按照 A列 B列 C列进行查询时，通常的做法是建立一个由三个列共同组成的复合索引而不是对每一个列建立普通索引。 联合索引的优点: 减少开销: 建一个联合索引(Gid,Cid,SId)，实际相当于建了(Gid)、(Gid,Cid)、(Gid,Cid,SId)三个索引。每多一个索引，都会增加写操作的开销和磁盘空间的开销。对于大量数据的表，使用联合索引会大大的减少开销！ 覆盖索引: 对联合索引(Gid,Cid,SId), 对于查询这三个字段的sql可以通过遍历索引就能得到所需全部数据, 无需回表; 减少io操作. 效率高: 索引列越多, 通过索引筛选出的数据越少, 因而需要回表的数据就少. 缺点: 在增删改数据的同时, 需要维护索引,这是很花时间的,而且索引所需的磁盘空间不少. 注意事项 最左前缀匹配原则: mysql以最左边的为起点任何连续的索引都能匹配上。同时遇到范围查询(\u003e、\u003c、between、like)就会停止匹配。 ​ 如b = 2 如果建立(a,b)顺序的索引，是匹配不到(a,b)索引的；但是如果查询条件是a = 1 and b = 2或者a=1(又或者是b = 2 and b = 1)就可以，因为优化器会自动调整a,b的顺序。再比如a = 1 and b = 2 and c \u003e 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，因为c字段是一个范围查询，它之后的字段会停止匹配 如果我们创建了(a, b,c)的复合索引，那么其实相当于创建了(a,b,c)、(a,b)、(a)三个索引，这被称为最佳左前缀特性;根据最左匹配原则, 写sql时需要将范围查询写在最后. ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:2:4","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"有索引以后查询的流程 从索引里自上而下查询 走到叶子节点查询到id 根据id去聚簇索引中查找真正的数据，这个过程叫做回表 如果你要的数据索引都有了不需要回表，就叫索引覆盖。 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:2:5","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"哪些情况适合建索引 频繁作为where条件语句查询的字段 关联字段需要建立索引，例如外键字段等 排序字段可以建立索引 分组字段可以建立索引，因为分组的前提是排序 统计字段可以建立索引，例如count(),max() ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:2:6","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"哪些情况不适合建索引 频繁更新的字段不适合建立索引 where条件中用不到的字段不适合建立索引 表数据可以确定比较少的不需要建索引 数据重复且发布比较均匀的的字段不适合建索引（唯一性太差的字段不适合建立索引），例如性别，真假值. 参与列计算的列不适合建索引，索引会失效 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:2:7","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"索引不会包含NULL值的列 单列索引无法储null值，复合索引无法储全为null的值。 查询时，采用is null条件时，不能利用到索引，只能全表扫描。 ​ 原因: 索引是有序的。NULL值进入索引时，无法确定其应该放在哪里。 如果需要把空值存入索引，方法有二：其一，把NULL值转为一个特定的值，在WHERE中检索时，用该特定值查找。其二，建立一个复合索引. create index ind_a on table(col1,1); 通过在复合索引中指定一个非空常量值，而使构成索引的列的组合中，不可能出现全空值。 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:2:8","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"排序的索引问题 ​ mysql查询只使用一个索引，因此如果where子句中已经使用了索引的话，那么order by中的列是不会使用索引的。因此数据库默认排序可以符合要求的情况下不要使用排序操作；尽量不要包含多个列的排序，如果需要最好给这些列创建复合索引。 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:2:9","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"Mysql索引失效的几种情况 如果条件中有or，即使其中有条件带索引也不会使用(这也是为什么尽量少用or的原因)要想使用or，又想让索引生效，只能将or条件中的每个列都加上索引 复合索引不满足最左原则就不能使用索引 like查询以%开头 如果mysql估计使用全表扫描要比使用索引快,则不使用索引 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:2:10","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"Explain 关键字 explain关键字可以模拟MySQL优化器执行SQL语句，可以很好的分析SQL语句或表结构的性能瓶颈。 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:2:11","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"事务 MySQL 中只有 Innodb 引擎才支持事务; 事务是一个不可分割的数据库操作序列，也是数据库并发控制的基本单位，其执行的结果必须使数据库从一种一致性状态变到另一种一致性状态。事务是逻辑上的一组操作，要么都执行，要么都不执行。 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:3:0","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"事务的实现原理 事务是基于重做日志文件(redo log)和回滚日志(undo log)实现的。 每提交一个事务必须先将该事务的所有日志写入到重做日志文件进行持久化，数据库就可以通过重做日志来保证事务的原子性和持久性。 每当有修改事务时，还会产生 undo log，如果需要回滚，则根据 undo log 找到回滚的数据位置,恢复成原来的数据。undo log 主要实现数据库的一致性。 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:3:1","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"事务的四大特性(ACID) 原子性(Atomicity) ​ 一个事务（transaction）中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。 一致性（Consistency） ​ 事务开始之前和事务结束以后，数据库的完整性没有被破坏。 即数据间的行为保持一致(比如：A向B转账，不可能A扣了钱，B却没有收到) 隔离性（Isolation） ​ 数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致; 事务隔离分为不同级别，包括读未提交（Read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（Serializable）。 持久性（Durability） ​ 事务处理结束后，对数据的修改就是永久的;即落入磁盘 ​ ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:3:2","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"事务的隔离级别 隔离级别\\解决问题 脏读 不可重复读 幻读 读未提交(Read Uncommitted) × × × 读已提交(Read Committed) √ × × 可重复读(Repeatable Read) √ √ × 串行化(Serializable) √ √ √ 读未提交(Read Uncommitted) 脏读问题: 事务A和事物B，事务A未提交的数据，事务B可以读取到;这里读取到的数据叫做“脏数据”，叫脏读 事务读不阻塞其他事务读和写，事务写阻塞其他事务写但不阻塞读。可以通过写操作加“持续-X锁”实现 读已提交(Read Committed) 不可重复读问题: 一个事务读到另一个事务修改后并提交的数据（update）。在同一个事务中，对于同一组数据读取到的结果不一致.针对update和delete 事务读不会阻塞其他事务读和写，事务写会阻塞其他事务读和写。可以通过写操作加**“持续-X”锁**，**读操作加“临时-S锁”实现**。 可重复读(Repeatable Read) 幻读问题: A事务在本次事务中对未操作的数据进行多次查询，发现第一次没有，第二次出现了就像幻觉一样。或者第一次有而第二次没有。针对delete和insert。 事务读会阻塞其他事务事务写但不阻塞读，事务写会阻塞其他事务读和写。可以通过写操作加“持续-X”锁，读操作加“持续-S锁”实现。 串行化(Serializable) 事务A和事务B，事务A在操作数据库时，事务B只能排队等待 这种隔离级别很少使用，吞吐量太低，用户体验差 这种级别可以避免“幻像读”，每一次读取的都是数据库中真实存在数据，事务A与事务B串行，而不并发。 使用“表级锁”。 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:3:3","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"锁机制 表锁的特点就是开销小、加锁快，不会出现死锁。锁粒度大，发生锁冲突的概率小，并发度相对低。 行锁的特点就是开销大、加锁慢，会出现死锁。锁粒度小，发生锁冲突的概率高，并发度搞。 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:4:0","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"行锁的种类 记录锁（Record Lock） 不加索引, 锁住的是表; 记录锁是加在索引上的,这是标准的行级锁 间隙锁（GAP Lock） ​ 在RR这个级别下，为了避免幻读，引入了间隙锁，他锁定的是记录范围，不包含记录本身，也就是不允许在范围内插入数据。 ​ 唯一索引 等值判断只会产生记录锁;范围查询会产生间隙锁;普通索引等值判断会产生间隙锁 临键锁(next-key Lock) ​ 临键锁，是记录锁与间隙锁的组合，它的封锁范围，既包含索引记录，又包含索引区间。 注：临键锁的主要目的，也是为了避免幻读(Phantom Read)。如果把事务的隔离级别降级为RC，临键锁则也会失效。 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:4:1","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"表锁 ​ 对于InnoDB表，在绝大部分情况下都应该使用行级锁，因为事务和行锁往往是我们之所以选择InnoDB表的理由。 使用表级锁的情况 事务需要更新大部分或全部数据，表又比较大，如果使用默认的行锁，不仅这个事务执行效率低，而且可能造成其他事务长时间锁等待和锁冲突，这种情况下可以考虑使用表锁来提高该事务的执行速度。 事务涉及多个表，比较复杂，很可能引起死锁，造成大量事务回滚。这种情况也可以考虑一次性锁定事务涉及的表，从而避免死锁、减少数据库因事务回滚带来的开销。 使用表锁的注意事项 表锁不是由InnoDB存储引擎层管理的，而是由其上一层ＭySQL Server负责的，仅当autocommit=0、innodb_table_lock=1（默认设置）时，InnoDB层才能知道MySQL加的表锁, ＭySQL Server才能感知InnoDB加的行锁，这种情况下，InnoDB才能自动识别涉及表级锁的死锁； 在用LOCAK TABLES对InnoDB锁时要注意，要将AUTOCOMMIT设为0，否则ＭySQL不会给表加锁；事务结束前，不要用UNLOCAK TABLES释放表锁，因为UNLOCK TABLES会隐含地提交事务；COMMIT或ROLLBACK不能释放用LOCAK TABLES加的表级锁，必须用UNLOCK TABLES释放表锁 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:4:2","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"InnoDB的锁类型 ​ InnoDB的锁类型主要有读锁(共享锁)、写锁(排他锁)、意向锁和MDL锁。 读锁 ​ 读锁（共享锁，shared lock）简称S锁。一个事务获取了一个数据行的读锁，其他事务能获得该行对应的读锁但不能获得写锁 应用情况: 自动提交模式下的select查询语句，不需加任何锁,直接返回查询结果，这就是一致性非锁定读。 通过select…. lock in share mode被读取的行记录或行记录的范围上加一个读锁,让其他事务可以读,但是要想申请加写锁,那就会被阻塞。 写锁 ​ 写锁，也叫排他锁，或者叫独占锁，简称x锁。一个事务获取了一个数据行的写锁，其他事务就不能再获取该行的其他锁与锁优先级最高。 应用情况: 1. 一些DML语句的操作都会对行记录加写锁。2 . 比较特殊的就是select for update，它会对读取的行记录上加一个写锁，那么其他任何事务不能对被锁定的行上加任何锁了，要不然会被阻塞。 MDL ​ MDL锁用于保证表中元数据的信息。在会话A中，表开启了查询事务后，会自动获得一个MDL锁，会话B就不可以执行任何DDL语句，不能执行为表中添加字段的操作，会用MDL锁来保证数据之间的一致性。 意向锁 ​ mysql的innodb引擎中，意向锁是表级锁，意向锁有两种: 意向共享锁（IS） 是指在给一个数据行加共享锁前必须获取该表的意向共享锁 意向排它锁（IX） 是指在给一个数据行加排他锁前必须获取该表的意向排他锁 意向锁和MDL锁都是为了防止在事务进行中，执行DDL语句导致数据不一致。 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:4:3","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"乐观锁和悲观锁 ​ 这是从逻辑的角度进行分类,并不是真正的的锁结构 乐观锁 ​ 乐观锁大多是基于数据版本记录机制实现，一般是给数据库表增加一个\"version\"字段。读取数据时，将此版本号一同读出，之后更新时，对此版本号加一。此时将提交数据的版本数据与数据库表对应记录的当前版本信息进行比对，如果提交的数据版本号大于数据库表当前版本号，则予以更新，否则认为是过期数据。 悲观锁 悲观锁依靠数据库提供的锁机制实现。MySQL中的共享锁和排它锁都是悲观锁。数据库的增删改操作默认都会加排他锁，而查询不会加任何锁。此处不赘述。 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:4:4","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"锁等待和死锁 锁等待 ​ 锁等待是指一个事务过程中产生的锁，其他事务需要等待上一个事务释放它的锁，才能占用该资源。如果该事务一直不释放，就需要持续等待下去，直到超过了锁等待时间，会报一个等待超时的错误。 ​ MysQL中通过innodb_lock_wait_timeout参数控制所等待的超时时间。 死锁 死锁的实例: 两行记录，至少两个事务 事务A 操作 第n行数据，并加锁 update teacher set name = 'a' where id = 1; 事务B 操作 第m行数据，并加锁 update teacher set name = 'b' where id = 2; 事务A 操作 第m行数据 update teacher set name = 'c' where id = 2; 事务B 操作 第n行数据 update teacher set name = 'd' where id = 1; 形成死锁 Deadlock found when trying to get lock; try restarting transaction InnoDB引擎可以自动检测死锁并回滚该事务 如何避免死锁 如果不同的程序会并发处理同一个表，或者涉及多行记录，尽量约定使用相同顺序访问表，可以大大减少死锁的发生。 业务中尽量采用小事务，避免使用大事务，要即使提交和回滚事务，可减少死锁产生的概率。 同一个事务中尽量做到一次锁定所需要的所有资源，减少死锁发生的概率。 对于非常容易发生死锁的业务，可以尝试使用升级锁的力度，该用表锁减少死锁的发生。 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:4:5","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"MVCC 多版本并发控制 ​ MVCC，全称Multi-Version Concurrency Control，即多版本并发控制。MVCC是一种并发控制的方法，一般在数据库管理系统中，实现对数据库的并发访问，在编程语言中实现事务。 ​ **MVCC**在InnoDB中的实现主要是为了提高数据库并发性能，用更好的方式去处理读-写冲突，做到即使有读写冲突时，也能做到不加锁，非阻塞并发读 当前读和快照读 当前读: 它读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行加锁. 共享锁和排他锁都是当前读 快照读: 快照读是基于提高并发性能的考虑，快照读的实现是基于多版本并发控制，即MVCC. 既然是基于多版本，即快照读可能读到的并不一定是数据的最新版本，而有可能是之前的历史版本 像不加锁的select操作就是快照读，即不加锁的非阻塞读；快照读的前提是隔离级别不是串行级别，串行级别下的快照读会退化成当前读； MVCC解决的问题 多版本并发控制（MVCC）是一种用来解决读-写冲突的无锁并发控制, 也就是为事务分配单向增长的时间戳，为每个修改保存一个版本，版本与事务时间戳关联，读操作只读该事务开始前的数据库的快照。 在并发读写数据库时，可以做到在读操作时不用阻塞写操作，写操作也不用阻塞读操作，提高了数据库并发读写的性能. 同时还可以解决脏读，幻读，不可重复读等事务隔离问题，但不能解决更新丢失问题(多次写导致上次更新丢失) MVCC实现原理 ​ 它的实现原理主要是依赖记录中的 3个隐式字段，undo日志 ，Read View 来实现的 隐式字段 ​ 每行记录除了自定义的字段外, 还有数据库隐式定义的 DB_TRX_ID,DB_ROLL_PTR,DB_ROW_ID等字段 DB_TRX_ID 6Byte; 最近修改(修改/插入)事务ID：记录创建这条记录/最后一次修改该记录的事务ID DB_ROLL_PTR 7byte; 回滚指针，指向这条记录的上一个版本（存储于rollback segment里） DB_ROW_ID 6byte; 隐含的自增ID（隐藏主键），如果数据表没有主键，InnoDB会自动以DB_ROW_ID产生一个聚簇索引 实际还有一个删除flag隐藏字段, 既记录被更新或删除并不代表真的删除，而是删除flag变了 undo日志 insert undo log 代表事务在insert新记录时产生的undo log, 只在事务回滚时需要，当事务提交后，该类型的undo日志就没用了，它占用的Undo Log Segment也会被系统回收(也就是该undo日志占用的Undo页面链表要么被重用，要么被释 放)。 update undo log 事务在进行update或delete时产生的undo log; 不仅在事务回滚时需要，在快照读时也需要；所以不能随便删除，只有在快速读或事务回滚不涉及该日志时，对应的日志才会被purge线程统一清除 purge线程 为了实现InnoDB的MVCC机制，更新或者删除操作都只是设置一下老记录的deleted_bit，并不真正将过时的记录删除。 为了节省磁盘空间，InnoDB有专门的purge线程来清理deleted_bit为true的记录。 对MVCC有帮助的实质是update undo log，undo log实际上就是存旧记录链，它的执行流程如下： 比如persion表有一条记录，记录如下，name为Jerry, age为24岁，隐式主键是1，事务ID和回滚指针，我们假设为NULL 事务1对该记录的name做出了修改，改为Tom 先对这行数据加排他锁 然后把该行数据拷贝到undo log中，作为旧记录，即在undo log中有当前行的拷贝副本 拷贝完毕后，修改该行name为Tom，并且修改隐藏字段的事务ID为当前事务1的ID, 我们默认从1开始，之后递增，回滚指针指向拷贝到undo log的副本记录，既表示我的上一个版本就是它 事务提交后，释放锁 事务2修改person表的同一个记录，将age修改为30岁 获取排他锁、加锁 把该行数据拷贝到undo log中，作为旧记录，发现该行记录已经有undo log了，那么最新的旧数据作为链表的表头，插在该行记录的undo log最前面 修改该行age为30岁，并且修改隐藏字段的事务ID为当前事务2的ID, 那就是2，回滚指针指向刚刚拷贝到undo log的副本记录 事务提交，释放锁 Read View (读视图) 设计思路: 1. READ UNCOMMITTED 隔离级别的事务，由于可以读到未提交事务修改过的记录，所以直接读取记录 的最新版本就好了。 1. SERIALIZABLE 隔离级别的事务，InnoDB规定使用加锁的方式来访问记录。 1. READ COMMITTED 和 REPEATABLE READ 隔离级别的事务，都必须保证读到已经提交了的事务修改 过的记录。 这是ReadView要解决的主要问题。 ​ Read View就是事务进行快照读操作的时候生产的读视图(Read View)，在该事务执行的快照读的那一刻，会生成数据库系统当前的一个快照，记录并维护系统当前活跃事务的ID trx_ids，当前有哪些事务正在执行，且还没有提交，这些事务的 id 就会存在这里； up_limit_id，是指 m_ids 里最小的值； low_limit_id，是指下一个要生成的事务 id。下一个要生成的事务 id 肯定比现在所有事务的 id 都大； creator_trx_id：表示生成该ReadView的事务的事务id 只有在对表中的记录做改动时（执行INSERT、DELETE、UPDATE这些语句时）才会为事务分配事务id，否则在一个只读事务中的事务id值都默认为0。 ReadView的规则 如果被访问版本的trx_id属性值与ReadView中的 creator_trx_id 值相同，意味着当前事务在访问它自己修改过的记录，所以该版本可以被当前事务访问。(这里的trx_id为每一行数据的trx_id) 如果被访问版本的trx_id属性值小于ReadView中的 up_limit_id 值，表明生成该版本的事务在当前事务生成ReadView前已经提交，所以该版本可以被当前事务访问。 如果被访问版本的trx_id属性值大于或等于ReadView中的 low_limit_id 值，表明生成该版本的事务在当前事务生成ReadView后才开启，所以该版本不可以被当前事务访问。 如果被访问版本的trx_id属性值在ReadView的 up_limit_id 和 low_limit_id 之间，那就需要判 断一下trx_id属性值是不是在 trx_ids 列表中。 如果在，说明创建ReadView时生成该版本的事务还是活跃的，该版本不可以被访问。 如果不在，说明创建ReadView时生成该版本的事务已经被提交，该版本可以被访问 在RC隔离级别下，是每个快照读都会生成并获取最新的Read View； 在RR隔离级别下，则是同一个事务中的第一个快照读才会创建Read View, 之后的快照读获取的都是同一个Read View MVCC操作流程 首先获取事务自己的版本号，也就是事务 ID; 获取 ReadView; 查询得到的数据，然后与 ReadView 中的事务版本号进行比较; 如果不符合 ReadView 规则，就需要从 Undo Log 中获取历史快照; 最后返回符合规则的数据。 InnoDB解决幻读的流程 假设现在表 student 中只有一条数据，数据内容中，主键 id=1，隐藏的 trx_id=10，它的 undo log 如下图 所示。现在有事务A和事务B并发执行， 的事务id为 20 ， 的事务id为 30 。 事务 A 开始第一次查询数据，查询的 SQL 语句如下。 select*fromstudentwhereid\u003e=1 在开始查询时,会生成一个ReadView; 内容如下 trx_id=[20,30] up_limit_id=20 low_limit_id=31 creator_trx_id=2 ​ 此时表 student 中只有一条数据，且符合 where id\u003e=1 条件，因此会查询出来。然后根据 ReadView 机制，发现该行数据的trx_id=10，小于事务 A 的 ReadView 里 up_limit_id，这表示这条数据是事务 A 开 启之前，其他事务就已经提交了的数据，因此事务 A 可以读取到。 接着事务 B(trx_id=30)，往表 student 中新插入两条数据，并提交事务。 insertintostudent(id,name)values(2,'李四');insertintostudent(id,name)values(3,'王五'); 此时表student 中就有三条数据了，对应的 undo 如下图所示: 接着事务 A 开启第二次查询，根据可重复读隔离级别的规则，此时事务 A 并不会再重新生成 ReadView。此时表 student 中的 3 条数据都满足 where id\u003e=1 的条件，因此会先查出来。然后根据 ReadView 机制，判断每条数据是不是都可以被事务 A 看到。 首先 id=1 的这条数据，前面已经说过了，可以被事务 A 看到。 然后是 id=2 的数据，它的 trx_id=30，此时事务 A 发现，这个值处于 up_limit_id 和 low_limit_id 之 间，因此还需要再判断 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:4:6","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"Undo log ​ undo log 叫做回滚日志，用于记录数据被修改前的信息。他正好跟前面所说的重做日志所记录的相反，重做日志记录数据被修改后的信息。undo log主要记录的是数据的逻辑变化，为了在发生错误时回滚之前的操作，需要将之前的操作都记录下来，然后在发生错误时才可以回滚。 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:4:7","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"Redo log InnoDB修改数据的基本流程 ​ 当我们想要修改DB上某一行数据的时候，InnoDB是把数据从磁盘读取到内存的缓冲池上进行修改。数据在内存中被修改，与磁盘中相比就存在了差异，我们称这种有差异的数据为脏页。InnoDB对脏页的处理不是每次生成脏页就将脏页刷新回磁盘，这样会产生海量的IO操作，严重影响InnoDB的处理性能。 ​ InnoDB采用Write Ahead Log策略来防止宕机数据丢失，即事务提交时，先写重做日志，再修改内存数据页，这样就产生了脏页. Redo log 工作原理 ​ redo log在数据库重启恢复的时候被使用，因为其属于物理日志的特性，恢复速度远快于逻辑日志。而我们经常使用的binlog就属于典型的逻辑日志。 CheckPoint ​ 脏页刷新的规则叫checkpoint机制。所做的事就是把脏页给刷新回磁盘。所以，当DB重启恢复时，只需要恢复checkpoint之后的数据。这样就能大大缩短恢复时间 两种checkpoint： sharp checkpoint：在数据库关闭时，刷新所有的脏页到磁盘，这里有参数控制，默认是开启的 fuzzy checkpoint：刷新一部分脏页到磁盘中。 定时刷新: Master Thread以每秒或每十秒的速度从缓冲池的脏页列表中刷新一定比例的页回磁盘;这个过程是异步的，不会阻塞查询线程。 FLUSH_LRU_LIST Checkpoint: InnoDB要保证LRU列表中有100左右空闲页可使用 Async/Sync Flush Checkpoint: 指重做日志文件不可用时，需要强制将脏页列表中的一些页刷新回磁盘。这可以保证重做日志文件可循环使用 Dirty Page too much Checkpoint: 脏页数量太多时，InnoDB引擎会强制进行Checkpoint。目的还是为了保证缓冲池中有足够可用的空闲页 LSN(Log Sequence Number) ​ LSN实际上就是InnoDB使用的一个版本标记的计数，它是一个单调递增的值。数据页和redo log都有各自的LSN。我们可以根据数据页中的LSN值和redo log中LSN的值判断需要恢复的redo log的位置和大小。 redo Log 工作原理 ​ redo log就是存储了数据被修改后的值。当我们提交一个事务时，InnoDB会先去把要修改的数据写入日志，然后再去修改缓冲池里面的真正数据页。 ​ redo log本身也由两部分所构成即重做日志缓冲(redo log buffer)和重做日志文件(redo log file)。这样的设计同样也是为了调和内存与磁盘的速度差异。InnoDB写入磁盘的策略可以通过innodb_flush_log_at_trx_commit这个参数来控制。​ 当该值为1时，当然是最安全的，但是数据库性能会受一定影响。为0时性能较好，但是可能会丢失掉master thread还没刷新进磁盘部分的数据。 master thread :后台运行的主线程; 它做的主要工作包括但不限于：刷新日志缓冲，合并插入缓冲，刷新脏页等 innodb_flush_log_at_trx_commit设为非0的值，并不是说不会在master thread中刷新日志了。master thread刷新日志是在不断进行的，所以redo log写入磁盘是在持续的写入。 宕机恢复 ​ DB宕机后重启，InnoDB会首先去查看数据页中的LSN的数值。这个值代表数据页被刷新回磁盘的LSN的大小。然后再去查看redo log的LSN的大小。如果数据页中的LSN值大说明数据页领先于redo log刷新，不需要进行恢复。反之需要从redo log中恢复数据。 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:4:8","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"主从复制 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:5:0","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"主从复制的作用 实现服务器负载均衡和读写分离,降低服务器工作负荷 通过复制实现数据的异地备份 提高数据库系统的高可用性, 主备切换不断网 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:5:1","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"主从复制原理 Master 数据库只要发生变化，立马记录到Binary log 日志文件中 Slave数据库启动一个I/O thread连接Master数据库，请求Master变化的二进制日志 Slave I/O获取到的二进制日志，保存到自己的Relay log 日志文件中。 Slave 有一个 SQL thread定时检查Realy log是否变化，变化那么就更新数据 三个线程: 主从同步的原理就是基于 binlog 进行数据同步的。在主从复制过程中，会基于 3 个线程 来操 作，一个主库线程，两个从库线程。 二进制日志转储线程 (Binlog dump thread)是一个主库线程。当从库线程连接的时候， 主库可以将二进制日志发送给从库，当主库读取事件(Event)的时候，会在 Binlog 上 加锁 ，读取完成之后，再将锁释放掉。 从库 I/O 线程会连接到主库，向主库发送请求更新Binlog。这时从库的I/O线程就可以读取到主库的二进制日志转储线程发送的 Binlog 更新部分，并且拷贝到本地的中继日志 (Relay log)。 从库 SQL 线程 会读取从库中的中继日志，并且执行日志中的事件，将从库中的数据与主库保持同步。 MySQL复制是异步的且串行化 的，而且重启后从接入点 开始复制。 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:5:2","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"同步的一致性问题 主从延迟问题 主从同步的内容是二进制日志，它是一个文件，在进行 网络传输 的过程中就一定会存在主从延迟(比如 500ms)，这样就可能造成用户在从库上读取的数据不是最新的数据，也就是主从同步中的 数据不一致性 问题。 主从延迟问题原因 ​ 主备延迟最直接的表现是，从库消费中继日志(relay log)的速度，比主库生产binlog的速度要慢。 从库的机器性能比主库要差 从库的压力大 大事务的执行 主从延迟问题解决: 降低多线程大事务并发的概率，优化业务逻辑 优化SQL，避免慢SQL， 减少批量操作 ，建议写脚本以update-sleep这样的形式完成 提高从库机器配置,减少主库写binlog和从库读binlog的效率差 减少网络延迟(距离和端口带宽) 实时性要求的业务读强制走主库，从库只做灾备，备份。 如何解决一致性问题 ​ 一致性问题, 即主库已经更新了,但从库还没有同步, 从而没办法读取到最新的数据,与主数据库不一致. 异步复制:主库在执行完客户端提交的事务后会立即将结果返给给客户端，并不关心从库是否已经接收并处理 半同步复制: 等主从同步完成之后，主库上的写请求再返回![截屏2022-08-31 下午2.45.57](https://raw.githubusercontent.com/NoobMidC/pics/main/截屏2022-08-31 下午2.45.57.png) 组复制 ​ 多个节点共同组成一个复制组，在 执行读写(RW)事务 的时候，需要通过一致性协议层的同意，也就是读写事务想要进行提交，必须要经过组里“大多数人”(对应 Node 节 点)的同意，大多数指的是同意的节点数量需要大于 (N/2+1)，这样才可以进行提交(Paxos 协议) 数据库中间件 缓存记录写key法 CUD操作: 将某个库上的某个key要发生写操作，记录在cache里，并设置“经验主从同步时间”的cache超时时间，例如500ms 修改数据库 R操作: 先到cache里查看，对应库的对应key有没有相关数据 如果cache hit，有相关数据，说明这个key上刚发生过写操作，此时需要将请求路由到主库读最新的数据 如果cache miss，说明这个key上近期没有发生过写操作，此时将请求路由到从库，继续读写分离 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:5:3","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"Binlog日志 Binlog 的录入格式 有三种格式，statement，row和 mixed。 statement 模式下，每一条会修改数据的 sql 都会记录在 binlog 中。不需要记录每一行的变化，减少了binlog日志量，节约了IO，提高性能。 row级别下，row level 的日志内容会非常清楚的记录下每一行数据修改的细节。 mixed，一种折中的方案，普通操作使用 statement 记录，当无法使用 statement 的时候使用 row。 写入机制 ​ 事务执行过程中，先把日志写到 binlog cache，事务提交的时候，再把 binlog cache 写到 binlog 文件中。一个事务的 binlog 是不能被拆开的，因此不论这个事务多大，也要确保一次性写入。这就涉及到了 binlog cache 的保存问题。 ​ 系统给 binlog cache 分配了一片内存，每个线程一个，参数 binlog_cache_size 用于控制单个线程内 binlog cache 所占内存的大小。如果超过了这个参数规定的大小，就要暂存到磁盘。每个线程有自己 binlog cache，但是共用同一份 binlog 文件。 ​ 线程将binlog日志write到page cache, 然后调用fsync(或者交给OS)持久化到操作系统;write 和 fsync 的时机，是由参数 sync_binlog 控制的： sync_binlog=0 的时候，表示每次提交事务都只 write，不 fsync sync_binlog=1 的时候，表示每次提交事务都会执行 fsync sync_binlog=N(N\u003e1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync。 Redo log和binlog对比 redo log是InnoDB引擎特有的；binlog是MySQL的Server层实现的，所有引擎都可以使用。 redo log是物理日志，记录的是“在某个数据页上做了什么修改”；binlog是逻辑日志，记录的 是这个语句的原始逻辑，比如“给ID=2这一行的c字段加1 ”。 redo log是循环写的，空间固定会用完；binlog是可以追加写入的。“追加写”是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。 两阶段提交 ​ 为了解决Redolog和binlog日志之间的逻辑一致问题，InnoDB存储引擎使用两阶段提交方案。原理很简单，将redo log的写入拆成了两个步骤prepare和commit，这就是两阶段提交。 先写入redo log时为 prepare阶段, 在提交事务前将binlog写入,然后将redo log设置为commit,这样事务便提交了 发生故障: 写入binlog时发生异常也不会有影响，因为MySQL根据redo log日志恢复数据时，发现redolog还处于prepare阶段，并且没有对应binlog日志，就会回滚该事务。 redo log设置commit阶段发生异常,并不会回滚事务，它会执行下图框住的逻辑，虽然redo log是处于prepare阶段，但是能通过事务id找到对应的binlog日志，所以MySQL认为是完整的，就会提交事务恢复数据。 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:5:4","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"三大范式 第一范式：字段(列)具有原子性,不可再分 第二范式：在第一范式的基础上，每行都有应该被唯一区分,唯一标识符为主键(都依赖于主键)。 第三范式：在第二范式的基础上，非主键列只依赖于主键，不依赖于其他非主键。(不间接依赖) 范式优缺点: 优点: 范式化, 重复冗余数据少,更新快,修改少. 缺点: 因为一个表不存在冗余重复数据，查询可能造成很多关联，效率变低，可能使一些索引策略无效，范式化将列存在不同表中，这些列若在同一个表中可以是一个索引。 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:6:0","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"什么是存储过程？有哪些优缺点？ 存储过程是一些预编译的 SQL 语句。 存储过程可以说是一个记录集，它是由一些 SQL 语句组成的代码块，这些 SQL 语句代码像一个方法一样实现一些功能（对单表或多表的增删改查），然后再给这个代码块取一个名字，在用到这个功能的时候调用他就行了。 存储过程是一个预编译的代码块，执行效率比较高,一个存储过程替代大量 SQL 语句 ，可以降低网络通信量，提高通信速率,可以一定程度上确保数据安全 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:7:0","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"mysql表的拆分 垂直拆分 ​ 垂直拆分的意思，就是把一个有很多字段的表给拆分成多个表，或者是多个库上去。每个库表的结构都不一样，每个库表都包含部分字段。一般来说，会将较少的访问频率很高的字段放到一个表里去，然后将较多的访问频率很低的字段放到另外一个表里去。因为数据库是有缓存的，你访问频率高的行字段越少，就可以在缓存里缓存更多的行，性能就越好。这个一般在表层面做的较多一些。 优点: 1 .可以使得行数据变小，在查询时减少读取的 Block 数，减少 I/O 次数。2. 可以简化表的结构，易于维 护。 缺点: 1. 主键会出现冗余，需要管理冗余列，查询所有数据需要 join 操作，可以通过在应用层进行 Join 来 解决。此外，垂直分区会让事务变得更加复杂。 适用场景: 一个表中某些列常用，另外一些列不常用 水平拆分 ​ 水平拆分的意思，就是把一个表的数据给弄到多个库的多个表里去，但是每个库的表结构都一样，只不过每个库表放的数据是不同的，所有库表的数据加起来就是全部数据。水平拆分的意义，就是将数据均匀放更多的库里，然后用多个库来抗更高的并发，还有就是用多个库的存储容量来进行扩容。 优点: 充分利用多个机器的性能,提高并发 适应场景: 表中的数据本身就有独立性，例如表中分表记录各个地区的数据或者不同时期的数据，特别是有些数据常用，有些不常用。 拆分的问题 事务支持: 分库分表后，就成了分布式事务了。如果依赖数据库本身的分布式事务管理功能去执行事 务，将付出高昂的性能代 价; 如果由应用程序去协助控制，形成程序逻辑上的事务，又会 造成编程方面的负担。 跨库 join: 只要是进行切分，跨节点 Join 的问题是不可避免的。但是良好的设计和切分却可以减少此类情况的发生。 ​ 解决这 一问题的普遍做法是分两次查询实现。在第一次查询的结果集中找出关联数据的 id, 根据这些 id 发起第二次请求得 到关联数据。 ID问题: 一旦数据库被切分到多个物理结点上，我们将不能再依赖数据库自身的主键生成机制。一 方面，某个分区数据库自 生成的 ID 无法保证在全局上是唯一的;另一方面，应用程序在 插入数据之前需要先获得 ID,以便进行 SQL 路由; ​ UUID 使用 UUID 作主键是最简单的方案，但是缺点也是非常明显的。由于 UUID 非常的 ⻓，除占用大量存储空间 外，最主要的问题是在索引上，在建立索引和基于索引进行查询 时都存在性能问题。 ​ Twitter 的分布式自增 ID 算 法 Snowflake 在分布式系统中，需要生 成全局 UID 的场合还是比较多的，twitter 的 snowflake 解决了这种需 求，实现也还是很简单的，除去配置信息，核心代码就是毫秒级时间 41 位机器 ID10位+毫秒内序列 12 位。 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:7:1","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"自增主键的理解 ​ Innodb引擎的自增值, 原本是保存在内存中 ,8.0以后则持久化, 重启后表的自增值能恢复到mysql重启前的值. mysql5.7 及以前,自增值保存内存,没有持久化.每次重启后,第一次打开表,都会去找自增值的最大值. MySQL 8.0版本，将自增值的变更记录在了redo log中，重启的时候依靠redo log恢复重启之前的值。 自增主键不连续的情况 在MySQL 5.7及之前的版本，自增值保存在内存里，并没有持久化. 事务回滚（自增值不能回退，因为并发插入数据时，回退自增ID可能造成主键冲突） 唯一键冲突（由于表的自增值已变，但是主键发生冲突没插进去，下一次插入主键=现在变了的子增值+1，所以不连续） 为什么用自增ID 主键页就会近乎于顺序的记录填满，提升了页面的最大填充率，不会有页的浪费 新插入的行一定会在原有的最大数据行下一行，mysql定位和寻址很快，不会为计算新行的位置而做出额外的消耗。 减少了页分裂和碎片的产生 如果使用uuid,会导致大量的随机IO+页分裂导致移动大量的数据+数据会有碎片 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:7:2","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"WAL(Write Ahead Log)预写日志 原子性: 事务的原子性是通过Redo Log和Undo Log保证的。 1. 每一个写事务，都会修改BufferPool，从而产生相应的Redo/Undo日志，这些日志信息会被记录到日志文件中. 2. 任何 Buffer Pool中的页被刷到磁盘之前，数据都会先写入到日志文件中 3. 如果Buffer Pool 中的数据提交(commit)，此时数据库挂了，那在数据库再次启动之后，可以通Redo日志将其恢复出来，以保证脏页写的数据不会丢失。 4. 如果数据没有提交（没有commit)，此时数据库挂了,就需要通过Undo来回滚了。 持久性: 通过Redo Log 和WAL实现的 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:7:3","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"大表怎么优化?分库分表了是怎么做的?分表分库了有什么问题? ​ 当 MySQL 单表记录数过大时，数据库的 CRUD 性能会明显下降，一些常见的优化措施如下: 限定数据的范围: 务必禁止不带任何限制数据范围条件的查询语句。比如:我们当用户在查询订单历史的时候，我们可以控制在一个月的范围内 读/写分离: 经典的数据库拆分方案，主库负责写，从库负责读; 缓存: 使用 MySQL 的缓存，另外对重量级、更新少的数据可以考虑使用应用级别的缓存 还有就是通过分库分表的方式进行优化。主要有垂直分区、垂直分表、水平分区、水平分表、垂直分区 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:7:4","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"MyISAM 表类型将在哪里存储，并且还提供其存储格式? 每个 MyISAM 表格以三种格式存储在磁盘上: 表结构(元数据)由“.frm”文件存储 数据文件具有“.MYD”(MYData)扩展名 索引文件具有“.MYI”(MYIndex)扩展名 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:7:5","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"百万级别或以上的数据如何删除 ​ 由于索引需要额外的维护成本，因为索引文件是单独存在的文件,所以当我们对数据的增加,修改,删除,都 会产生额外的对索引文件的操作,这些操作需要消耗额外的 IO,会降低增/改/删的执行效率。 可以先删除索引(此时大概耗时三分多钟) 然后删除其中无用数据(此过程需要不到两分钟) 删除完成后重新创建索引(此时数据较少了)创建索引也非常快，约十分钟左右。 与之前的直接删除绝对是要快速很多，更别说万一删除中断,一切删除会回滚。那更是坑了 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:7:6","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"什么是临时表，何时删除临时表? ​ MySQL在执行 SQL语句的过程中通常会临时创建一些存储中间结果集的表，临时表只对当前连接可见，在连接关闭时，临时表会被删除并释放所有表空间。 ​ 临时表分为两种:一种是内存临时表，一种是磁盘临时表，什么区别呢?内存临时表使用的是 MEMORY存储引擎，而 临时表采用的是 MylSAM 存储引擎。 ​ MySQL会在下面这几种情况产生临时表: 使用 UNION查询:UNION有两种，一种是 UNION，一种是 UNION ALL，它们都用于联合查询;区别是使用 UNION会去掉两个表中的重复数据，相当于对结果集做了一下去重(distinct)。使用 UNIONALL，则不会排重，返回所有的行。使用 UNION查询会产生临时表。 使用UNION查询中的视图。意味这要 MySQL要先创建好一个临时表，然后将结果放到临时表中去，然后再使用这个临 时表进行相应的查询。 ORDER BY和 GROUPBY的子句不一样时也会产生临时表。 DISTINCT 查询并且加上 ORDER BY时; FROM中的子查询; EXPLAIN 查看执行计划结果的 Extra 列中，如果使用 Using Temporary 就表示会用到临时表。 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:7:7","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"计算机网络 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:0:0","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"为什么要对网络协议分层？ ​ 网络协议是计算机在通信过程中要遵循的一些约定好的规则。 ​ 网络分层的原因： 易于实现和维护，因为各层之间是独立的，层与层之间不会收到影响。 有利于标准化的制定 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:1:0","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"路由器和交换机的区别？ ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:2:0","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"协议模型 OSI七层协议模型包括: 应用-表示-会话-传输-网络-数据链路-物理层 五层协议模型包括: 应用-传输-网络-数据链路-物理层 物理层 ​ 主要解决两台物理机之间的通信，通过二进制比特流的传输来实现，二进制数据表现为电流电压上的强弱，到达目的地再转化为二进制机器码。网卡、集线器工作在这一层。 数据链路层 ​ 在不可靠的物理介质上提供可靠的传输，接收来自物理层的位流形式的数据，并封装成帧，传送到上一层;同样，也将来自上层的数据帧，拆装为位流形式的数据转发到物理层。这一层在物理层提供的比特流的基础上，通过差错控制、流量控制方法，使有差错的物理线路变为无差错的数据链路。提供物理地址寻址功能。交换机工作在这一层。 网络层 ​ 将网络地址翻译成对应的物理地址，并决定如何将数据从发送方路由到接收方，通过路由选择算法为分组通过通信子网选择最佳路径。路由器工作在这一层。常见的协议有IP协议，ARP协议、ICMP协议。 传输层 ​ 传输层提供了进程间的逻辑通信，传输层向高层用户屏蔽了下面网络层的核心细节，使应用程序看起来像是在两个传输层实体之间有一条端到端的逻辑通信信道。主要协议为TCP、UDP协议 会话层 建立会话:身份验证，权限鉴定等; 保持会话:对该会话进行维护，在会话维持期间两者可以随时使用这条会话传输数据; 断开会话:当应用程序或应用层规定的超时时间到期后，OSI会话层才会释放这条会话。 表示层 ​ 对数据格式进行编译，对收到或发出的数据根据应用层的特征进行处理，如处理为文字、图片、音频、视频、文档等，还可以对压缩文件进行解压缩、对加密文件进行解密等。 应用层 ​ 应用层的任务是通过应用进程之间的交互来完成特定的网络作用，常见的应用层协议有DNS，HTTP、FTP协议等。 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:3:0","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"[应用层]HTTP协议 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:4:0","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"HTTP 状态码 类别 描述 1xx 信息性状态码 2xx 成功状态码 3xx 重定向状态码 4xx 客户端错误状态码 5xx 服务端错误状态码 1xx 100 Continue：表示正常，客户端可以继续发送请求 101 Switching Protocols：切换协议，服务器根据客户端的请求切换协议。 2xx 200 OK：请求成功 201 Created：已创建，表示成功请求并创建了新的资源 202 Accepted：已接受，已接受请求，但未处理完成。 204 No Content：无内容，服务器成功处理，但未返回内容。 205 Reset Content：重置内容，服务器处理成功，客户端应重置文档视图。 206 Partial Content：表示客户端进行了范围请求，响应报文应包含Content-Range指定范围的实体内容 3xx 301 Moved Permanently：永久性重定向 302 Found：临时重定向 303 See Other：和301功能类似，但要求客户端采用get方法获取资源 304 Not Modified：所请求的资源未修改，服务器返回此状态码时，不会返回任何资源。 305 Use Proxy：所请求的资源必须通过代理访问 307 Temporary Redirect： 临时重定向，与302类似，要求使用get请求重定向。 4xx 400 Bad Request：客户端请求的语法错误，服务器无法理解。 401 Unauthorized：表示发送的请求需要有认证信息。 403 Forbidden：服务器理解用户的请求，但是拒绝执行该请求 404 Not Found：服务器无法根据客户端的请求找到资源。 405 Method Not Allowed：客户端请求中的方法被禁止 406 Not Acceptable：服务器无法根据客户端请求的内容特性完成请求 408 Request Time-out：服务器等待客户端发送的请求时间过长，超时 5xx 500 Internal Server Error：服务器内部错误，无法完成请求 501 Not Implemented：服务器不支持请求的功能，无法完成请求 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:4:1","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"HTTP版本 HTTP1.0 ​ HTTP1.0 使用的是非持久连接，主要缺点是客户端必须为每一个待请求的对象建立并维护一个新的连接，即每请求一个文档就要有两倍RTT 的开销。因为同一个页面可能存在多个对象，所以非持久连接可能使一个页面的下载变得十分缓慢，而且这种 短连接增加了网络传输的负担。 RTT(Round Trip Time)：一个连接的往返时间，即数据发送时刻到接收到确认的时刻的差值； HTTP1.1 支持长连接。 在HTTP1.0的基础上引入了更多的缓存控制策略。 引入了请求范围设置，优化了带宽。 在错误通知管理中新增了错误状态响应码。 增加了Host头处理，可以传递主机名（hostname） HTTP1.X优化（SPDY） ​ SPDY 并不是新的一种协议，而是在 HTTP 之前做了一层会话层。为了达到减少页面加载时间的目标，SPDY 引入了一个新的二进制分帧数据层，以实现优先次序、最小化及消除不必要的网络延迟，目的是更有效地利用底层 TCP 连接。 多路复用，为多路复用设立了请求优先级。 对header部分进行了压缩。 引入了HTTPS加密传输。 客户端可以在缓存中取到之前请求的内容。 HTTP2.0（SPDY的升级版） HTTP2.0支持明文传输，而HTTP 1.X强制使用SSL/TLS加密传输。 和HTTP 1.x使用的header压缩方法不同。 HTTP2.0 基于二进制格式进行解析，而HTTP 1.x基于文本格式进行解析。增加二进程的传输方式，相对于文本传输更加安全. 多路复用，HTTP1.1是多个请求串行化单线程处理，HTTP 2.0是并行执行，一个请求超时并不会影响其他请求。 请求划分优先级 HTTP 3.0 (QUIC) QUIC (Quick UDP Internet Connections), 快速 UDP 互联网连接。QUIC是基于UDP协议的。两个主要特性： 线头阻塞(HOL)问题的解决更为彻底： ​ 基于TCP的HTTP/2，尽管从逻辑上来说，不同的流之间相互独立，不会相互影响，但在实际传输方面，数据还是要一帧一帧的发送和接收，一旦某一个流的数据有丢包，则同样会阻塞在它之后传输的流数据传输。而基于UDP的QUIC协议则可以更为彻底地解决这样的问题，让不同的流之间真正的实现相互独立传输，互不干扰。 切换网络时的连接保持 ​ 当前移动端的应用环境，用户的网络可能会经常切换，比如从办公室或家里出门，WiFi断开，网络切换为3G或4G。基于TCP的协议，由于切换网络之后，IP会改变，因而之前的连接不可能继续保持。而基于UDP的QUIC协议，则可以内建与TCP中不同的连接标识方法，从而在网络完成切换之后，恢复之前与服务器的连接。 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:4:2","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"HTTP方法 方法 作用 GET 获取资源 POST 传输实体主体 PUT 上传文件 DELETE 删除文件 HEAD 和GET方法类似，但只返回报文首部，不返回报文实体主体部分 PATCH 对资源进行部分修改 OPTIONS 查询指定的URL支持的方法 CONNECT 要求用隧道协议连接代理 TRACE 服务器会将通信路径返回给客户端 为了方便记忆，可以将PUT、DELETE、POST、GET理解为客户端对服务端的增删改查。 PUT：上传文件，向服务器添加数据，可以看作增 DELETE：删除文件 POST：传输数据，向服务器提交数据，对服务器数据进行更新。 GET：获取资源，查询服务器资源 GET和POST的区别 作用GET用于获取资源，POST用于传输实体主体 参数位置GET的参数放在URL中，POST的参数存储在实体主体中，并且GET方法提交的请求的URL中的数据做多是2048字节，POST请求没有大小限制。 安全性GET方法因为参数放在URL中，安全性相对于POST较差一些 幂等性GET方法是具有幂等性的，而POST方法不具有幂等性。这里幂等性指客户端连续发出多次请求，收到的结果都是一样的. ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:4:3","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"HTTP和HTTPS的区别 HTTP HTTPS 端口 80 443 安全性 无加密 有加密机制、安全性较高 资源消耗 较少 由于加密处理，资源消耗更多 是否需要证书 不需要 需要 协议 运行在TCP协议之上 运行在SSL协议之上，SSL运行在TCP协议之上 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:4:4","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"HTTPS的加密过程 HTTPS使用的是对称加密和非对称加密的混合加密算法。具体做法就是使用非对称加密来传输对称密钥来保证安全性，使用对称加密来保证通信的效率。 简化的工作流程：服务端生成一对非对称密钥，将公钥发给客户端。客户端生成对称密钥，用服务端发来的公钥进行加密，加密后发给服务端。服务端收到后用私钥进行解密，得到客户端发送的对称密钥。通信双方就可以通过对称密钥进行高效地通信了。 HTTPS的详细加密过程： 客户端向服务端发起第一次握手请求，告诉服务端客户端所支持的SSL的指定版本、加密算法及密钥长度等信息。 服务端将自己的公钥发给数字证书认证机构，数字证书认证机构利用自己的私钥对服务器的公钥进行数字签名，并给服务器颁发公钥证书。 服务端将证书发给客服端。 客服端利用数字认证机构的公钥，向数字证书认证机构验证公钥证书上的数字签名，确认服务器公开密钥的真实性。 客服端使用服务端的公钥加密自己生成的对称密钥，发给服务端。 服务端收到后利用私钥解密信息，获得客户端发来的对称密钥。 通信双方可用对称密钥来加密解密信息。 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:4:5","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"[应用层]DNS协议 DNS : 域名系统；DNS系统采用的是分布式的层次数据数据库模式，还有缓存的机制。 ​ 工作流程 主机向本地域名服务器的查询一般是采用递归查询，而本地域名服务器向根域名的查询一般是采用迭代查询 递归查询，是服务器向上级服务器发送请求报文，返回给你ip地址 迭代查询，是服务器通知你，需要向哪个上级服务器发请求报文，请求ip. 实例: 在浏览器中输入百度域名，操作系统会先检查自己本地的hosts文件是否有这个域名的映射关系，如果有，就先调用这个IP地址映射，完成域名解析。 如果hosts文件中没有，则查询本地DNS解析器缓存，如果有，则完成地址解析。 如果本地DNS解析器缓存中没有，则去查找本地DNS服务器，如果查到，完成解析。 如果没有，则本地服务器会向根域名服务器发起查询请求。根域名服务器会告诉本地域名服务器去查询哪个顶级域名服务器。 本地域名服务器向顶级域名服务器发起查询请求，顶级域名服务器会告诉本地域名服务器去查找哪个权限域名服务器。 本地域名服务器向权限域名服务器发起查询请求，权限域名服务器告诉本地域名服务器百度所对应的IP地址。 本地域名服务器告诉主机百度所对应的IP地址。 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:5:0","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"[传输层]TCP/UDP协议详解 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:6:0","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"TCP 数据结构 ​ TCP头部: 前20个字节是固定的，后面有4n个字节是根据需而增加的选项，所以TCP首部最小长度为20字节。 序号：seq，占32位，用来标识从发送端到接收端发送的字节流。(一般来说在0 - 2^32-1之间) 确认号：ack，占32位，只有ACK标志位为1时，确认序号字段才有效，ack=seq+1。 标志位： SYN：发起一个新连接。 FIN：释放一个连接。 ACK：确认序号有效。 TCP可靠传输 主要有校验和、序列号、超时重传、流量控制及拥塞避免等几种方法。 校验和: 在发送端和接收端分别计算数据的校验和，如果两者不一致，则说明数据在传输过程中出现了差错，TCP将丢弃和不确认此报文段。 序列号: TCP会对每一个发送的字节进行编号，接收方接到数据后，会对发送方发送确认应答(ACK报文)，并且这个ACK报文中带有相应的确认编号，告诉发送方，下一次发送的数据从编号多少开始发。如果发送方发送相同的数据，接收端也可以通过序列号判断出，直接将数据丢弃. 超时重传: 在上面说了序列号的作用，但如果发送方在发送数据后一段时间内（可以设置重传计时器规定这段时间）没有收到确认序号ACK，那么发送方就会重新发送数据。 这里发送方没有收到ACK可以分两种情况： 如果是发送方发送的数据包丢失了，接收方收到发送方重新发送的数据包(序列号大于了丢失的数据的序列号)后会马上重新给发送方发送(原丢失数据的)ACK； 如果是接收方之前接收到了发送方发送的数据包，而返回给发送方的ACK丢失了，这种情况，发送方重传后，接收方会直接丢弃发送方重传的数据包，然后再次发送ACK响应报文。如果数据被重发之后还是没有收到接收方的确认应答，则进行再次发送。此时，等待确认应答的时间将会以2倍、4倍的指数函数延长，直到最后关闭连接。 流量控制: 如果发送端发送的数据太快，接收端来不及接收就会出现丢包问题。 ​ 为了解决这个问题，TCP协议利用了滑动窗口进行了流量控制。在TCP首部有一个16位字段大小的窗口，窗口的大小就是接收端接收数据缓冲区的剩余大小。接收端会在收到数据包后发送ACK报文时，将自己的窗口大小填入ACK中，发送方会根据ACK报文中的窗口大小进而控制发送速度。如果窗口大小为零，发送方会停止发送数据。 拥塞控制: 如果网络出现拥塞，则会产生丢包等问题，这时发送方会将丢失的数据包继续重传，网络拥塞会更加严重，所以在网络出现拥塞时应注意控制发送方的发送数据，降低整个网络的拥塞程度。 拥塞控制主要有四部分组成：慢开始、拥塞避免、快重传、快恢复 （这里的发送方会维护一个拥塞窗口的状态变量，它和流量控制的滑动窗口是不一样的，滑动窗口是根据接收方数据缓冲区大小确定的，而拥塞窗口是根据网络的拥塞情况动态确定的，一般来说发送方真实的发送窗口为滑动窗口和拥塞窗口中的最小值） 慢开始: 为了避免一开始发送大量的数据而产生网络阻塞，会先初始化cwnd为1，当收到ACK后到下一个传输轮次，cwnd为2，以此类推成指数形式增长。 拥塞避免: 因为cwnd的数量在慢开始是指数增长的，为了防止cwnd数量过大而导致网络阻塞，会设置一个慢开始的门限值ssthresh，当cwnd\u003e=ssthresh时，进入到拥塞避免阶段，cwnd每个传输轮次加1。但网络出现超时，会将门限值ssthresh变为出现超时cwnd数值的一半，cwnd重新设置为1，如上图，在第12轮出现超时后，cwnd变为1，ssthresh变为12。 快重传：在网络中如果出现超时或者阻塞，则按慢开始和拥塞避免算法进行调整。但如果只是丢失某一个报文段，如下图，则使用快重传算法。 但是根据快重传算法，要求在这种情况下，需要快速向发送端发送M2的确认报文，在发送方收到三个M2的确认报文后，无需等待重传计时器所设置的时间，可直接进行M3的重传，这就是快重传。 快恢复: 当发送收到三个重复的ACK，会进行快重传和快恢复。快恢复是指将ssthresh设置为发生快重传时的cwnd数量的一半，而cwnd不是设置为1而是设置为为门限值ssthresh，并开始拥塞避免阶段。 TCP三次握手 发送端状态：CLOSED、SYN-SENT、ESTABLISHED 接收端状态：LISTEN、SYN-RCVD、ESTABLISHED 对于客户端而言,第二次握手就已经确定了建立链接,因此第三次握手实际上也算是数据传输的一次, 所以第一个数据包序列号为x+1 TCP连接队列 半连接队列: 服务端收到客户端发起的 SYN 请求后，内核会把该连接存储到半连接队列（SYN队列），并向客户端响应 SYN+ACK. 全连接队列: 服务端收到第三次握手的ACK后，内核会把连接从半连接队列移除，然后创建新的完全的连接，并将其添加到accept队列，等待进程调用accept 函数时把连接取出来。 为什么握手需要三次? 假设建立TCP连接仅需要两次握手，那么如果第二次握手时，服务端返回给客户端的确认报文丢失了，客户端这边认为服务端没有和他建立连接，而服务端却以为已经和客户端建立了连接，并且可能服务端已经开始向客户端发送数据，但客户端并不会接收这些数据，浪费了资源。如果是三次握手，不会出现双方连接还未完全建立成功就开始发送数据的情况。 如果服务端接收到了一个早已失效的来自客户端的连接请求报文，会向客户端发送确认报文同意建立TCP连接。但因为客户端并不需要向服务端发送数据，所以此次TCP连接没有意义并且浪费了资源。 如果是一次握手,则退化成了UDP SYN洪泛攻击，以及解决策略是什么? ​ 因为服务器端的资源分配是在二次握手时分配的，而客户端的资源是在完成三次握手时分配的，所以服务器容易受到SYN洪泛攻击。 洪泛攻击: SYN攻击就是Client在短时间内伪造大量不存在的IP地址，并向Server不断地发送SYN包，Server则回复确认包，并等待Client确认，由于源地址不存在，因此Server需要不断重发直至超时，这些伪造的SYN包将长时间占用半连接队列，导致正常的SYN请求因为队列满而被丢弃，从而引起网络拥塞甚至系统资源被占用完而瘫痪。SYN 攻击是一种典型的 DoS/DDoS 攻击 查看检测 SYN 攻击非常的方便，当你在服务器上看到大量的半连接状态时，特别是源IP地址是随机的，基本上可以断定这是一次SYN攻击。 netstat -n -p TCP | grep SYN_RECV 常见的解决办法: 缩短超时（SYN Timeout）时间 增加最大半连接数: 可以保存更多的半连接数,防止丢弃新连接 增加过滤网关防护 SYN cookies技术: 可以在不使用SYN半连接队列的情况下成功建立连接; ​ 原理是，在TCP服务器接收到TCP SYN包并返回TCP SYN + ACK包时，不分配一个专门的数据区，而是根据这个SYN包计算出一个cookie值。这个cookie作为将要返回的SYN ACK包的初始序列号。当客户端返回一个ACK包时，根据包头信息计算cookie，与返回的确认序列号(初始序列号 + 1)进行对比，如果相同，则是一个正常连接，然后，分配资源，建立连接。 TCP四次挥手 客户端状态：ESTABLISHED、FIN-WAIT-1、FIN-WAIT-2、TIME-WAIT、CLOSED 服务器状态：ESTABLISHED、CLOSE-WAIT、LAST-ACK、CLOSED 为什么要time_wait状态, 以及等待2MSL的时间? ​ MSL(Maximum Segment LifeTime)是报文最大生成时间，它是任何报文在网络上存在的最长时间，超过这个时间的报文将被丢弃。可以从两方面考虑： 客户端发送第四次挥手中的报文后，再经过2MSL，可使本次TCP连接中的所有报文全部消失，不会出现在下一个TCP连接中。 考虑丢包问题，如果第四挥手发送的报文在传输过程中丢失了，那么服务端没收到确认ack报文就会重发第三次挥手的报文。如果客户端发送完第四次挥手的确认报文后直接关闭，而这次报文又恰好丢失，则会造成服务端无法正常关闭。 TIME_WAIT和CLOSE_WAIT的区别在哪? CLOSE_WAIT是被动关闭形成的，当客户端发送FIN报文，服务端返回ACK报文后进入CLOSE_WAIT。 TIME__WAIT_是主动关闭形成的，当第四次挥手完成后，客户端进入TIME_WAIT状态 TCP中的timewait状态过多会怎样? 占用过多的系统资源,占用服务器端口,导致无法使用, 建立链接失败 解决timewait状态过多的方法 : 允许timewait状态的端口被重用 减小timewait的时长 客户端头部设置keep-alive 出现了大量的CLOSE_WAIT状态怎么解决? ​ 大量 CLOSE_WAIT 表示程序出现了问题，对方的 socket 已经关闭连接，而我方忙于读或写没有及时关闭连接，需 要检查代码，特别是释放资源的代码，或者是处理请求的线程配置。 为什么挥手需要四次? ​ 由于TCP的**半关闭(half-close)**造成的。半关闭是指：TCP提供了连接的一方在结束它的发送后还能接受来自另一端数据的能力。通俗来说，就是不能发送数据，但是还可以接受数据。 ​ 当服务端发送完数据后还需要向客户端发送释放连接请求，客户端返回确认报文，TCP连接彻底关闭。所以断开TCP连接需要客户端和服务端分别通知对方并分别收到确认报文，一共需要四次。 问题: 如果已经建立了TCP连接，但是客户端突然出现故障了怎么办？ ​ 如果TCP连接已经建立，在通信过程中，客户端突然故障，那么服务","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:6:1","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"UDP 数据结构 UDP的首部只有8个字节，源端口号、目的端口号、长度和校验和各两个字节。TCP和UDP对比 是否面向连接 可靠性 传输形式 传输效率 资源消耗 应用场景 首部字节 TCP 是 可靠 字节流 慢 多 文件/邮件传输 20-60 UDP 否 不可靠 数据报文段 快 少 语音/视频 8 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:6:2","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"[网络层]ARP协议 ​ 主要作用是实现从IP地址转换为MAC地址。 ​ 网络层实现的是主机之间的通信，而链路层实现的是链路之间的通信，所以从下图可以看出，在数据传输过程中，IP数据报的源地址(IP1)和目的地址(IP2)是一直不变的，而MAC地址(硬件地址)却一直随着链路的改变而改变。ARP的工作流程: 在局域网内，主机A要向主机B发送IP数据报时，首先会在主机A的ARP缓存表中查找是否有IP地址及其对应的MAC地址，如果有，则将MAC地址写入到MAC帧的首部，并通过局域网将该MAC帧发送到MAC地址所在的主机B。 如果主机A的ARP缓存表中没有主机B的IP地址及所对应的MAC地址，主机A会在局域网内广播发送一个ARP请求分组。局域网内的所有主机都会收到这个ARP请求分组。 主机B在看到主机A发送的ARP请求分组中有自己的IP地址，会向主机A以单播的方式发送一个带有自己MAC地址的响应分组。 主机A收到主机B的ARP响应分组后，会在ARP缓存表中写入主机B的IP地址及其IP地址对应的MAC地址。 如果主机A和主机B不在同一个局域网内，即使知道主机B的MAC地址也是不能直接通信的，必须通过路由器转发到主机B的局域网才可以通过主机B的MAC地址找到主机B。并且主机A和主机B已经可以通信的情况下，主机A的ARP缓存表中存的并不是主机B的IP地址及主机B的MAC地址，而是主机B的IP地址及该通信链路上的下一跳路由器的MAC地址。这就是上图中的源IP地址和目的IP地址一直不变，而MAC地址却随着链路的不同而改变。 如果主机A和主机B不在同一个局域网，参考上图中的主机H1和主机H2，这时主机H1需要先广播找到路由器R1的MAC地址，再由R1广播找到路由器R2的MAC地址，最后R2广播找到主机H2的MAC地址，建立起通信链路。 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:7:0","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"[网络层]IP协议 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:8:0","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"TCP分段和IP分片 分段分片的目的，都是为了能够传输上层交付的、数据量超过本层传输能力上限的数据，不得已才做的数据切分. ​ 最大传输单元(Maximum Transmission Unit)，即MTU，为数据链路层的最大载荷上限。 ​ 最大报文段长度(Maximum Segment Size)，即MSS，为TCP传输层的最大载荷上限(即应用层数据最大长度) MTU = MSS + TCP首部长度 + IP首部长度 分片发生在IP层，分段发生在tcp层 IP层分片的原因是mtu的限制，tcp层分段的原因是mss的限制 udp不进行分段会在ip层进行分片 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:8:1","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"有了IP地址，为什么还要用MAC地址？ ​ 标识网络中的一台计算机，比较常用的就是IP地址和MAC地址，但计算机的IP地址可由用户自行更改，管理起来相对困难，而MAC地址不可更改，所以一般会把IP地址和MAC地址组合起来使用。 ​ 随着网络中的设备越来越多，整个路由过程越来越复杂，便出现了子网的概念。对于目的地址在其他子网的数据包，路由只需要将数据包送到那个子网即可，这个过程就是上面说的ARP协议。 ​ 如果只是用MAC地址,路由器则需要记住每个MAC地址在哪个子网，这需要路由器有极大的存储空间，是无法实现的。如果只是用IP地址,没办法标志多个子网中唯一的设备. ​ IP地址可以比作为地址，MAC地址为收件人，在一次通信过程中，两者是缺一不可的 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:8:2","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"[网络层]ICMP协议 ​ 网络层协议，主要是实现 IP 协议中未实现的部分功能，是一种网络层协议。该协议并不传输数据，只传输控制信息来辅助网络层通信. 应用: ping ping的作用是测试两个主机的连通性。工作过程: 向目的主机发送多个ICMP回送请求报文 根据目的主机返回的回送报文的时间和成功响应的次数估算出数据包往返时间及丢包率。 TraceRoute ​ 其主要用来跟踪一个分组从源点耗费最少 TTL 到达目的地的路径。TraceRoute 通过逐渐增大 TTL 值并重复发送数据报来实现其功能.(TTL, Time To live生存时间) 首先，TraceRoute 会发送一个 TTL 为 1 的 IP 数据报到目的地，当路径上的第一个路由器收到这个数据报时，它将 TTL 的值减 1，此时 TTL = 0，所以路由器会将这个数据报丢掉，并返回一个差错报告报文， 之后源主机会接着发送一个 TTL 为 2 的数据报，并重复此过程，直到数据报能够刚好到达目的主机。此时 TTL = 0，因此目的主机要向源主机发送 ICMP 终点不可达差错报告报文，之后源主机便知道了到达目的主机所经过的路由器 IP 地址以及到达每个路由器的往返时间。 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:9:0","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"JWT ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:10:0","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"Session、Cookie和Token的主要区别 Cookie ​ Cookie是保存在客户端一个小数据块，其中包含了用户信息。当客户端向服务端发起请求，服务端会像客户端浏览器发送一个Cookie，客户端会把Cookie存起来，当下次客户端再次请求服务端时，会携带上这个Cookie，服务端会通过这个Cookie来确定身份。 Session ​ Session是通过Cookie实现的，和Cookie不同的是，Session是存在服务端的。当客户端浏览器第一次访问服务器时，服务器会为浏览器创建一个sessionid，将sessionid放到Cookie中，存在客户端浏览器。比如浏览器访问的是购物网站，将一本《图解HTTP》放到了购物车，当浏览器再次访问服务器时，服务器会取出Cookie中的sessionid，并根据sessionid获取会话中的存储的信息，确认浏览器的身份是上次将《图解HTTP》放入到购物车那个用户。 Token ​ 客户端在浏览器第一次访问服务端时，服务端生成的一串字符串作为Token发给客户端浏览器，下次浏览器在访问服务端时携带token即可无需验证用户名和密码，省下来大量的资源开销。 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:10:1","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"客户端禁止 cookie 能实现 session 还能用吗 ​ 可以，Session的作用是在服务端来保持状态，通过sessionid来进行确认身份，但sessionid一般是通过Cookie来进行传递的。如果Cooike被禁用了，可以通过在URL中传递sessionid。 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:10:2","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"NAT ​ NAT（Network Address Translation），即网络地址转换，它是一种把内部私有网络地址翻译成公有网络 IP 地址的技术。 ​ 该技术不仅能解决 IP 地址不足的问题，而且还能隐藏和保护网络内部主机，从而避免来自外部网络的攻击。 NAT 的实现方式主要有三种： 静态转换：内部私有 IP 地址和公有 IP 地址是一对一的关系，并且不会发生改变。通过静态转换，可以实现外部网络对内部网络特定设备的访问，这种方式原理简单，但当某一共有 IP 地址被占用时，跟这个 IP 绑定的内部主机将无法访问 Internet。 动态转换：采用动态转换的方式时，私有 IP 地址每次转化成的公有 IP 地址是不唯一的。当私有 IP 地址被授权访问 Internet 时会被随机转换成一个合法的公有 IP 地址。当 ISP 通过的合法 IP 地址数量略少于网络内部计算机数量时，可以采用这种方式。 端口多路复用：该方式将外出数据包的源端口进行端口转换，通过端口多路复用的方式，实现内部网络所有主机共享一个合法的外部 IP 地址进行 Internet 访问，从而最大限度地节约 IP 地址资源。同时，该方案可以隐藏内部网络中的主机，从而有效避免来自 Internet 的攻击。 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:11:0","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"URI 和URL的区别 URI(Uniform Resource Identifier)：中文全称为统一资源标志符，主要作用是唯一标识一个资源。 URL(Uniform Resource Location)：中文全称为统一资源定位符，主要作用是提供资源的路径。 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:12:0","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"路由器和交换机的区别？ 所属网络模型的层级 功能 路由器 网络层 识别IP地址并根据IP地址转发数据包，维护数据表并基于数据表进行最佳路径选择 交换机 数据链库层 识别MAC地址并根据MAC地址转发数据帧 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:13:0","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"在浏览器中输⼊url地址到显示主页的过程 对输入到浏览器的url进行DNS解析，将域名转换为IP地址。 和目的服务器建立TCP连接 向目的服务器发送HTTP请求 服务器处理请求并返回HTTP报文 浏览器解析并渲染页面 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:14:0","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"一个主机可以建立多少连接 客户端 ​ 每一个ip可建立的TCP连接理论受限于ip_local_port_range参数，也受限于65535。但可以通过配置多ip的方式来加大自己的建立连接的能力。 服务器 ​ 每一个监听的端口虽然理论值很大，但这个数字没有实际意义。最大并发数取决你的内存大小，每一条静止状态的TCP连接大约需要吃3.3K的内存 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:15:0","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"操作系统 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:0:0","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"进程管理 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:1:0","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"进程和线程 进程组成 进程控制块PCB，是进程存在的唯一标志，包含进程标识符PID，进程当前状态，程序和数据地址，进程优先级、CPU现场保护区(用于进程切换)，占有的资源清单等。 程序段 数据段 进程创建、终止 进程创建的方法 系统初始化（init） 正在运行的程序执行了创建进程的系统调用（比如 fork） 用户请求创建一个新进程 初始化一个批处理工作 进程终止的方法 正常退出：exit() 发生程序错误后退出(自愿的) 被其他进程杀死(如发送信号kill) 进程和线程的区别 ​ 一个线程只能属于一个进程，而一个进程可以有多个线程，但至少有一个线程。线程依赖于进程而 存在。 调度: 进程是资源管理的基本单位，线程是程序执行的基本单位 切换: 线程上下文切换比进程上下文切换要快得多 拥有资源:进程是拥有资源的一个独立单位，线程不拥有系统资源，但是可以访问隶属于进程的资源。 系统开销:创建或撤销进程时，系统都要为之分配或回收系统资源，如内存空间，I/O 设备等，OS所付出的 开销显著大于在创建(只有栈的开销)或撤销线程时的开销，进程切换的开销也远大于线程切换的开销。 ​ 左侧为进程中每个线程共享的内容，右侧为线程单独的内容 协程，进程，线程的区别 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:1:1","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"进程状态 ​ 进程一共有5 种状态，分别是创建、就绪、运行(执行)、终止、阻塞。 运行状态就是进程正在 CPU上运行。在单处理机环境下，每一时刻最多只有一个进程处于运行状态。 就绪状态就是说进程已处于准备运行的状态，即进程获得了除 CPU之外的一切所需资源，一旦得到 CPU即可 运行。 阻塞状态就是进程正在等待某一事件而暂停运行，比如等待某资源为可用或等待 I/O 完成。即使 CPU空闲， 该进程也不能运行。 运行态→阻塞态:往往是由于等待外设，等待主存等资源分配或等待人工干预而引起的。 阻塞态→就绪态:则是等待的条件已满足，只需分配到处理器后就能运行。 运行态→就绪态:不是由于自身原因，而是由外界原因使运行状态的进程让出处理器，这时候就变成就绪态。例如 时间片用完，或有更高优先级的进程来抢占处理器等。 就绪态→运行态:系统按某种策略选中就绪队列中的一个进程占用处理器，此时就变成了运行态。 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:1:2","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"进程和线程的切换流程 进程切换: 切换页表以使用新的地址空间，一旦去切换上下文，处理器中所有已经缓存的内存地址一瞬间都作废了。 切换内核栈和硬件上下文。 线程切换 ​ 线程切换时因为其共享所在进程的虚拟地址空间的, 所以不需要切换地址空间,只需要切换内核栈和上下文 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:1:3","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"为什么虚拟空间的切换特别耗时? ​ 进程都有自己的虚拟地址空间，把虚拟地址转换为物理地址需要查找页表，页表查找是一个很慢的过程，因此通常使用 Cache 来缓存常用的地址映射，这样可以加速页表查找，这个 Cache 就是 TLB(translation Lookaside Buffer， TLB本质上就是一个 Cache，是用来加速页表查找的),即快表. ​ 显然每个进程都有自己的页表，那么当进程切换后页表也要进行切换，页表切换后 TLB就失效了，Cache 失效导致命 中率降低，那么虚拟地址转换为物理地址就会变慢，表现出来的就是程序运行会变慢 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:1:4","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"进程通信方式 管道 (速度慢，容量有限;) 管道可以分为两类:匿名管道和命名管道。匿名管道是单向的，只能在有亲缘关系的进程间通信;命名管道FIFO以磁盘文件的方式存在，可以实现本机任意两个进程通信。 信号 常用信号: SIGHUP: 用户从终端注销，所有已启动进程都将收到该进程。系统缺省状态下对该信号的处理是终止进程。 SIGINT: 程序终止信号。程序运行过程中，按 Ctrl+C 键将产生该信号。 SIGQUIT:程序退出信号。程序运行过程中，按 Ctrl+\\键将产生该信号 SIGBUS和 SIGSEGV:进程 访问非法地址。 SIGKILL:用户终止进程执行信号。shell 下执行 kill -9 发送该信号。 信号量: 信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程 正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手 段。(不能传递复杂消息，只能用来同步;) 消息队列。 (容量受到系统限制，且要注意第一次读的时候，要考虑上一次没有读完数据的问题;) 共享内存:共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都 可以访问。共享内存是最快的 IPC 方式(能够很容易控制容量，速度快，但要保持同步) Socket: 不同机器间的进程间通信 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:1:5","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"进程间同步的方式 临界区 ​ 通过对多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问。 ​ 优点: 保证在某一时刻只有一个线程能访问数据的简便办法 ​ 缺点: 虽然然临界区同步速度很快，但却只能用来同步 本进程内的线程，而不可用来同步多个进程中的线程。 ​ ​ 冲突解决: 如果有若干进程要求进入空闲的临界区，一次仅允许一个进程进入，如已有进程进入自己的临界区，则其它所 有试图进入临界区的进程必须等待; 进入临界区的进程要在有限时间内退出。 如果进程不能进入自己的临界区，则应让出 CPU，避免进程出现“忙等”现象。 互斥量 ​ 互斥量跟临界区很相似，比临界区复杂，互斥对象只有一个，只 有拥有互斥对象的线程才具有访问资源的权限。 ​ 优点: 使用互斥不仅仅能够在同一应用程序不同线程中实现资源的 安全共享，而且可以在不同进程的线程之间实现对资源的安全共享。 ​ 缺点: 1. 消耗的资源较多 2. 只能针对一个资源进行同步访问,没办法计数 信号量 ​ 为控制一个具有有限数量用户资源而设计。它允许多个线程在同一时刻访问同一资源，但是需要限制在同 一时刻访问此资源的最大线程数目。互斥量是信号量的一种特殊情况，当信号量的最大资源数=1就是互斥量了。 ​ 优点: 适用于对 Socket(套接字)程序中线程的同步。 ​ 缺点: 1. 必须有公共内存，不能用于分布式操作系统，这是它最大的弱点; 2. 对信号量的操作分散，而且难以控制，读写和维护都很困难 ​ ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:1:6","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"线程同步方式 临界区: 当多个线程访问一个独占性共享资源时，可以使用临界区对象。拥有临界区的线程可以访问被保护起来的 资源或代码段，其他线程若想访问，则被挂起，直到拥有临界区的线程放弃临界区为止，以此达到用原子方式操作 共享资源的目的 事件机制: 事件机制，则允许一个线程在处理完一个任务后，主动唤醒另外一个线程执行任务 互斥量: 互斥对象和临 界区对象非常相似，只是其允许在进程间使用，而临界区只限制与同一进程的各个线程之间使用，但是更节省资 源，更有效率 信号量: 当需要一个计数器来限制可以使用某共享资源的线程数目时,可以使用信号量 a. 互斥量与临界区的作用非常相似，但互斥量是可以命名的，也就是说互斥量可以跨越进程使用，但创建互斥量需要的资源更多，所以如果只为了在进程内部是用的话使用临界区会带来速度上的优势并能够减少资源占用 量. b. 互斥量，信号量，事件都可以被跨越进程使用来进行同步数据操作。 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:1:7","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"死锁和死锁产生的条件 ​ 两个或者多个并发进程中，如果每个进程持有某种资源而又等待其它进程释放它或它们现在保持着 的资源，在未改变这种状态之前都不能向前推进，称这一组进程产生了死锁. 四个必要条件 互斥条件:一个资源一次只能被一个进程使用 请求与保持条件:一个进程因请求资源而阻塞时，对已获得资源保持不放 非抢占: 进程获得的资源，在未完全使用完之前，不能强行抢占 循环等待条件:若干进程之间形成一种头尾相接的环形等待资源关系 死锁问题解决: 资源一次性分配，这样就不会再有请求了(破坏请求条件)。 只要有一个资源得不到分配，也不给这个进程分配其他的资源(破坏占有并等待条件)。 可抢占资源:即当进程新的资源未得到满足时，释放已占有的资源，从而破坏不可抢占的条件。 资源有序分配法:系统给每类资源赋予一个序号，每个进程按编号递增的请求资源，释放则相反，从而破坏环路等待的条件 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:1:8","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"进程调度策略 先来先服务: 非抢占式的调度算法，按照请求的顺序进行调度。 ​ 有利于长作业，但不利于短作业，因为短作业 必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很⻓时间，造成了短作业等待时间过长。 另外，对 I/O 密集型进程也不利，因为这种进程每次进行 I/O 操作之后又得重新排队. ​ 短作业优先: 非抢占式的调度算法，按估计运行时间最短的顺序进行调度 ​ 长作业有可能会饿死，处于一直等 待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度 最短剩余时间优先: 最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度 ​ 当一个新的作业到达时， 其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。 时间片轮转: 将所有就绪进程按 FCFS的原则排成一个队列，每次调度时，把 CPU时间分配给队首进程，该进程可 以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU时间分配给队 首的进程。 ​ a. 时间片轮转算法的效率和时间片的大小有很大关系:因为进程切换都要保存进程的信息并且载入新进程的信 息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。而如果时间片过长，那么实时性就不能得到保证。 ​ b. 优先级调度:为每个进程分配一个优先级，按优先级进行调度。为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。 多级队列调度算法: 将系统中的进程就绪队列从一个拆分为若干个，将不同类型或性质的进程固定分配在不同的就绪队列，不同的就绪队列采用不同的调度算法，一个就绪队列中的进程可以设置不同的优先级，不同的就绪队列本身也可以设置不同的优先级。 多级反馈队列调度算法: 为就绪队列赋予不同的优先级数，不同的时间片，按照优先级抢占CPU的调度算法; 优先权越高，队列的时间片越小. 首先调度优先级高的队列中的进程。若高优先级中队列中已没有调度的进程，则调度次优先级队列中的进程 同一个队列中的各个进程，按照 时间片轮转法调度 在低优先级的队列中的进程在运行时，又有新到达的作业，那么在运行完这个时间片后，CPU马上分配给新到达的作业即抢占式调度CPU ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:1:9","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"孤儿进程和僵尸进程 孤儿进程: 父进程已退出，但子进程还在运行的这些子进程都是孤儿进程，孤儿进程将被init进程(1号进程)所收养，并由init进程对他们完成状态收集工作。 僵尸进程: 进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait 获waitpid 获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中的这些进程是僵尸进程。 危害:僵尸进程会占用系统资源, 没有回收导致内存泄漏 避免: 手动杀死父进程,让子进程变成孤儿进程由init进程回收; 严格回收子进程 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:1:10","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"IO多路复用 ​ IO多路复用是指内核一旦发现进程指定的一个或者多个 IO条件准备读取，它就通知该进程。 适用场景 当客户处理多个描述字时(一般是交互式输入和网络套接口)，必须使用 I/O 复用。 当一个客户同时处理多个套接口时，而这种情况是可能的，但很少出现。 如果一个 TCP服务器既要处理监听套接口，又要处理已连接套接口，一般也要用到 I/O 复用。 如果一个服务器即要处理 TCP，又要处理 UDP，一般要使用 I/O 复用。 如果一个服务器要处理多个服务或多个协议，一般要使用 I/O 复用。 与多进程和多线程技术相比，I/O 多路复用技术的最大优势是系统开销小，系统不必创建进程/线程，也不必 维护这些进程/线程，从而大大减小了系统的开销。 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:1:11","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"写时复制 如果进程从来就不需要修改资源，则不需要进行复制,每个进程只要保存一 个指向这个资源的指针就可以了。惰性算法的好处 就在于它们尽量推迟代价高昂的操作，直到必要的时刻才会去执行。 在使用虚拟内存的情况下，写时复制(Copy-On-Write)是以页为基础进行的。所以，只要进程不 修改它全部的地址空间，那么就不必复制整个地址空间。在fork()调用结束后，父进程和子进程都相信它们有一个自己的地址空间，但实际上它们共享父进程的原始页，接下来这些页又可以被其他的父进程或子进程共享。 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:1:12","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"中断 ​ 简单来说就是CPU停下当前的工作任务，去处理其他事情，处理完后回来继续执行刚才的任务，这一过程便是中断。 中断的处理过程**?** 保护现场:将当前执行程序的相关数据保存在寄存器中，然后入栈。 开中断:以便执行中断时能响应较高级别的中断请求。 中断处理 关中断:保证恢复现场时不被新中断打扰 恢复现场:从堆栈中按序取出程序数据，恢复中断前的执行状态。 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:1:13","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"优先级反转问题 ​ 由于多进程共享资源，具有最高优先权的进程被低优先级进程阻塞，反而使具有中优先级的进程先于高 优先级的进程执行，导致系统的崩溃。这就是所谓的优先级反转(Priority Inversion)。 ​ 解决: 优先级继承(priority inheritance) :是指将低优先级任务的优先级提升到等待它所占有的资 源的最高优先级任务的优先级.当高优先级任务由于等待资源而被阻塞时,此时资源的拥有者的优先 级将会自动被提升。 优先级天花板(priority ceilings):是指将申请某资源的任务的优先级提升到可能访问该资 源的所有任务中最高优先级任务的优先级 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:1:14","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"内存管理 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:2:0","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"1. 分页 ​ 把内存空间划分为大小相等且固定的块，作为主存的基本单位。因为程序数据存储在不同的页面中，而页面又离散的分布在内存中，因此需要一个页表来记录映射关系，以实现从页号到物理块号的映射。访问分页系统中内存数据 需要两次的内存访问(一次是从内存中访问页表，从中找到指定的物理块号，加上页内偏移得到实际物理地址;第二 次就是根据第一次得到的物理地址访问内存取出数据)。 ​ 分片是由于分段的粒度太大,容易产生大量外部碎片. 而且对于某一个段进行内存置换代价也过大,因此进行段页式内存管理. ​ 每个页为4KB, 如果要规避分段,只需要跟linux一样将每个段的首地址设置为0,这样寻址则从内存开始出寻址,跟没分段一样. 多级页表 一个进程的页表可能很大, 一次性加载到内存中会浪费空间, 因此产生了多级页表, 一次只加载所需要的页表,用于节省内存空间. 快表 快表（TLB）：提高变换速度→用高速缓冲存储器存放常用的页表项 MMU: 即内存管理单元，该硬件负责处理虚拟地址到物理地址的转化工作。快表也存储在MMU上。 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:2:1","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"2. 分段 ​ 分段是为了满足程序员在编写代码的时候的一些逻辑需求(比如数据共享，数据保 护，动态链接等)。分段内存管理当中，地址是二维的，一维是段号，二维是段内地址;由于分段管理中，每个段内部是连续内存分配，但是段和段之间是离散 分配的，因此也存在一个逻辑地址到物理地址的映射关系，相应的就是段表机制。 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:2:2","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"3. 分段分页的区别 分页对程序员是透明的，但是分段需要程序员显式划分每个段。 分页的地址空间是一维地址空间，分段是二维的。 页的大小不可变，段的大小可以动态改变。 分页主要用于实现虚拟内存，从而获得更大的地址空间;分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护。 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:2:3","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"4. 交换空间是什么 ​ 操作系统把物理内存(physical RAM)分成一块一块的小内存，每一块内存被称为页(page)。当内存资源不足时， Linux 把某些页的内容转移至硬盘上的一块空间上，以释放内存空间。硬盘上的那块空间叫做交换空间(swap space),而这一过程被称为交换(swapping)。物理内存和交换空间的总容量就是虚拟内存的可用容量。 ​ 用途: 物理内存不足时一些不常用的页可以被交换出去，腾给系统。 程序启动时很多内存页被用来初始化，之后便不再需要，可以交换出去。 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:2:4","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"5. 页面置换算法 ​ 在程序运行过程中，如果要访问的页面不在内存中，就发生缺页中断从而将该页调入内存中。此时如果内存已无空闲空间，系统必须从内存中调出一个页面到磁盘对换区中来腾出空间。 最佳算法:所选择的被换出的页面将是最长时间内不再被访问，通常可以保证获得最低的缺页率。这是一种理论上的算法，因为无法知道一个页面多长时间不再被访问。 (先进先出)FIFO: 思路:置换最先调入内存的页面，即置换在内存中驻留时间最久的页面。 实现:按照进入内存的先后次序排列成队列，从队尾进入，从队首删除。 特点:实现简单;性能较差，调出的页面可能是经常访问的 (最近最少使用)LRU: LRU将最近最久未使用的页面换出。 为了实现 LRU，需要在内存中维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。因为每次访问都需要更新链表，因此这种方式实现的 LRU代价很高。 特点:可能达到最优的效果，维护这样的访问链表开销比较大 时钟算法:时钟算法使用环形链表将页面连接起来，再使用一个指针指向最开始的页面。当需要进行页面置换时，时钟指针开始转动寻找可置换页面，直到遇到访问位为0的页号为止。在这个过程中，将遇到的访问位为1的页全部置为0.时钟指针寻找到要被置换的页面后，将新页放于那个位置。 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:2:5","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"6. 缓冲区 ​ 缓冲区又称为缓存，它是内存空间的一部分。也就是说，在内存空间中预留了一定的存储空间，这些存储空间用来缓冲输入或输出的数据，这部分预留的空间就叫做缓冲区 缓冲区溢出 冲区溢出是指当计算机向缓冲区填充数据时超出了缓冲区本身的容量，溢出的数据覆盖在合法数据上。 危害有以下两点: 程序崩溃，导致拒绝服务 跳转并且执行一段恶意代码造成缓冲区溢出的主要原因是程序中没有仔细检查用户输入 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:2:6","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"7. 虚拟内存 ​ 在操作系统中，进程是以页为单位加载到内存中的，按需分页是一种虚拟内存的管理方式。在使用请求分页的系统中，只有在尝试访问页面所在的磁盘并且该页面尚未在内存中时，也就发生了缺页异常，操作系统才会将磁盘页面复制到内存中。 虚拟内存就是说，让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。虚拟内存使用部分加载的技术，让一个进程或者资源的某些页面加载进内存，从而能够加载更多的进程，甚至能加载比内存大的进程，这样看起来好像内存变大了，这部分内存其实包含了磁盘或者硬盘，并且就叫做虚拟内存。 虚拟内存是一种对主存的抽象概念,其为每个进程提供了一个全物理内存的、一致的和私有的地址空间 虚拟内存主要能力: 它将主存看成是一个存储在磁盘上的地址空间的高速缓存，在主存中只保存活动区域，并根据需要 在磁盘和主存之间来回传送数据，通过这种方式，它高效地使用了主存。 操作系统为每个进程提供了一个独立的页表(一致的地址空间)，也就是独立的虚拟地 址空间。多个虚拟页面可以映射到同一个物理页面上。从而简化了内存管理。 它保护了每个进程的地址空间不被其他进程破坏。 为什么引入虚拟内存? 简化链接: 独立的地址空间允许每个进程的内存映像使用相同的基本格式，而不管代码和数据 实际存放在物理内存的何处 简化加载: 加载器从不在磁盘到内存实际复制任何数据，在每个页初次被引用时，虚拟内存系统会按照需要自动的调入数据页 简化共享: 一般来说, 每个进程有各自私有的代码，数据，堆栈，是不和其他进程共享的，这样OS创建页表，将虚拟页映射到不连续的物理页面。 某些情况下，需要进程来共享代码和数据。例如每个进程调用相同的操作系统内核代码， 或者C标准库函数。OS会把不同进程中适当的虚拟页面映射到相同的物理页面。 简化内存分配: 虚拟地址转换到物理地址的过程 ​ 虚拟地址由虚拟页号和页偏移两部分组成。通过虚拟地址的页面号，首先在快表中查询是否有该映射，查询成功，在页表中找到该页对应的物理地址。然后通过页物理地址+页偏移，得到真实的物理地址 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:2:7","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"8. 内存分配和回收 ​ 为了防止内存碎片，把所有的空闲页框分组为11个块链表，每个块链表分别包含大小为1，2，4，8，16，32，64，128，256，512和1024个连续页框的页框块。 ​ 假设要申请一个256个页框的块，先从256个页框的链表中查找空闲块，如果没有，就去512个页框的链表中找，找到了则将页框块分为2个256个页框的块，一个分配给应用，另外一个移到256个页框的链表中。如果512个页框的链表中仍没有空闲块，继续向1024个页框的链表查找，如果仍然没有，则返回错误。页框块在释放时，会主动将两个连续的页框块合并为一个较大的页框块。 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:2:8","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"系统管理 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:3:0","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"1. 内核态和用户态切换 系统调用: 系统调用是操作系统的最小功能单位，是操作系统提供的用户接口，系统调用本身是一种软中断. 异常: 也叫做内中断，是由错误引起的，如文件损坏、缺页故障等。 外部中断: 是通过两根信号线来通知处理器外设的状态变化，是硬中断。 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:3:1","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"2. 内核态和用户态的区别 处于内核态的进程可以访问系统的所有数据，并且cpu不会发生抢占。 处于用户态的进程只能受限得访问内存，并且cpu会被抢占。 操作系统从用户态跳转到内核态 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:3:2","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"3. OS启动过程 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:3:3","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"4. 系统调用 调用 说明 pid = fork() 创建与父进程相同的子进程 pid = waitpid(pid, \u0026statloc,options) 等待一个子进程终止 s = execve(name,argv,environp) 替换一个进程的核心映像 exit(status) 终止进程执行并返回状态 fork()， 它创建一个原有进程的副本，包括所有的文件描述符、寄存器等内容。fork 调用会返回一个值，在子进程中该值为 0 ，并且在父进程中等于子进程的 进程标识符(Process IDentified,PID)。使用返回的 PID，就可以看出来哪个是父进程和子进程。 waitpid：为了等待子进程完成，父进程需要执行 waitpid 系统调用，父进程会等待直至子进程终止（若有多个子进程的话，则直至任何一个子进程终止）。waitpid 可以等待一个特定的子进程，或者通过将第一个参数设为 -1 的方式，等待任何一个比较老的子进程。 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:3:4","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"Linux ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:0:0","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"基础命令 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:0","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"1. 怎么查看当前进程？怎么执行退出？怎么查看当前路径？ ​ 查看当前进程：ps、执行退出：exit、查看当前路径：pwd ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:1","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"2. 查看当前用户id [root@cx-ali ~]# id uid=0(root) gid=0(root) groups=0(root) # 用户id、组id、所属附加群组的id ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:2","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"3. 建立软链接和硬链接 ln -s src dist ln src dist 硬链接就是在目录下创建一个条目，记录着文件名与 inode 编号，这个 inode 就是源文件的 inode。删除任 意一个条目，文件还是存在，只要引用数量不为0。但是硬链接有限制，它不能跨越文件系统，也不能对目录 进行链接。 软链接又叫符号链接文件, 保存着源文件所在的绝对路径，在读取时会定位到源文件上，可以理解为 Windows的快捷方 式。当源文件被删除了，链接文件就打不开了。因为记录的是路径，所以可以为目录建立符号链接。 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:3","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"4. 查看文件命令 vi filename #编辑方式查看，可修改 cat filename #显示全部文件内容 more filename #分页显示文件内容 less filename #与 more 相似，更好的是可以往前翻页 tail filename #仅查看尾部，还可以指定行数 head filename #仅查看头部,还可以指定行数 # 一页一页查看大文件命令 cat filename | more ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:4","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"5.统计文件内容命令 [root@cx-ali ~]# wc -c -l -w .viminfo 47 148 770 .viminfo # -c 统计字节数 -l 统计行数 -w 统计字数 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:5","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"6. grep搜索命令 grep -i \"error\" #忽略大小写区分 grep -v \"grep\" #忽略grep命令本身，在文档中过滤掉包含有grep字符的行 grep [^string] filename #正则表达式搜索 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:6","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"7. 后台运行命令 ​ 使用 \u0026 在命令结尾来让程序自动运行。 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:7","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"8. 查看所有进程 ps -ef # system v 输出 ps -aux # bsd 格式输出 ps -ef | grep pid ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:8","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"9. 查看后台任务 jobs -l ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:9","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"10. 把后台任务调到前台执行使用什么命令?把停下的后台任务在后台执行起来用什么命令? fg # 把后台任务调到前台执行 bg # 把停下的后台任务在后台执行起来 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:10","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"11. 终止进程用什么命令? # kill [-s \u003c信息名称或编号\u003e][程序] 或 kill [-l \u003c信息编号\u003e] kill -9 pid kill -l # 查看系统支持的所有信号 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:11","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"12. 搜索文件的命令 # find \u003c指定目录\u003e \u003c指定条件\u003e \u003c指定动作\u003e # find 直接搜索磁盘，较慢。 find / -name \"string*\" locate 只加文件名 whereis # whereis [-bfmsu][-B \u003c目录\u003e...][-M \u003c目录\u003e...][-S \u003c目录\u003e...][文件...] #-b 只查找二进制文件。 #-B\u003c目录\u003e 只在设置的目录下查找二进制文件。-f 不显示文件名前的路径名称。 #-m 只查找说明文件。 #-M\u003c目录\u003e 只在设置的目录下查找说明文件。-s 只查找原始代码文件。 #-S\u003c目录\u003e 只在设置的目录下查找原始代码文件。-u 查找不包含指定类型的文件。 #which 指令会在 PATH 变量指定的路径中，搜索某个系统命令的位置，并且返回第一个搜索结果。 #-n 指定文件名长度，指定的长度必须大于或等于所有文件中最长的文件名。 #-p 与-n 参数相同，但此处的包括了文件的路径。-w 指定输出时栏位的宽度。 #-V 显示版本信息 #which 只能查可执行文件 #whereis 只能查二进制文件、说明文档，源文件等 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:12","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"13. 使用什么命令查看磁盘使用空间？ [root@cx-ali ~]# df -hl Filesystem Size Used Avail Use% Mounted on # 文件系统 容量 已用 可用 已用% 挂载点 devtmpfs 1.8G 0 1.8G 0% /dev # du 和 df 的定义，以及区别？ # du 显示目录或文件的大小 # df 显示每个\u003c文件\u003e所在的文件系统的信息，默认是显示所有文件系统。 # df 命令获得真正的文件系统数据，而 du 命令只查看文件系统的部分情况。 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:13","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"14. 查看网络 netstat netstat -nlpt # 查看tcp的网络信息 # 查看端口占用 lsof -i:port netstat -tunlp|grep port ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:14","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"15. 对命令取别名 alias la='ls -a' ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:15","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"16. awk cat /etc/passwd |awk -F ':' '{print $1\"\\t\"$7}' # -F 的意思是以':'分隔 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:16","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"17. 列出所有支持的命令 compgen -c ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:17","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"18. 不重启机器的条件下，有什么方法可以把所有正在运行的进程移除呢？ disown -r ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:18","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"19. 定时任务 crontab [-u username]　#省略用户表表示操作当前用户的crontab -e (编辑工作表) -l (列出工作表里的命令) -r (删除工作作) # 实例 * * * * * myCommand # 每分钟执行 3,15 8-11 * * * myCommand # 在上午8点到11点的第3和第15分钟执行 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:19","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"20. 查看路由表 route -n nestat -rn ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:20","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"21. 查看系统资源占用 top # top 命令 第一行 — 任务队列信息: top - 20:45:10 up 10:08, 1 user, load average: 0.00, 0.01, 0.05 内容 意义 20:45:10 当前时间 up 10:08 系统运行时间（10小时08分钟） 1 user 当前登录用户数 load average: 0.00, 0.01, 0.05 系统负载（任务队列的平均长度），分别是1分钟、5分钟、15分钟到现在的平均值 第二行 — 进程信息: Tasks: 105 total, 1 running, 104 sleeping, 0 stopped, 0 zombie 内容 意义 105 total 进程总数 1 running 正在运行的进程数 104 sleeping 睡眠进程数 0 stopped 停止进程数 0 zombie 僵尸进程数 第三行 — CPU信息: Cpu(s): 0.0%us, 0.1%sy, 0.0%ni, 99.9%id, 0.0%wa, 0.0%hi, 0.0%si, 0.0%st 内容 意义 0.0%us 用户空间占CPU百分比 0.1%sy 内核空间占CPU百分比 0.0%ni 用户进程空间内改变过优先级的进程占用CPU百分比 99.9%id 空闲CPU百分比 0.0%wa 等待输入输出的CPU时间百分比 0.0%hi 硬件中断占CPU时间百分比 0.0%si 软件终端占CPU时间百分比 0.0%st 提供给虚拟化环境执行占CPU时间百分比 第四行 — 内存信息: Mem: 288428k total, 257956k used, 30472k free, 40160k buffers 内容 意义 288428k total 物理内存总量 257956k used 使用的物理内存总量 30472k free 空闲内存总量 40160k buffers 用作内核缓存的内存量 第五行 — 内存交换区信息: Swap: 1046524k total, 3856k used, 1042668k free, 82000k cached 内容 意义 1046524k total 交换区总容量 3856k used 使用交换区的总量 1042668k free 空闲交换区总量 82000k cached 缓冲交换区总量 进程信息: PID 进程ID S 进程状态 USER 进程所有者用户名 %CPU CPU 时间占用百分比 PR 优先级 %MEM 进程使用物理内存百分比 NI nice值,负数表示高优先级 TIME+ 进程使用的CPU时间总计 VIRT 进程使用虚拟内存总量（以KB为单位） VIRT=SWAP+RES COMMAND 命令名/命令行 RES 进程使用的未被换出的物理内存大小（以KB为单位） RES=CODE+DATA SHR 共享内存总大小 lsof ​ lsof表示文件列表，我们可以知道哪个进程打开了哪个文件。 查看系统负载 [root@cx-ali ~]# w 12:57:02 up 27 days, 22:54, 1 user, load average: 0.01, 0.02, 0.05 USER TTY FROM LOGIN@ IDLE JCPU PCPU WHAT root pts/0 113.246.112.27 11:35 6.00s 0.06s 0.00s w [root@cx-ali ~]# uptime 12:57:34 up 27 days, 22:55, 1 user, load average: 0.00, 0.02, 0.05 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:21","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"22. 查看物理CPU和CPU核数 cat /proc/cpuinfo|grep -c 'physical id' # CPU数 cat /proc/cpuinfo|grep -c 'processor' # 核数 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:22","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"23. 查看内存信息 [root@centos6 ~ 10:57 #39]# vmstat procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 0 0 0 1783964 13172 106056 0 0 29 7 15 11 0 0 99 0 0 [root@cx-ali ~]# free -m total used free shared buff/cache available Mem: 3733516 1493136 196568 616 2043812 1960704 Swap: 0 # cat /proc/meminfo r即running，表示正在跑的任务数; b即blocked，表示被阻塞的任务数; si表示有多少数据从交换分区读入内存; so表示有多少数据从内存写入交换分区; bi表示有多少数据从磁盘读入内存; bo表示有多少数据从内存写入磁盘 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:23","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"24.网络修改 编辑/etc/sysconfig/network-scripts/ifcft-eth0 文件。重启网络服务service network restart 给一个网卡配置多个ip, 新建一个ifcfg-eth0:1文件,将DEVICE名称改为eth0:1 ,修改ip,重启网络服务即可 在文件 /etc/resolv.conf 中设置DNS ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:24","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"系统管理 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:2:0","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"1. 终端是哪个文件夹下的哪个文件？黑洞文件是哪个文件夹下的哪个命令？ 终端 /dev/tty 黑洞文件 /dev/null ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:2:1","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"2. Linux 中进程有哪几种状态？在 ps 显示出来的信息中，分别用什么符号表示的？ (D)不可中断状态：进程处于睡眠状态，但是此刻进程是不可中断的。不可中断， 指进程不响应异步信号.() (T)停止状态/跟踪状态：向进程发送一个 SIGSTOP 信号，它就会因响应该信号 而进入 TASK_STOPPED 状态;当进程正在被跟踪时，它处于 TASK_TRACED 这个特殊的状态。“正在被跟踪”指的是进程暂停下来，等待跟踪它的进程对它进行操作 就绪状态： (R)运行状态：在 run_queue 队列里的状态 (S)可中断睡眠状态：处于这个状态的进程因为等待某某事件的发生（比如等待 socket 连接、等待信号量），而被挂起 (Z)僵尸 状态：父亲没有通过 wait 系列的系统调用会顺便将子进程的尸体（task_struct）也释放掉 (X)退出状态 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:2:2","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"3. 进程管理 父子进程通信 父进程通过使用管道，套接字，消息队列等与子进程进行通信。 僵尸进程 这是一个执行已完成但进程表中甚至存在信息的进程。由于父进程需要读取子进程的状态，因此发生在父进程中。一旦使用wait系统调用完成了该任务，则僵尸进程将从进程表中删除。这被称为僵尸进程。 异步和非阻塞的区别 异步:调用在发出之后，这个调用就直接返回，不管有无结果;异步是过程。 非阻塞:关注的是程序在等待调用结果(消息，返回值)时的状态，指在不能立刻得到结果之前，该调用不会阻塞当前线程。 进程状态 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:2:3","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"4. 内存管理 buffer和cache如何区分? ​ **Cache是加速“读”，**而buffer是缓冲“写 ​ buffer和cache都是内存中的一块区域，当需要写数据到磁盘时，由于磁盘速度比较慢，所以CPU先把数据存进buffer，然后CPU去执行其他任务，buffer中的数据会定期写入磁盘；当需要从磁盘读入数据时，由于磁盘速度比较慢，可以把即将用到的数据提前存入cache，CPU直接从Cache中拿数据要快的多。 Swap空间 交换空间的主要功能是当全部的 RAM 被占用并且需要更多内存时，用磁盘空间代替 RAM 内存。Linux 计算机中的内存总量是 RAM + 交换分区，交换分区被称为虚拟内存. 内存数据段 预留内存地址（操作系统维护的内存地址，不可访问） 代码段（codesegment/textsegment）：又称文本段，用来存放指令，运行代码的一块内存空间，此空间大小在代码运行前就已经确定。 数据段（datasegment）：可读可写，存储初始化的全局变量和初始化的 static 变量。 bss段（bsssegment）：可读可写，存储未初始化的全局变量和未初始化的 static 变量。 rodata段：只读数据，常量区 栈（stack）：可读可写，存储的是函数或代码中的局部变量(非 static 变量)。 堆（heap）：可读可写，存储的是程序运行期间动态分配的 malloc/realloc 的空间。 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:2:4","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"源码和原理分析 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:3:0","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"1. 进程和线程API 进程API 线程API 描述 fork pthread_create 创建新的控制流 exit pthread_exit 从现有的控制流中退出 waitpid pthread_join 从控制流中得到退出状态 atexit pthread_cancel_push 注册在退出控制流时调用的函数 getpid pthread_self 获取控制流的ID abort pthread_cancel 请求控制流的非正常退出 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:3:1","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"2. select、poll、epoll原理 ​ IO 多路复用的本质是通过一种机制，让单个进程可以监视多个描述符，当发现某个描述符就绪之后，能够通知程序进行相应的读写操作。 ​ select，poll，epoll 都是同步 IO。所谓同步 IO，便是读写是阻塞的，需要在读写事件就绪后自己负责读写，而异步 IO 会把数据从内核拷贝到用户空间，并不需要自己负责读写。 select: ​ 遍历监听的fd_set（1024位的bitmap数组存储） ​ 调用 select 函数时，内核会根据 IO 状态对 fd_set 的内容进行修改，从而通知执行 select 函数的进程哪一个文件或者 Socket 是可读的。select 函数与同步阻塞模型并无过多区别，甚至还多出了一部分操作（监视 socket /调用 select 函数），导致更低的效率。 优点：用户可以在一个线程内同时处理多个 socket 的 IO 请求。用户可以注册多个 socket，然后调用 select 函数读取被激活的 socket，从而实现在同一个线程内同时处理多个 IO 请求，在这点上select 函数与同步阻塞模型不同，因为在同步阻塞模型中需要通过多线程才能达到这个目的。 缺点： 调用 select 函数时，需要把 fd__set_ 集合从用户态拷贝到内核态，当 fd_set 集合很大时，这个开销将会非常巨大 调用 select 函数时，需要在内核遍历传递进来的所有 fd__set_，当 fd_set 集合很大时，这个开销将会非常巨大 内核对被监控的 fd_set 集合大小做了限制 poll ​ 就是对fd_set（链表存储）没有1024的限制了 epoll ​ epoll采用IO多路复用技术,采用事件回调的方式，可以非常高效的处理数以百万计的Socket句柄. ​ epoll 使用一个文件描述符管理多个描述符，它将文件描述符的事件放入内核的一个事件表中，从而在用户空间和内核空间的复制操作只用实行一次即可。 ​ 在获取事件时，epoll 无需遍历整个被监听的描述符集，而是只需遍历被内核 IO 事件异步唤醒而加入 Ready 队列的描述符集合即可。因此，epoll 能显著提高程序在大量并发连接中只有少量活跃的情况下的系统 CPU 利用率。 核心数据结构 ​ epoll的核心数据结构在于红黑树+双向链表 首先调用epoll_create时内核帮我们在epoll文件系统里建了个file结点. 在内核cache里建立红黑树用于存储以后epoll_ctl传来的socket，当有新的socket连接来时，先遍历红黑书中有没有这个socket存在，如果有就立即返回，没有就插入红黑数 然后给内核中断处理程序注册一个钩子函数，每当有事件发生时就通过钩子函数把这些文件描述符放到用来存储就绪事件的链表中。 epoll_wait并不监听文件句柄，而是等待就绪链表不空or收到信号or超时这三种条件后返回。 优点: 没有最大并发连接的限制 不采取轮询的方式，效率高，只会处理活跃的连接，与连接总数无关 select、poll、epoll 总结对比 效率: select 只知道有 IO 事件发生，却不知道是哪几个流，只能采取轮询所有流的方式，故其具有 O(n) 的无差别轮询复杂度，处理的流越多，无差别轮询时间就越长 poll 与 select 并无区别，它的时间复杂度也是 O(n) epoll 会将哪个流发生了怎样的 IO 事件通知我们（当描述符就绪时，系统注册的回调函数会被调用，将就绪描述符放到 readyList 里面），它是事件驱动的，其时间复杂度为 O(1) 操作方式: select 和 poll 都是采取遍历的方式，而 epoll 则是采取了回调的方式 底层实现 select 的底层实现为数组，poll 的底层实现为链表，而 epoll 的底层实现为红黑树 最大链接 select 的最大连接数为 1024 或 2048，而 poll 和 epoll 是无上限的 对文件描述符的拷贝 select 和 poll 每次被调用时都会把描述符集合从用户态拷贝到内核态 epoll 在调用 epoll_ctl 时会拷贝进内核并保存，之后每次 epoll_wait 时不会拷贝 性能 epoll 在绝大多数情况下性能远超 select 和 poll，但在连接数少并且连接都十分活跃的情况下，select 和 poll 的性能可能比 epoll 好，因为 epoll 的通知机制需要很多函数回调 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:3:2","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"3. 编译 编译过程 预处理阶段：处理以 # 开头的预处理命令； 编译阶段：翻译成汇编文件； 汇编阶段：将汇编文件翻译成可重定位目标文件； 链接阶段：将可重定位目标文件和 printf.o 等单独预编译好的目标文件进行合并，得到最终的可执行目标文件。 动态链接和静态链接的过程 静态链接 符号解析：每个符号对应于一个函数、一个全局变量或一个静态变量，符号解析的目的是将每个符号引用与一个符号定义关联起来。 重定位：链接器通过把每个符号定义与一个内存位置关联起来，然后修改所有对这些符号的引用，使得它们指向这个内存位置。 将所有需要的二进制代码都包含到可执行文件中. 动态链接 在给定的文件系统中一个库只有一个文件，所有引用该库的可执行目标文件都共享这个文件，它不会被复制到引用它的可执行文件中； 在内存中，一个共享库的 .text 节（已编译程序的机器代码）的一个副本可以被不同的正在运行的进程共享。 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:3:3","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"Golang ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:0:0","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"基础数据结构 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:0","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"1. go的指针和c的指针 ​ 相同点: ​ 运算符相同, \u0026为取地址, *为解引用 ​ 不同点: 数组名和数组首地址. c语言中arr、\u0026arr[0]为数组的首个元素地址,单位偏移量为元素大小; \u0026arr为数组的首地址,单位偏移量为数组大小. golang中\u0026arr[0]和\u0026arr与c语言中相同, 但是arr表示为整个数组的值. // C int arr[5] = {1, 2, 3, 4, 5}; // Go // 需要指定长度，否则类型为切片 arr := [5]int{1, 2, 3, 4, 5} 指针运算. c语言中指针本质为无符号整数,代表内存地址, 可以进行加减运算. Golang中指针为 *uint32类型非数字,不可以加减运算. Go 标准库中提供了一个 unsafe 包用于编译阶段绕过 Go 语言的类型系统，直接操作内存 uintptr : Go 的内置类型。是一个无符号整数，用来存储地址，支持数学运算。常与 unsafe.Pointer 配合做指针运算 unsafe.Pointer : 表示指向任意类型的指针，可以和任何类型的指针互相转换（类似 C 语言中的 void* 类型的指针），也可以和 uintptr 互相转换 unsafe.Sizeof : 返回操作数在内存中的字节大小，参数可以是任意类型的表达式，例如 fmt.Println(unsafe.Sizeof(uint32(0)))的结果为 4 unsafe.Offsetof : 函数的参数必须是一个字段 x.f，然后返回 f 字段相对于 x 起始地址的偏移量，用于计算结构体成员的偏移量 golang中不能被寻址的类型:(不可变的，临时结果和不安全的。) 常量、字符串、函数或方法、map中的元素… ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:1","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"2. String的底层结构 type StringHeader struct { // 16 字节 Data uintptr Len int } 本质为byte类型的数组 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:2","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"3.slice和array的区别和底层结构 ​ array 为定长数组, slice为不定长数组 底层结构 type slice struct { array unsafe.Pointer // array指针指向底层array的某一个元素，其决定slice所能控制的内存片段的起始位置，这里需要注意的是，array不一定指向底层array的首元素，这与slice的创建有关。 len int //len 代表当前切片的长度,限定slice可直接通过索引(下标)存取元素的范围 cap int // cap 是当前切片的容量,表示slice所引用的array片段的真实大小 } // slice 扩张: slice扩容规则是：在1024字节以内，扩容一倍，大于1024时，增加cap的1/4 初始化方式: // 数组 // 切片 a := [3]int{1,2,3} //指定长度 s := make([]int, 3) //指定长度 a := [...]int{1,2,3} //不指定长度 s := []int{1,2,3} //不指定长度 函数传递 当切片和数组作为参数在函数（func）中传递时，数组传递的是值，而切片传递的是指针。因此当传入的切片在函数中被改变时，函数外的切片也会同时改变。相同的情况，函数外的数组则不会发生任何变化。 nil切片和空切片最大的区别在于指向的数组引用地址是不一样的 所有的空切片指向的数组引用地址都是一样的 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:3","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"4. Map底层结构 用于存储一系列无序的键值对,hashmap作为底层实现 Map基本数据结构: // hashmap的简称 type hmap struct { count int //元素个数 flags uint8 //标记位 B uint8 //buckets的对数, 说明包含2^B个bucket noverflow uint16 //溢出的bucket的个数 hash0 uint32 //hash种子 buckets unsafe.Pointer //指向buckets数组的指针，数组个数为2^B oldbuckets unsafe.Pointer //扩容时使用，buckets长度是oldbuckets的两倍 nevacuate uintptr //扩容进度，小于此地址的buckets已经迁移完成 extra *mapextra //扩展信息 } //当map的key和value都不是指针，并且size都小于128字节的情况下，会把 bmap 标记为不含指针，这样可以避免gc时扫描整个hmap。但是，我们看bmap其实有一个overflow的字段，是指针类型的，破坏了bmap不含指针的设想，这时会把overflow移动到extra字段来。 type mapextra struct { overflow *[]*bmap oldoverflow *[]*bmap //用于扩容 nextOverflow *bmapx //prealloc的地址 } // bucket type bmap struct { tophash [bucketCnt]uint8 //bucketCnt = 8,用于记录8个key哈希值的高8位，这样在寻找对应key的时候可以更快，不必每次都对key做全等判断 // keys [8]keytype // values [8]valuetype // pad uintptr // overflow uintptr } ​ hmap结构图 如何扩容 ​ 触发条件: 1. 装填因子大于6.5(装填因子为2^B); 2. overflow bucket 太多 ​ 解决办法: 双倍扩容:扩容采取了一种称为“渐进式”地方式，原有的 key 并不会一次性搬迁完毕，每次最多只会搬迁2 个 bucket.(条件1) 等量扩容:重新排列，极端情况下，重新排列也解决不了，map成了链表，性能大大降低，此时哈希种子 hash0 的设置，可以降低此类极端场景的发生。(条件2) 赋值操作 在查找key之前，会做异常检测，校验map是否未初始化，或正在并发写操作，如果存在，则抛出异常：（这就是为什么map 并发写回panic的原因） 需要计算key 对应的hash 值，如果buckets 为空（初始化的时候小于一定长度的map 不会初始化数据）还需要初始化一个bucket 通过hash 值，获取对应的bucket。如果map 还在迁移数据，还需要在oldbuckets中找对应的bucket，并搬迁到新的bucket。 拿到bucket之后，还需要按照链表方式一个一个查，找到对应的key， 可能是已经存在的key，也可能需要新增。 插入数据前，会先检查数据太多了，需要扩容，如果需要扩容，那就从第③开始拿到新的bucket，并查找对应的位置。 如果没有空的位置，那就需要在链表后追加一个bucket，拿到kv 最后更新tophash 和 key 的字面值, 并解除hashWriting 约束 数据迁移 先要判断当前bucket是不是已经转移。 (oldbucket 标识需要搬迁的bucket 对应的位置) 如果没有被转移，那就要迁移数据了。数据迁移时，可能是迁移到大小相同的buckets上，也可能迁移到2倍大的buckets上。这里xy 都是标记目标迁移位置的标记：x 标识的是迁移到相同的位置，y 标识的是迁移到2倍大的位置上。 确定bucket位置后，需要按照kv 一条一条做迁移。（目的就是清除空闲的kv） 数据查找 ​ Go语言中 map采用的是哈希查找表，由一个 key 通过哈希函数得到哈希值，64 位系统中就生成一个64bit 的哈希值，由这个哈希值将 key 对应到不同的桶bucket中，当有多个哈希映射到相同的的桶中时，使用链表解决哈希冲突。key 经过 hash 后共64 位，根 据 hmap中 B的值，计算它到底要落在哪个桶时，桶的数量为2^B，如 B=5，那么用64 位最后5 位表示第几号桶，在用 hash 值的高8 位确定在 bucket 中的存储位置，当前 bmap中的 bucket 未找到，则查询对应的 overflow bucket，对应位置有数据则对比完整的哈希值，确定是否是要查找的数据。如果两个不同的 key 落在的同一个桶上，hash 冲突使用链表法接近，遍历 bucket 中的 key ;如果当前处于 map进 行了扩容，处于数据搬移状态，则优先从 oldbuckets 查找。 根据key计算出hash值。 如果存在old table, 首先在old table中查找，如果找到的bucket已经evacuated，转到步骤3。 反之，返回其对应的value。 在new table中查找对应的value。 map 顺序读取方法 ​ 给key排序后读取 set实现 map[string]bool //会有bool的空间占用，可以替换成空结构体 type void struct{} var member void set := make(map[string]void) set[\"test\"] = member ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:4","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"5. Channel 底层结构 type hchan struct { qcount uint // 队列中的数据个数 dataqsiz uint // 环形队列的大小，channel本身是一个环形队列 buf unsafe.Pointer // 存放实际数据的指针，用unsafe.Pointer存放地址，为了避免gc elemsize uint16 closed uint32 // 标识channel是否关闭 elemtype *_type // 数据 元素类型 sendx uint // send的 index recvx uint // recv 的 index recvq waitq // 阻塞在 recv 的队列 sendq waitq // 阻塞在 send 的队列 lock mutex // 锁 } channel本身是一个环形缓冲区，数据存放到堆上面，channel的同步是通过锁实现的，并不是想象中的lock-free的方式，channel中有两个队列，一个是发送阻塞队列，一个是接收阻塞队列。当向一个已满的channel发送数据会被阻塞，此时发送协程会被添加到sendq中，同理，当向一个空的channel接收数据时，接收协程也会被阻塞，被置入recvq中。 ​ 创建channel 缓冲区大小为0: 只需要分配hchansize大小的内存就ok; 缓冲区大小不为0，且channel的类型不包含指针: buf为hchanSize+元素大小*元素个数的连续内存 缓冲区大小不为0，且channel的类型包含指针，则不能简单的根据元素的大小去申请内存，需要通过mallocgc去分配内存(即内存逃逸) channel特性 \u003e 1. 给一个 nil channel 发送数据，造成永远阻塞 从一个 nil channel 接收数据，造成永远阻塞 关闭一个 nil channel 将会发生 panic 给一个已经关闭的 channel 发送数据，引起 panic 当 c.closed != 0 则为通道关闭，此时执行写，源码提示直接 panic，输出的内容就是上面提到的 \"send on closed channel\"。 从一个已经关闭的 channel 接收数据，如果缓冲区中为空，则返回一个零值 c.closed != 0 \u0026\u0026 c.qcount == 0 指通道已经关闭，且缓存为空的情况下（已经读完了之前写到通道里的值） 如果接收值的地址 ep 不为空 那接收值将获得是一个该类型的零值 typedmemclr 会根据类型清理相应地址的内存 这就解释了上面代码为什么关闭的 chan 会返回对应类型的零值 无缓冲的 channel 是同步的，而有缓冲的 channel 是非同步的 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:5","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"6. interface // interface 分为空接口和非空接口，分别用eface 和 iface实现。 // eface type eface struct { _type *_type data unsafe.Pointer //指向数据的数据指针 } //_type 定义 type _type struct { size uintptr // 类型的大小 ptrdata uintptr // size of memory prefix holding all pointers hash uint32 // 类型的Hash值 tflag tflag // 类型的Tags align uint8 // 结构体内对齐 fieldalign uint8 // 结构体作为field时的对齐 kind uint8 // 类型编号 定义于runtime/typekind.go alg *typeAlg // 类型元方法 存储hash和equal两个操作。map key便使用key的_type.alg.hash(k)获取hash值 gcdata *byte // GC相关信息 str nameOff // 类型名字的偏移 ptrToThis typeOff } // iface type iface struct { tab *itab data unsafe.Pointer } // 非空接口的类型信息 type itab struct { inter *interfacetype // 接口定义的类型信息 _type *_type // 接口实际指向值的类型信息 link *itab bad int32 inhash int32 fun [1]uintptr // 接口方法实现列表，即函数地址列表，按字典序排序 } // 非空接口类型，接口定义，包路径等。 type interfacetype struct { typ _type pkgpath name mhdr []imethod // 接口方法声明列表，按字典序排序 } // 接口的方法声明 type imethod struct { name nameOff // 方法名 ityp typeOff // 描述方法参数返回值等细节 } 非空interface与eface不同的，所有空interface的结构是一样的，而非空interface每个都不一样，因为彼此定义的方法可以不一样的，所以相对eface，iface的定义复杂多。 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:6","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"7. reflect t := reflect.TypeOf(stru).Elem() for i := 0; i \u003c t.NumField(); i++ { // 获取Tag t.Field(i).Name, t.Field(i).Tag.Get(\"json\"), t.Field(i).Tag.Get(\"otherTag\") } //reflect.TypeOf(stru).Elem()获取指针指向的值对应的结构体内容。 //NumField()可以获得该结构体的含有几个字段。 //遍历结构体内的字段，通过t.Field(i).Tag.Get(\"json\")可以获取到tag为json的字段。 json包里不能导出私有变量的tag是因为json包里认为私有变量为不可导出的Unexported，所以跳过获取名为json的tag的内容 动态类型判断: 类型开关是在运行时检查变量类型的最佳方式 //1. 类型识别 var data interface{} = \"hello\" strValue, ok := data.(string) if ok { fmt.Printf(\"%s is string type\\n\", strValue) } //2. 类型获取 var str string = \"hello\" fmt.Println(reflect.TypeOf(str)) //3. 类型判断 func typeJudge(x interface{}) { switch x.(type){ case int,int8,int64,int16,int32,uint,uint8,uint16,uint32,uint64: fmt.Println(\"整型变量\") case float32,float64: fmt.Println(\"浮点型变量\") case []byte,[]rune,string: fmt.Println(\"字符串变量\") default: fmt.Println(\"不清楚...\") } } ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:7","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"8. new 和make的区别 new(T) 返回的是 T 的指针：new(T) 为一个 T 类型新值分配空间并将此空间初始化为 T 的零值，返回的是新值的地址，也就是 T 类型的指针 *T，该指针指向 T 的新分配的零值。 make 只能用于 slice,map,channel，返回值是经过初始化之后的 T 的引用 make 分配空间后，会进行初始化 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:8","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"9.struct能不能比较 ​ go中的struct能不能比较取决于struct内部存储的数据，如果struct中的字段都是可比较的，那么该struct就是可比较的，如果其中的字段是不可比较的，那么该struct不可比较。slice,map就无法比较。 struct字段顺序要一致才能比较 数组的长度是类型的一部分，如果数组长度不同，无法比较。 interface{}类型的比较包含该接口变量存储的值和值的类型两部分组成，分别称为接口的动态类型和动态值。只有动态类型和动态值都相同时，两个接口变量才相同。 slice在go设计之初为了和数组区分，不让其可以比较（浅层指针比较没有意义） 1、引用类型，比较地址没有意义。 2、切片有len，cap，比较的维度不好衡量，因此go设计的时候就不允许切片可比较。 3、map的value, 函数均可以包含slice,因而均不可比较 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:9","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"10. defer defer关键字定义的函数是在调用函数返回之后执行，而不是在代码块退出之后执行。defer的执行顺序是先创建的后执行。看做是一个 FILO(First In Last Out) 栈. 所有传入defer函数的参数都是在创建的时候预先计算处理的，而不是调用函数退出的时候计算的 defer等到包含它的程序返回时(包含它的函数执行了return语句、运行到函数结尾自动返回、对应的goroutine panic）defer函数才会被执行。通常用于资源释放、打印日志、异常捕获等 defer 关键字对应的 runtime.deferproc 会将延迟调用函数与调用方所在 Goroutine 进行关联。所以当程序发生崩溃时只会调用当前 Goroutine 的延迟调用函数 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:10","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"11. init函数 整个golang程序初始化顺序 先调用osinit，再调用schedinit，创建就绪队列并新建一个G，接着就是mstart 即设置好本地线程存储，设置好main函数参数，根据环境变量GOMAXPROCS设置好使用的procs，初始化调度器和内存管理等等。 main.main之前的准备 sysmon :Go语言的runtime库会初始化一些后台任务，其中一个任务就是sysmon. 它由物理线程运行.主要处理两个事件：对于网络的epoll以及抢占式调度的检测. 释放闲置超过5 分钟的 span 物理内存; 如果超过2 分钟没有垃圾回收，强制执行; 将长时间未处理的 netpoll 添加到全局队列; 向长时间运行的 G 任务发出抢占调度(超过10ms的 g，会进行 retake); 收回因 syscall 长时间阻塞的 P; scavenger: 只是由goroutine运行.用于执行heap的内存回收给os ​ 先于main函数执行，实现包级别的一些初始化操作 ​ 主要作用: 初始化不能采用初始化表达式初始化的变量; 程序运行前的注册 实现sync.Once功能 ​ 主要特点: init函数先于main函数自动执行，不能被其他函数调用； init函数没有输入参数、返回值； 每个包可以有多个init函数； 包的每个源文件也可以有多个init函数，这点比较特殊； 同一个包的init执行顺序，golang没有明确定义，编程时要注意程序不要依赖这个执行顺序 不同包的init函数按照包导入的依赖关系决定执行顺序 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:11","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"12.包的循环引用 为什么不允许循环引用 ​ 加快编译速度、规范框架设计，使项目结构更加清晰明了 解决办法: 1. mvc 结构,将包规划好 1. 新建公共接口包(父包), 将需要循环调用的函数或方法抽象为接口 1. 新建公共组合包(子包), 在组合包中组合调用 1. 全局存储需要相互依赖的函数, 通过关键字进行调用 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:12","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"13. SELECT select可以用来等待多个channel的可读可写，其中select中的case表达式必须都是channel的读写操作。 当存在default时，select执行的就是非阻塞收发，当不存在时，必须等待某一个channel可读或可写。 当多个channel都可读可写时，会随机选择一个分支。 如果有一个channel已关闭,则每次都执行到这个case; 如果只有一个case,则出现死循环. var c1, c2, c3 chan int var i1, i2 int select { case i1 = \u003c-c1: fmt.Printf(\"received \", i1, \" from c1\\n\") case c2 \u003c- i2: fmt.Printf(\"sent \", i2, \" to c2\\n\") case i3, ok := (\u003c-c3): // same as: i3, ok := \u003c-c3 if ok { fmt.Printf(\"received \", i3, \" from c3\\n\") } else { fmt.Printf(\"c3 is closed\\n\") } default: fmt.Printf(\"no communication\\n\") } x, ok := \u003c-ch,如果ch已经关闭,则ok为false,置ch为nil,则可以继续阻塞. 保证case的优先级 for { select { case \u003c-stopCh: return case job1 := \u003c-ch1: fmt.Println(job1) case job2 := \u003c-ch2: priority: // label for { select { case job1 := \u003c-ch1: fmt.Println(job1) default: break priority } } fmt.Println(job2) } } ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:13","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"14. for range 循环 { for_temp := slice1 len_temp := len(for_temp) for index_temp := 0; index_temp \u003c len_temp; index_temp++ { value_temp := for_temp[index_temp] // index = index_temp // value = value_temp // origin body } } // 新的语句块结束 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:14","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"15. Panic和Recover panic ​ panic的作用是制造一次宕机，宕机就代表程序运行终止，但是已经“生效”的(当前 Goroutine )延迟函数仍会执行（即已经压入栈的defer延迟函数，panic之前的）。 // 嵌套崩溃 func main() { defer fmt.Println(\"in main\") defer func() { defer func() { panic(\"panic again and again\") }() panic(\"panic again\") }() panic(\"panic once\") } $ go run main.go in main panic: panic once panic: panic again panic: panic again and again goroutine 1 [running]: ... exit status 2 recover ​ recover 只有在发生 panic 之后调用才会生效。然而在上面的控制流中，recover 是在 panic 之前调用的，并不满足生效的条件，所以需要在 defer 中使用 recover 关键字。 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:15","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"16. golang函数调用规则 通过堆栈传递参数，入栈的顺序是从右到左，而参数的计算是从左到右 函数返回值通过堆栈传递并由调用者预先分配内存空间； 调用函数时都是传值，接收方会对入参进行复制再计算； ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:16","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"17. go相比于c++线程的优势 开销更小 切换更方便 C线程的上下文切换涉及到模式转换-从用户态到内核态 go的协程中的上下文切换只是在用户态的操作 用户可控制（用户态） 高级调度策略: 任务窃取和减少阻塞 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:17","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"进阶原理 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:2:0","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"1. GMP模型和golang调度原理 ​ go中调度采用GMP算法，G表示一个goroutine，M表示machine一个真实的线程，P表示processor表示一个调度器 P由启动时环境变量 $GOMAXPROCS 或者是由 runtime 的方法 GOMAXPROCS() 决定。这意味着在程序执行的任意时刻都只有 $GOMAXPROCS 个 goroutine 在同时运行。最大256 M的最大限制是10000个，但是内核很难支持这么多的线程数，所以这个限制可以忽略; 一般为CPU数 在P没有足够的M绑定运行时,则会创建一个M;每次创建一个M都会同步创建一个G0，它负责调度其它的G，每个M都有一个G0 每个 P有个局部队列，局部队列保存待执行的 goroutine(流程2)，当 M绑定的 P的的局部队列已经满了之后就 会把 goroutine 放到全局队列(流程2-1) 每个 P和一个 M绑定，M是真正的执行 P中 goroutine 的实体(流程3)，M 从绑定的 P中的局部队列获取 G来 执行 当 M绑定的 P的局部队列为空时，M会从全局队列获取到本地队列来执行 G(流程3.1)，当从全局队列中没有获取到可执行的 G时候，M会从其他 P 的局部队列中偷取 G来执行(流程3.2)，这种从其他 P偷的方式称为 work stealing 当 G因系统调用(syscall)阻塞时会阻塞 M，此时 P会和 M解绑即 hand off，并寻找新的 idle 的 M，若没有 idle 的 M就会新建一个 M(流程5.1)。 当 G因 channel 或者 network I/O 阻塞时，不会阻塞 M，M会寻找其他 runnable 的 G;当阻塞的 G恢复后会重新进入 runnable 进入 P队列等待执行(流程5.3) Work stealing ​ 当本线程无可运行的 G 时，尝试从其他线程绑定的 P 偷取 G，而不是销毁线程。 Hand off 本线程因为 G 进行系统调用阻塞时，线程释放绑定的 P，把 P 转移给其他空闲的线程执行。 利用并行：GOMAXPROCS 设置 P 的数量，最多有 GOMAXPROCS 个线程分布在多个 CPU 上同时运行。GOMAXPROCS 也限制了并发的程度，比如 GOMAXPROCS = 核数/2，则最多利用了一半的 CPU 核进行并行。 抢占：在 coroutine 中要等待一个协程主动让出 CPU 才执行下一个…在 Go 中，一个 goroutine 最多占用 CPU 10ms，防止其他 goroutine 被饿死，这就是 goroutine 不同于 coroutine 的一个地方。 如果没有P或怎样? 调度器把 G都分配到 M上，不同的 G在不同的 M并发运行时，都需要向系统申请资源，比如堆栈内存等，因为资源 是全局的，就会因为资源竞争照成很多性能损耗。 GMP 调度过程中存在哪些阻塞 I/O, select block on syscall channel 等待锁 runtime.Gosched() 抢占式调度 sysmon。这个函数会周期性地做epoll操作，同时它还会检测每个P是否运行了较长时间。如果检测到某个P状态处于syscall超过了一个sysmon的时间周期(20us)，并且还有其它可运行的任务，则切换P。 如果检测到某个P的状态为running，并且它已经运行了超过10ms，则会将P的当前的G的stackguard设置为StackPreempt。这个操作其实是相当于加上一个标记，通知这个G在合适时机进行调度。 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:2:1","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"2. 垃圾回收(GC) 垃圾回收常用方法 1. 引用计数(reference counting) ​ 如C++中的智能指针:shard_ptr; 优点：简单直接，回收速度快 缺点：需要额外的空间存放计数，无法处理循环引用的情况； 标记-清除(mark and sweep) ​ 标记出所有不需要回收的对象，在标记完成后统一回收掉所有未被标记的对象。 优点：简单直接，速度快，适合可回收对象不多的场景 缺点：会造成不连续的内存空间（内存碎片），导致有大的对象创建的时候，明明内存中总内存是够的，但是空间不是连续的造成对象无法分配； 分代搜集(generation) ​ java的jvm 就使用的分代回收的思路。在面向对象编程语言中，绝大多数对象的生命周期都非常短。分代收集的基 本思想是，将堆划分为两个或多个称为代(generation)的空间。新创建的对象存放在称为新生代(young generation)中(一般来说，新生代的大小会比 老年代小很多)，随着垃圾回收的重复执行，生命周期较⻓的对 象会被提升(promotion)到老年代中(这里用到了一个分类的思路，这个是也是科学思考的一个基本思路)。 ​ 因此，新生代垃圾回收和老年代垃圾回收两种不同的垃圾回收方式应运而生，分别用于对各自空间中的对象执行垃 圾回收。新生代垃圾回收的速度非常快，比老年代快几个数量级，即使新生代垃圾回收的频率更高，执行效率也仍 然比老年代垃圾回收强，这是因为大多数对象的生命周期都很短，根本无需提升到老年代。 GOLANG的GC策略 ​ golang采用无分代（对象没有代际之分）、不整理（回收过程中不对对象进行移动与整理）、并发（与用户代码并发执行）的三色标记清扫算法。 ​ 原因: golang的内存分配算法tcmalloc，基本上不会造成内存碎片，因此不需要使用对象整理。 golang对于存活时间短的对象直接分配在栈上面，go程死亡后栈会被回收，不需要gc的参与。 Go 以 STW 为界限，可以将 GC 划分为五个阶段：：栈扫描（开始时STW）;第一次标记（并发）;第二次标记（STW）;清除（并发）,归还 三色标记清扫法 white，grep，black;白色为需要清理的数据，黑色则不要清理。从根对象（全局变量、执行栈、寄存器(主要是指针)）开始循环，能访问到的标记为灰色，然后从灰色队列开始遍历，自身变成黑色。后续没有访问到的直接清理掉。 没有STW的三色标记法 条件1: 一个白色对象被黑色对象引用 (白色被挂在黑色下) 条件2: 灰色对象与它之间的可达关系的白色对象遭到破坏 (灰色同时丢了该白色) 当以上两个条件同时满足时, 就会出现对象丢失现象! 屏障保护 为了减少STW的影响,又防止三色标记法出现对象丢失现象,出现屏障保护技术; 插入写屏障 ​ 垃圾收集器将根对象指向 A 对象标记成黑色并将 A 对象指向的对象 B 标记成灰色；用户程序修改 A 对象的指针，将原本指向 B 对象的指针指向 C 对象，这时触发写屏障将 C 对象标记成灰色；一种相对保守的屏障技术，它会将有存活可能的对象都标记成灰色以满足强三色不变性. ​ 写屏障只会针对堆进行限制. 删除写屏障 ​ 垃圾收集器将根对象指向 A 对象标记成黑色并将 A 对象指向的对象 B 标记成灰色；用户程序将 A 对象原本指向 B 的指针指向 C，触发删除写屏障，但是因为 B 对象已经是灰色的，所以不做改变；用户程序将 B 对象原本指向 C 的指针删除，触发删除写屏障，白色的 C 对象被涂成灰色； ​ 缺点是开始收集器时需要STW快照全局对象 混合写屏障 操作流程: ​ 1、GC开始将栈上的对象全部扫描并标记为黑色(之后不再进行第二次重复扫描，无需STW)， ​ 2、GC期间，任何在栈上创建的新对象，均为黑色。 ​ 3、被删除的对象标记为灰色。(删除写屏障) ​ 4、被添加的对象标记为灰色。(插入写屏障) 该写屏障会将被覆盖的对象标记成灰色并在当前栈没有扫描时将新对象也标记成灰色; 只需要针对堆内存扫描即可. GC触发机制 主动: 通过调用 runtime.GC 来触发 GC，此调用阻塞式地等待当前 GC 运行完毕。 被动: 使用系统监控(sysmon)，当超过两分钟没有产生任何 GC 时，强制触发 GC。 使用步调（Pacing）算法，其核心思想是控制内存增长的比例。(步调算法可以通过gogc传参设置量控制gc的时间。也是go中唯一对外开放的配置gc的参数。默认值为100，也就是达到百分百后触发gc机制) GC细节 增量垃圾收集 ​ 增量地标记和清除垃圾，降低应用程序暂停的最长时间； ​ 传统的垃圾收集算法会在垃圾收集的执行期间暂停应用程序，一旦触发垃圾收集，垃圾收集器会抢占 CPU 的使用权占据大量的计算资源以完成标记和清除工作，然而很多追求实时的应用程序无法接受长时间的 STW。增量式（Incremental）的垃圾收集是减少程序最长暂停时间的一种方案，它可以将原本时间较长的暂停时间切分成多个更小的 GC 时间片，虽然从垃圾收集开始到结束的时间更长了，但是这也减少了应用程序暂停的最大时间。 并发垃圾收集 ​ 利用多核的计算资源，在用户程序执行时并发标记和清除垃圾； GC 如何调优 通过 go tool pprof 和 go tool trace 等工具 控制内存分配的速度，限制 goroutine 的数量，从而提高赋值器对 CPU 的利用率。 减少并复用内存，例如使用 sync.Pool 来复用需要频繁创建临时对象，例如提前分配足够的内存来降低多余的 拷贝。 需要时，增大 GOGC 的值，降低 GC 的运行频率。 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:2:2","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"3. 内存模型和内存管理 内存逃逸 ​ golang程序变量会携带有一组校验数据，用来证明它的整个生命周期是否在运行时完全可知。如果变量通过了这些校验，它就可以在栈上分配。否则就说它 逃逸 了，必须在堆上分配 内存逃逸的情况: 在方法内把局部变量指针返回 发送指针或带有指针的值到 channel 中 在一个切片上存储指针或带指针的值 slice 的背后数组被重新分配了，因为 append 时可能会超出其容量( cap );slice 初始化的地方在编译时是可以知道的，它最开始会在栈上分配。如果切片背后的存储要基于运行时的数据进行扩充，就会在堆上分配。 **在 interface 类型上调用方法。**在 interface 类型上调用方法都是动态调度的 —— 方法的真正实现只能在运行时知道。 查看内存逃逸的情况: go build -gcflags=-m main.go 避免内存逃逸 Noescape函数, 可以在逃逸分析中隐藏一个指针。让这个指针在逃逸分析中不会被检测为逃逸。 func noescape(p unsafe.Pointer) unsafe.Pointer { x := uintptr(p) return unsafe.Pointer(x ^ 0) } noescape() 函数的作用是遮蔽输入和输出的依赖关系。使编译器不认为 p 会通过 x 逃逸， 因为 uintptr() 产生的引用是编译器无法理解的。 内置的 uintptr 类型是一个真正的指针类型，但是在编译器层面，它只是一个存储一个 指针地址 的 int 类型。代码的最后一行返回 unsafe.Pointer 也是一个 int。 闭包 闭包是由函数及其相关引用环境组合而成的实体(即：闭包=函数+引用环境)。 func f(i int) func() int { return func() int { i++ return i } } 不可在栈上分配: 变量i是函数f中的局部变量，假设这个变量是在函数f的栈中分配的，是不可以的。因为函数f返回以后，对应的栈就失效了，f返回的那个函数中变量i就引用一个失效的位置了。所以闭包的环境中引用的变量不能够在栈上分配。 因此以上代码在汇编中就类似于: type Closure struct { F func()() i *int } 在堆中创建结构体, 将函数地址赋值给F, 闭包环境的局部变量在堆上开辟空间,写值后再将地址赋值给i; 返回闭包时并不是单纯返回一个函数，而是返回了一个结构体，记录下函数返回地址和引用的环境中的变量地址 栈空间管理 ​ Go语言的运行环境(runtime)会在goroutine需要的时候动态地分配栈空间，而不是给每个goroutine分配固定大小的内存空间。这样就避免了需要程序员来决定栈的大小。当创建一个goroutine的时候，它会分配一个8KB的内存空间来给goroutine的栈使用。 分段栈 ​ 当检测到函数需要更多栈时，分配一块新栈，旧栈和新栈使用指针连接起来，函数返回就释放。 每个Go函数的开头都有一小段检测代码。这段代码会检查我们是否已经用完了分配的栈空 间。如果是的话，它会调用 morestack 函数。 morestack 函数分配一块新的内存作为栈空间，并且在这块栈空间 的底部填入各种信息(包括之前的那块栈地址)。在分配了这块新的栈空间之后，它会重试刚才造成栈空间不足的函数。这个过程叫做栈分裂(stack split). 2. 在新分配的栈底有个lessstack的函数指针; 当我们从那个函数返回时，它会跳转到 lessstack 。 lessstack 函 数会查看在栈底部存放的数据结构里的信息，然后调整栈指针(stack pointer)。这样就完成了从新的栈块到老的 栈块的跳转。接下来，新分配的这个块栈空间就可以被释放掉了。 问题: 多次循环调用同一个函数会出现“hot split”问题, 即如果函数产生的返回在一个循环或者递归中, 会频繁的alloc/free,导致严重性能问题 每次分配和释放都要额外消耗 连续栈 连续栈的实现方式：当检测到需要更多栈时，分配一块比原来大一倍的栈，把旧栈数据copy到新栈，释放旧栈 栈的扩缩容何时触发? goroutine运行并用完栈空间的时候，与之前的方法一样，栈溢出检查会被 触发 栈的扩缩容大小 扩容为原来的两倍,缩容为原来的1/2 栈的扩缩容过程中做了哪些事? 重新申请一块新栈，然后把旧栈的数据复制到新栈。协程占用的物理内存完全被替换了，而Go在运行时会把指针保存到内存里面，例如：gp.sched.ctxt ，gp._defer ，gp._panic，包括函数里的指针。这部分指针值会被转换成整数型uintptr，然后 + delta进行调整 如果栈空间发现不够用，会调用stackalloc分配一块新的栈，大小比原来大一倍进行扩容 ;栈的缩容主要是发生在GC期间. 内存泄漏 字符串截取: 解决办法: string和[]byte 转化 切片截取 解决办法: append 没有重置丢失的子切片元素中的指针: 原切片元素为指针类型，原切片被截取后，丢失的子切片元素中的指针元素未被置空，导致内存泄漏 解决办法:元素置空 函数数组传参: 由于数组为值类型,赋值和函数传参会复制整个数组; 如果数组较大,短时间内传递多次,会消耗大量内存又来不及gc,就会产生临时性的内存泄漏 解决办法:采用指针传递、使用切片 gorouting :有些编码不当的情况下，goroutine被长期挂住，导致该协程中的内存也无法被释放，就会造成永久性的内存泄漏。例如协程结束时协程中的channel没有关闭，导致一直阻塞；例如协程中有死循环 可见并发和sync包的使用 定时器: 定时器未到触发时间，该定时器不会被gc回收，从而导致临时性的内存泄漏，而如果定时器一直在创建，那么就造成了永久性的内存泄漏了 解决办法:创建timer定时器，每次需要启动定时器的时候，使用Reset方法重置定时器 外部资源没有办法GC的: 如打开的文件句柄 内存泄漏实例 func main() { num := 6 for index := 0; index \u003c num; index++ { resp, _ := http.Get(\"https://www.baidu.com\") _, _ = ioutil.ReadAll(resp.Body) } fmt.Printf(\"此时goroutine个数= %d\\n\", runtime.NumGoroutine()) }// 没有执行resp.Body.Close(), 一共泄漏了3个goroutine 虽然执行了 6 次循环，而且每次都没有执行 Body.Close() ,就是因为执行了ioutil.ReadAll()把内容都读出来了，连接得以复用，因此只泄漏了一个读goroutine和一个写goroutine，最后加上main goroutine，所以答案就是3个goroutine 正常情况下我们的代码都会执行 ioutil.ReadAll()，但如果此时忘了 resp.Body.Close()，确实会导致泄漏。但如果你调用的域名一直是同一个的话，那么只会泄漏一个 读goroutine 和一个写goroutine，这就是为什么代码明明不规范但却看不到明显内存泄漏的原因。 内存对齐 一个非空结构体包含有尾部size为0的变量(字段)，如果不给它分配内存，那么该变量(字段)的指针地址将指向一个超出该结构体内存范围的内存空间。这可能会导致内存泄漏，或者在内存垃圾回收过程中，程序crash掉。 为什么对齐? 操作系统并非一个字节一个字节访问内存，而是按2, 4, 8这样的字长来访问。当被访问的数据长度为 n 字节且该数据地址为n字节对齐，那么操作系统就可以高效地一次定位到数据，无需多次读取、处理对齐运算等额外操作. struct 的对齐是：如果类型 t 的对齐保证是 n，那么类型 t 的每个值的地址在运行时必须是 n 的倍数。 struct 内字段如果填充过多，可以尝试重排，使字段排列更紧密，减少内存浪费 零大小字段要避免作为 struct 最后一个字段，会有内存浪费(零大小也会补一个对齐保证的长度,防止指针错误,内存泄漏) 对齐规则: 对于任意类型的变量 x ，unsafe.Alignof(x) 至少为 1。 对于 struct 结构体类型的变量 x，计算 x 每一个字段 f 的 unsafe.Alignof(x.f)，unsafe.Alignof(x) 等于其中的最大值。 对于 array 数组类型的变量 x，unsafe.Alignof(x) 等于构成数组的元素类型的对齐倍数。 没有任何字段的空 struct{} 和没有任何元素的 array 占据的内存空间大小为 0，不同的大小为 0 的变量可能指向同一块地址。 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:2:3","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"4. 并发和sync包 Data Race ​ 同步访问共享数据是处理数据竞争的一种有效的方法. 可以使用 go run - race 或者 go build -race来进行静态检测。其在内部的实现是,开启多个协程执行同一个命令， 并且记录下每个变 量的状态. go test -race mypkg // 测试包 go run -race mysrc.go // 编译和运行程序 go build -race mycmd // 构建程序 go install -race mypkg // 安装程序 解决数据竞争的方法: 互斥锁: sync.Mutex、sync.WaitGroup 通道: channel ,channel的效率是高于互斥锁的 并发模型 通过channel通知实现并发控制 通过sync包中的WaitGroup实现并发控制 a. Add(), 可以添加或减少 goroutine的数量. b. Done(), 相当于Add(-1). c. Wait(), 执行后会堵塞主线程，直到WaitGroup 里的值减至0. 注意,在 WaitGroup 第一次使用后，不能被拷贝 func main(){ wg := sync.WaitGroup{} for i := 0; i \u003c 5; i++ { wg.Add(1) go func(wg sync.WaitGroup, i int) { fmt.Printf(\"i:%d\", i) wg.Done() }(wg, i) } wg.Wait() fmt.Println(\"exit\") } // error: all goroutines are asleep - deadlock! 因为 wg 给拷⻉传递到了 goroutine 中，导致只有 Add 操作，其实 Done操作是在 wg 的副本执行的。 可以将 传入类型改为 *sync.WaitGroup, 或者使用闭包 Context 上下文 context 包主要是用来处理多个 goroutine 之间共享数据，及多个 goroutine 的管理。Context 对象是线程安全的，你可以把一个 Context 对象传递给任意个数的 gorotuine，对它执行取消 操作时， 所有 goroutine 都会接收到取消信号。 web编程中，一个请求对应多个goroutine之间的数据交互、同步数据，主要是共享数据，如token 超时控制：请求被取消或是处理时间太长，这有可能是使用者关闭了浏览器或是已经超过了请求方规定的超时时间，请求方直接放弃了这次请求结果。这时，所有正在为这个请求工作的 goroutine 需要快速退出，因为它们的“工作成果”不再被需要了。在相关联的 goroutine 都退出后，系统就可以回收相关的资源。 上下文控制 CAS Compare And Swap，直译就是比较交换;是一种实现并发算法时常用到的技术. 作用是让 CPU先进行比较两 个值是否相等，然后原子地更新某个位置的值，其实现方式是给予硬件平台的汇编指令， func CompareAndSwapUint32(addr *uint32, old, new uint32) (swapped bool) 缺陷: CAS在共享资源竞争比较激烈的时候，每个goroutine会容易处于自旋状态，影响效率，在竞争激烈的时候推荐使用锁。 无法解决ABA问题 ABA问题是无锁结构实现中常见的一种问题，可基本表述为： 进程P1读取了一个数值A P1被挂起(时间片耗尽、中断等)，进程P2开始执行 P2修改数值A为数值B，然后又修改回A P1被唤醒，比较后发现数值A没有变化，程序继续执行。 Sync包 互斥锁: sync.Mutex //Mutex 是互斥锁， 零值是解锁的互斥锁， 首次使用后不得复制互斥锁。 type Mutex struct { state int32 sema uint32 } //Locker表示可以锁定和解锁的对象。 type Locker interface { Lock() Unlock() } //锁定当前的互斥量 //如果锁已被使用，则调用goroutine //阻塞直到互斥锁可用。 func (m *Mutex) Lock() //对当前互斥量进行解锁 //如果在进入解锁时未锁定m，则为运行时错误。 //锁定的互斥锁与特定的goroutine无关。 //允许一个goroutine锁定Mutex然后安排另一个goroutine来解锁它。 func (m *Mutex) Unlock() Mutex的几种状态: mutexLocked —表示互斥锁的锁定状态; mutexWoken —表示从正常模式被从唤醒; mutexStarving —当前的互斥锁进入饥饿状态; Mutex的正常模式和饥饿模式: 正常模式**(**非公平锁): 正常模式下，所有等待锁的 goroutine 按照 FIFO(先进先出)顺序等待。唤醒的 goroutine 不会直接拥有锁，而是会 和新请求锁的 goroutine 竞争锁的拥有。但是和正在使用cpu的goroutine相比很大可能失败. 饥饿模式**(**公平锁): 一个等待的 goroutine 超过1ms没有获取锁,或者当前队列只剩下一个 g 的时候那么它将会把锁转 变为饥饿模式。 ​ 饥饿模式下，直接由 unlock 把锁交给等待队列中排在第一位的 G(队头)，同时，饥饿模式下，新进来的 G不会参与 抢锁也不会进入自旋状态，会直接进入等待队列的尾部,这样很好的解决了老的 g 一直抢不到锁的场景 自旋锁: 循环等待锁的释放,一直处于内核态,不进行内核态和用户态切换. 锁已被占用，并且锁不处于饥饿模式 积累的自旋次数小于最大自旋次数(active_spin=4)。 cpu 核数大于1。 有空闲的 P 当前 goroutine 所挂载的 P下，本地待运行队列为空。 ​ 读写锁: sync.RWMutex 1 多个写操作之间是互斥的 2 写操作与读操作之间也是互斥的 3 多个读操作之间不是互斥的 // RWMutex是一个读/写互斥锁，可以由任意数量的读操作或单个写操作持有。 // RWMutex的零值是未锁定的互斥锁。 //首次使用后，不得复制RWMutex。 //如果goroutine持有RWMutex进行读取而另一个goroutine可能会调用Lock，那么在释放初始读锁之前， goroutine不应该期望能够获取读锁定。 //特别是，这种禁止递归读锁定。 这是为了确保锁最终变得可用; 阻止的锁定会阻止新读操作获取锁定。 type RWMutex struct { w Mutex //如果有待处理的写操作就持有 uint32 writerSem int32 // 写操作等待读操作完成的信号量 readerSem uint32 //读操作等待写操作完成的信号量 readerCount int32 // 待处理的读操作数量 readerWait int32 // number of departing readers } //对读操作的锁定 func (rw *RWMutex) RLock() //对读操作的解锁 func (rw *RWMutex) RUnlock() //对写操作的锁定 func (rw *RWMutex) Lock() //对写操作的解锁 func (rw *RWMutex) Unlock() //返回一个实现了sync.Locker接口类型的值，实际上是回调rw.RLock and rw.RUnlock. func (rw *RWMutex) RLocker() Locker ​ 通过记录 readerCount 读锁的数量来进行控制，当有一个写锁的时候，会将读锁数量设置为负数1«30。目的是让 新进入的读锁等待写锁之后释放通知读锁。同样的写锁也会等等待之前的读锁都释放完毕，才会开始进行后续的操 作。而等写锁释放完之后，会将值重新加上1«30,并通知刚才新进入的读锁(rw.readerSem)，两者互相限制。 RWMutex 的读锁不要用于递归调用，比较容易产生死锁。 写锁被解锁后，所有因操作锁定读锁而被阻塞的 goroutine 会被唤醒，并都可以成功锁定读锁。 读锁被解锁后，在没有被其他读锁锁定的前提下，所有因操作锁定写锁而被阻塞的 goroutine，其中等待时间 最⻓的一个 goroutine 会被唤醒。 安全锁: Sync.Map golang中的sync.Map是并发安全的，其实也就是sync包中golang自定义的一个名叫Map的结构体。它通过空间换时间的方式，使用 read 和 dirty 两个 map 来进行读写分离，降低锁时间来提高效率。 type Map struct { mu Mutex // 该锁用来保护dirty read atomic.Value // readOnly// 存读的数据，因为是atomic.value类型，只读类型，所以它的读是并发安全的 dirty map[interface{}]*entry //包含最新的写入的数据，并且在写的时候，会把read中未被删除的数据拷⻉到该dirty中，因为是普通的map存在并发安全问题，需要用到上面的mu字段。 misses int // 从read读数据失败的时候，会将该字段+1，当等于len(misses)的时候，会将dirty拷⻉到read中(从而提升读的性能)。 } func (m *Map) Delete(key i","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:2:4","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"5. golang编译过程 go build -gcflags -S main.go 可以生成中间的汇编代码 词法分析：源码翻译成token（分词） 语法分析：将token序列输出成AST结构 词义分析： 类型检查（类型推断等） 中间码生产：对于不同的操作系统和硬件进行处理；提高后端编译的重用 代码优化： 并行性，充分利用现在多核计算机的特性 流水线，cpu 有时候在处理 a 指令的时候，还能同时处理 b 指令 指令的选择，为了让 cpu 完成某些操作，需要使用指令，但是不同的指令效率有非常大的差别，这里会进行指令优化 利用寄存器与高速缓存，我们都知道 cpu 从寄存器取是最快的，从高速缓存取次之。这里会进行充分的利用 机器码生产： 先生成汇编代码，其汇编器使用GOARCH参数进行初始化，然后调用对应架构便携的特定方法来生成机器码，从而跨平台。 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:2:5","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"}]