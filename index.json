[{"categories":[],"content":"计算机网络 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:0:0","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"为什么要对网络协议分层？ ​ 网络协议是计算机在通信过程中要遵循的一些约定好的规则。 ​ 网络分层的原因： 易于实现和维护，因为各层之间是独立的，层与层之间不会收到影响。 有利于标准化的制定 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:1:0","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"路由器和交换机的区别？ ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:2:0","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"协议模型 OSI七层协议模型包括: 应用-表示-会话-传输-网络-数据链路-物理层 五层协议模型包括: 应用-传输-网络-数据链路-物理层 物理层 ​ 主要解决两台物理机之间的通信，通过二进制比特流的传输来实现，二进制数据表现为电流电压上的强弱，到达目的地再转化为二进制机器码。网卡、集线器工作在这一层。 数据链路层 ​ 在不可靠的物理介质上提供可靠的传输，接收来自物理层的位流形式的数据，并封装成帧，传送到上一层;同样，也将来自上层的数据帧，拆装为位流形式的数据转发到物理层。这一层在物理层提供的比特流的基础上，通过差错控制、流量控制方法，使有差错的物理线路变为无差错的数据链路。提供物理地址寻址功能。交换机工作在这一层。 网络层 ​ 将网络地址翻译成对应的物理地址，并决定如何将数据从发送方路由到接收方，通过路由选择算法为分组通过通信子网选择最佳路径。路由器工作在这一层。常见的协议有IP协议，ARP协议、ICMP协议。 传输层 ​ 传输层提供了进程间的逻辑通信，传输层向高层用户屏蔽了下面网络层的核心细节，使应用程序看起来像是在两个传输层实体之间有一条端到端的逻辑通信信道。主要协议为TCP、UDP协议 会话层 建立会话:身份验证，权限鉴定等; 保持会话:对该会话进行维护，在会话维持期间两者可以随时使用这条会话传输数据; 断开会话:当应用程序或应用层规定的超时时间到期后，OSI会话层才会释放这条会话。 表示层 ​ 对数据格式进行编译，对收到或发出的数据根据应用层的特征进行处理，如处理为文字、图片、音频、视频、文档等，还可以对压缩文件进行解压缩、对加密文件进行解密等。 应用层 ​ 应用层的任务是通过应用进程之间的交互来完成特定的网络作用，常见的应用层协议有DNS，HTTP、FTP协议等。 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:3:0","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"[应用层]HTTP协议 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:4:0","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"HTTP 状态码 类别 描述 1xx 信息性状态码 2xx 成功状态码 3xx 重定向状态码 4xx 客户端错误状态码 5xx 服务端错误状态码 1xx 100 Continue：表示正常，客户端可以继续发送请求 101 Switching Protocols：切换协议，服务器根据客户端的请求切换协议。 2xx 200 OK：请求成功 201 Created：已创建，表示成功请求并创建了新的资源 202 Accepted：已接受，已接受请求，但未处理完成。 204 No Content：无内容，服务器成功处理，但未返回内容。 205 Reset Content：重置内容，服务器处理成功，客户端应重置文档视图。 206 Partial Content：表示客户端进行了范围请求，响应报文应包含Content-Range指定范围的实体内容 3xx 301 Moved Permanently：永久性重定向 302 Found：临时重定向 303 See Other：和301功能类似，但要求客户端采用get方法获取资源 304 Not Modified：所请求的资源未修改，服务器返回此状态码时，不会返回任何资源。 305 Use Proxy：所请求的资源必须通过代理访问 307 Temporary Redirect： 临时重定向，与302类似，要求使用get请求重定向。 4xx 400 Bad Request：客户端请求的语法错误，服务器无法理解。 401 Unauthorized：表示发送的请求需要有认证信息。 403 Forbidden：服务器理解用户的请求，但是拒绝执行该请求 404 Not Found：服务器无法根据客户端的请求找到资源。 405 Method Not Allowed：客户端请求中的方法被禁止 406 Not Acceptable：服务器无法根据客户端请求的内容特性完成请求 408 Request Time-out：服务器等待客户端发送的请求时间过长，超时 5xx 500 Internal Server Error：服务器内部错误，无法完成请求 501 Not Implemented：服务器不支持请求的功能，无法完成请求 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:4:1","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"HTTP版本 HTTP1.0 ​ HTTP1.0 使用的是非持久连接，主要缺点是客户端必须为每一个待请求的对象建立并维护一个新的连接，即每请求一个文档就要有两倍RTT 的开销。因为同一个页面可能存在多个对象，所以非持久连接可能使一个页面的下载变得十分缓慢，而且这种 短连接增加了网络传输的负担。 RTT(Round Trip Time)：一个连接的往返时间，即数据发送时刻到接收到确认的时刻的差值； HTTP1.1 支持长连接。 在HTTP1.0的基础上引入了更多的缓存控制策略。 引入了请求范围设置，优化了带宽。 在错误通知管理中新增了错误状态响应码。 增加了Host头处理，可以传递主机名（hostname） HTTP1.X优化（SPDY） ​ SPDY 并不是新的一种协议，而是在 HTTP 之前做了一层会话层。为了达到减少页面加载时间的目标，SPDY 引入了一个新的二进制分帧数据层，以实现优先次序、最小化及消除不必要的网络延迟，目的是更有效地利用底层 TCP 连接。 多路复用，为多路复用设立了请求优先级。 对header部分进行了压缩。 引入了HTTPS加密传输。 客户端可以在缓存中取到之前请求的内容。 HTTP2.0（SPDY的升级版） HTTP2.0支持明文传输，而HTTP 1.X强制使用SSL/TLS加密传输。 和HTTP 1.x使用的header压缩方法不同。 HTTP2.0 基于二进制格式进行解析，而HTTP 1.x基于文本格式进行解析。增加二进程的传输方式，相对于文本传输更加安全. 多路复用，HTTP1.1是多个请求串行化单线程处理，HTTP 2.0是并行执行，一个请求超时并不会影响其他请求。 请求划分优先级 HTTP 3.0 (QUIC) QUIC (Quick UDP Internet Connections), 快速 UDP 互联网连接。QUIC是基于UDP协议的。两个主要特性： 线头阻塞(HOL)问题的解决更为彻底： ​ 基于TCP的HTTP/2，尽管从逻辑上来说，不同的流之间相互独立，不会相互影响，但在实际传输方面，数据还是要一帧一帧的发送和接收，一旦某一个流的数据有丢包，则同样会阻塞在它之后传输的流数据传输。而基于UDP的QUIC协议则可以更为彻底地解决这样的问题，让不同的流之间真正的实现相互独立传输，互不干扰。 切换网络时的连接保持 ​ 当前移动端的应用环境，用户的网络可能会经常切换，比如从办公室或家里出门，WiFi断开，网络切换为3G或4G。基于TCP的协议，由于切换网络之后，IP会改变，因而之前的连接不可能继续保持。而基于UDP的QUIC协议，则可以内建与TCP中不同的连接标识方法，从而在网络完成切换之后，恢复之前与服务器的连接。 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:4:2","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"HTTP方法 方法 作用 GET 获取资源 POST 传输实体主体 PUT 上传文件 DELETE 删除文件 HEAD 和GET方法类似，但只返回报文首部，不返回报文实体主体部分 PATCH 对资源进行部分修改 OPTIONS 查询指定的URL支持的方法 CONNECT 要求用隧道协议连接代理 TRACE 服务器会将通信路径返回给客户端 为了方便记忆，可以将PUT、DELETE、POST、GET理解为客户端对服务端的增删改查。 PUT：上传文件，向服务器添加数据，可以看作增 DELETE：删除文件 POST：传输数据，向服务器提交数据，对服务器数据进行更新。 GET：获取资源，查询服务器资源 GET和POST的区别 作用GET用于获取资源，POST用于传输实体主体 参数位置GET的参数放在URL中，POST的参数存储在实体主体中，并且GET方法提交的请求的URL中的数据做多是2048字节，POST请求没有大小限制。 安全性GET方法因为参数放在URL中，安全性相对于POST较差一些 幂等性GET方法是具有幂等性的，而POST方法不具有幂等性。这里幂等性指客户端连续发出多次请求，收到的结果都是一样的. ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:4:3","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"HTTP和HTTPS的区别 HTTP HTTPS 端口 80 443 安全性 无加密 有加密机制、安全性较高 资源消耗 较少 由于加密处理，资源消耗更多 是否需要证书 不需要 需要 协议 运行在TCP协议之上 运行在SSL协议之上，SSL运行在TCP协议之上 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:4:4","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"HTTPS的加密过程 HTTPS使用的是对称加密和非对称加密的混合加密算法。具体做法就是使用非对称加密来传输对称密钥来保证安全性，使用对称加密来保证通信的效率。 简化的工作流程：服务端生成一对非对称密钥，将公钥发给客户端。客户端生成对称密钥，用服务端发来的公钥进行加密，加密后发给服务端。服务端收到后用私钥进行解密，得到客户端发送的对称密钥。通信双方就可以通过对称密钥进行高效地通信了。 HTTPS的详细加密过程： 客户端向服务端发起第一次握手请求，告诉服务端客户端所支持的SSL的指定版本、加密算法及密钥长度等信息。 服务端将自己的公钥发给数字证书认证机构，数字证书认证机构利用自己的私钥对服务器的公钥进行数字签名，并给服务器颁发公钥证书。 服务端将证书发给客服端。 客服端利用数字认证机构的公钥，向数字证书认证机构验证公钥证书上的数字签名，确认服务器公开密钥的真实性。 客服端使用服务端的公钥加密自己生成的对称密钥，发给服务端。 服务端收到后利用私钥解密信息，获得客户端发来的对称密钥。 通信双方可用对称密钥来加密解密信息。 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:4:5","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"[应用层]DNS协议 DNS : 域名系统；DNS系统采用的是分布式的层次数据数据库模式，还有缓存的机制。 ​ 工作流程 主机向本地域名服务器的查询一般是采用递归查询，而本地域名服务器向根域名的查询一般是采用迭代查询 递归查询，是服务器向上级服务器发送请求报文，返回给你ip地址 迭代查询，是服务器通知你，需要向哪个上级服务器发请求报文，请求ip. 实例: 在浏览器中输入百度域名，操作系统会先检查自己本地的hosts文件是否有这个域名的映射关系，如果有，就先调用这个IP地址映射，完成域名解析。 如果hosts文件中没有，则查询本地DNS解析器缓存，如果有，则完成地址解析。 如果本地DNS解析器缓存中没有，则去查找本地DNS服务器，如果查到，完成解析。 如果没有，则本地服务器会向根域名服务器发起查询请求。根域名服务器会告诉本地域名服务器去查询哪个顶级域名服务器。 本地域名服务器向顶级域名服务器发起查询请求，顶级域名服务器会告诉本地域名服务器去查找哪个权限域名服务器。 本地域名服务器向权限域名服务器发起查询请求，权限域名服务器告诉本地域名服务器百度所对应的IP地址。 本地域名服务器告诉主机百度所对应的IP地址。 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:5:0","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"[传输层]TCP/UDP协议详解 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:6:0","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"TCP 数据结构 ​ TCP头部: 前20个字节是固定的，后面有4n个字节是根据需而增加的选项，所以TCP首部最小长度为20字节。 序号：seq，占32位，用来标识从发送端到接收端发送的字节流。(一般来说在0 - 2^32-1之间) 确认号：ack，占32位，只有ACK标志位为1时，确认序号字段才有效，ack=seq+1。 标志位： SYN：发起一个新连接。 FIN：释放一个连接。 ACK：确认序号有效。 TCP可靠传输 主要有校验和、序列号、超时重传、流量控制及拥塞避免等几种方法。 校验和: 在发送端和接收端分别计算数据的校验和，如果两者不一致，则说明数据在传输过程中出现了差错，TCP将丢弃和不确认此报文段。 序列号: TCP会对每一个发送的字节进行编号，接收方接到数据后，会对发送方发送确认应答(ACK报文)，并且这个ACK报文中带有相应的确认编号，告诉发送方，下一次发送的数据从编号多少开始发。如果发送方发送相同的数据，接收端也可以通过序列号判断出，直接将数据丢弃. 超时重传: 在上面说了序列号的作用，但如果发送方在发送数据后一段时间内（可以设置重传计时器规定这段时间）没有收到确认序号ACK，那么发送方就会重新发送数据。 这里发送方没有收到ACK可以分两种情况： 如果是发送方发送的数据包丢失了，接收方收到发送方重新发送的数据包(序列号大于了丢失的数据的序列号)后会马上重新给发送方发送(原丢失数据的)ACK； 如果是接收方之前接收到了发送方发送的数据包，而返回给发送方的ACK丢失了，这种情况，发送方重传后，接收方会直接丢弃发送方重传的数据包，然后再次发送ACK响应报文。如果数据被重发之后还是没有收到接收方的确认应答，则进行再次发送。此时，等待确认应答的时间将会以2倍、4倍的指数函数延长，直到最后关闭连接。 流量控制: 如果发送端发送的数据太快，接收端来不及接收就会出现丢包问题。 ​ 为了解决这个问题，TCP协议利用了滑动窗口进行了流量控制。在TCP首部有一个16位字段大小的窗口，窗口的大小就是接收端接收数据缓冲区的剩余大小。接收端会在收到数据包后发送ACK报文时，将自己的窗口大小填入ACK中，发送方会根据ACK报文中的窗口大小进而控制发送速度。如果窗口大小为零，发送方会停止发送数据。 拥塞控制: 如果网络出现拥塞，则会产生丢包等问题，这时发送方会将丢失的数据包继续重传，网络拥塞会更加严重，所以在网络出现拥塞时应注意控制发送方的发送数据，降低整个网络的拥塞程度。 拥塞控制主要有四部分组成：慢开始、拥塞避免、快重传、快恢复 （这里的发送方会维护一个拥塞窗口的状态变量，它和流量控制的滑动窗口是不一样的，滑动窗口是根据接收方数据缓冲区大小确定的，而拥塞窗口是根据网络的拥塞情况动态确定的，一般来说发送方真实的发送窗口为滑动窗口和拥塞窗口中的最小值） 慢开始: 为了避免一开始发送大量的数据而产生网络阻塞，会先初始化cwnd为1，当收到ACK后到下一个传输轮次，cwnd为2，以此类推成指数形式增长。 拥塞避免: 因为cwnd的数量在慢开始是指数增长的，为了防止cwnd数量过大而导致网络阻塞，会设置一个慢开始的门限值ssthresh，当cwnd\u003e=ssthresh时，进入到拥塞避免阶段，cwnd每个传输轮次加1。但网络出现超时，会将门限值ssthresh变为出现超时cwnd数值的一半，cwnd重新设置为1，如上图，在第12轮出现超时后，cwnd变为1，ssthresh变为12。 快重传：在网络中如果出现超时或者阻塞，则按慢开始和拥塞避免算法进行调整。但如果只是丢失某一个报文段，如下图，则使用快重传算法。 但是根据快重传算法，要求在这种情况下，需要快速向发送端发送M2的确认报文，在发送方收到三个M2的确认报文后，无需等待重传计时器所设置的时间，可直接进行M3的重传，这就是快重传。 快恢复: 当发送收到三个重复的ACK，会进行快重传和快恢复。快恢复是指将ssthresh设置为发生快重传时的cwnd数量的一半，而cwnd不是设置为1而是设置为为门限值ssthresh，并开始拥塞避免阶段。 TCP三次握手 发送端状态：CLOSED、SYN-SENT、ESTABLISHED 接收端状态：LISTEN、SYN-RCVD、ESTABLISHED 对于客户端而言,第二次握手就已经确定了建立链接,因此第三次握手实际上也算是数据传输的一次, 所以第一个数据包序列号为x+1 TCP连接队列 半连接队列: 服务端收到客户端发起的 SYN 请求后，内核会把该连接存储到半连接队列（SYN队列），并向客户端响应 SYN+ACK. 全连接队列: 服务端收到第三次握手的ACK后，内核会把连接从半连接队列移除，然后创建新的完全的连接，并将其添加到accept队列，等待进程调用accept 函数时把连接取出来。 为什么握手需要三次? 假设建立TCP连接仅需要两次握手，那么如果第二次握手时，服务端返回给客户端的确认报文丢失了，客户端这边认为服务端没有和他建立连接，而服务端却以为已经和客户端建立了连接，并且可能服务端已经开始向客户端发送数据，但客户端并不会接收这些数据，浪费了资源。如果是三次握手，不会出现双方连接还未完全建立成功就开始发送数据的情况。 如果服务端接收到了一个早已失效的来自客户端的连接请求报文，会向客户端发送确认报文同意建立TCP连接。但因为客户端并不需要向服务端发送数据，所以此次TCP连接没有意义并且浪费了资源。 如果是一次握手,则退化成了UDP SYN洪泛攻击，以及解决策略是什么? ​ 因为服务器端的资源分配是在二次握手时分配的，而客户端的资源是在完成三次握手时分配的，所以服务器容易受到SYN洪泛攻击。 洪泛攻击: SYN攻击就是Client在短时间内伪造大量不存在的IP地址，并向Server不断地发送SYN包，Server则回复确认包，并等待Client确认，由于源地址不存在，因此Server需要不断重发直至超时，这些伪造的SYN包将长时间占用半连接队列，导致正常的SYN请求因为队列满而被丢弃，从而引起网络拥塞甚至系统资源被占用完而瘫痪。SYN 攻击是一种典型的 DoS/DDoS 攻击 查看检测 SYN 攻击非常的方便，当你在服务器上看到大量的半连接状态时，特别是源IP地址是随机的，基本上可以断定这是一次SYN攻击。 netstat -n -p TCP | grep SYN_RECV 常见的解决办法: 缩短超时（SYN Timeout）时间 增加最大半连接数: 可以保存更多的半连接数,防止丢弃新连接 增加过滤网关防护 SYN cookies技术: 可以在不使用SYN半连接队列的情况下成功建立连接; ​ 原理是，在TCP服务器接收到TCP SYN包并返回TCP SYN + ACK包时，不分配一个专门的数据区，而是根据这个SYN包计算出一个cookie值。这个cookie作为将要返回的SYN ACK包的初始序列号。当客户端返回一个ACK包时，根据包头信息计算cookie，与返回的确认序列号(初始序列号 + 1)进行对比，如果相同，则是一个正常连接，然后，分配资源，建立连接。 TCP四次挥手 客户端状态：ESTABLISHED、FIN-WAIT-1、FIN-WAIT-2、TIME-WAIT、CLOSED 服务器状态：ESTABLISHED、CLOSE-WAIT、LAST-ACK、CLOSED 为什么要time_wait状态, 以及等待2MSL的时间? ​ MSL(Maximum Segment LifeTime)是报文最大生成时间，它是任何报文在网络上存在的最长时间，超过这个时间的报文将被丢弃。可以从两方面考虑： 客户端发送第四次挥手中的报文后，再经过2MSL，可使本次TCP连接中的所有报文全部消失，不会出现在下一个TCP连接中。 考虑丢包问题，如果第四挥手发送的报文在传输过程中丢失了，那么服务端没收到确认ack报文就会重发第三次挥手的报文。如果客户端发送完第四次挥手的确认报文后直接关闭，而这次报文又恰好丢失，则会造成服务端无法正常关闭。 TIME_WAIT和CLOSE_WAIT的区别在哪? CLOSE_WAIT是被动关闭形成的，当客户端发送FIN报文，服务端返回ACK报文后进入CLOSE_WAIT。 TIME__WAIT_是主动关闭形成的，当第四次挥手完成后，客户端进入TIME_WAIT状态 TCP中的timewait状态过多会怎样? 占用过多的系统资源,占用服务器端口,导致无法使用, 建立链接失败 解决timewait状态过多的方法 : 允许timewait状态的端口被重用 减小timewait的时长 客户端头部设置keep-alive 出现了大量的CLOSE_WAIT状态怎么解决? ​ 大量 CLOSE_WAIT 表示程序出现了问题，对方的 socket 已经关闭连接，而我方忙于读或写没有及时关闭连接，需 要检查代码，特别是释放资源的代码，或者是处理请求的线程配置。 为什么挥手需要四次? ​ 由于TCP的**半关闭(half-close)**造成的。半关闭是指：TCP提供了连接的一方在结束它的发送后还能接受来自另一端数据的能力。通俗来说，就是不能发送数据，但是还可以接受数据。 ​ 当服务端发送完数据后还需要向客户端发送释放连接请求，客户端返回确认报文，TCP连接彻底关闭。所以断开TCP连接需要客户端和服务端分别通知对方并分别收到确认报文，一共需要四次。 问题: 如果已经建立了TCP连接，但是客户端突然出现故障了怎么办？ ​ 如果TCP连接已经建立，在通信过程中，客户端突然故障，那么服务","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:6:1","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"UDP 数据结构 UDP的首部只有8个字节，源端口号、目的端口号、长度和校验和各两个字节。TCP和UDP对比 是否面向连接 可靠性 传输形式 传输效率 资源消耗 应用场景 首部字节 TCP 是 可靠 字节流 慢 多 文件/邮件传输 20-60 UDP 否 不可靠 数据报文段 快 少 语音/视频 8 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:6:2","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"[网络层]ARP协议 ​ 主要作用是实现从IP地址转换为MAC地址。 ​ 网络层实现的是主机之间的通信，而链路层实现的是链路之间的通信，所以从下图可以看出，在数据传输过程中，IP数据报的源地址(IP1)和目的地址(IP2)是一直不变的，而MAC地址(硬件地址)却一直随着链路的改变而改变。ARP的工作流程: 在局域网内，主机A要向主机B发送IP数据报时，首先会在主机A的ARP缓存表中查找是否有IP地址及其对应的MAC地址，如果有，则将MAC地址写入到MAC帧的首部，并通过局域网将该MAC帧发送到MAC地址所在的主机B。 如果主机A的ARP缓存表中没有主机B的IP地址及所对应的MAC地址，主机A会在局域网内广播发送一个ARP请求分组。局域网内的所有主机都会收到这个ARP请求分组。 主机B在看到主机A发送的ARP请求分组中有自己的IP地址，会向主机A以单播的方式发送一个带有自己MAC地址的响应分组。 主机A收到主机B的ARP响应分组后，会在ARP缓存表中写入主机B的IP地址及其IP地址对应的MAC地址。 如果主机A和主机B不在同一个局域网内，即使知道主机B的MAC地址也是不能直接通信的，必须通过路由器转发到主机B的局域网才可以通过主机B的MAC地址找到主机B。并且主机A和主机B已经可以通信的情况下，主机A的ARP缓存表中存的并不是主机B的IP地址及主机B的MAC地址，而是主机B的IP地址及该通信链路上的下一跳路由器的MAC地址。这就是上图中的源IP地址和目的IP地址一直不变，而MAC地址却随着链路的不同而改变。 如果主机A和主机B不在同一个局域网，参考上图中的主机H1和主机H2，这时主机H1需要先广播找到路由器R1的MAC地址，再由R1广播找到路由器R2的MAC地址，最后R2广播找到主机H2的MAC地址，建立起通信链路。 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:7:0","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"[网络层]IP协议 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:8:0","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"TCP分段和IP分片 分段分片的目的，都是为了能够传输上层交付的、数据量超过本层传输能力上限的数据，不得已才做的数据切分. ​ 最大传输单元(Maximum Transmission Unit)，即MTU，为数据链路层的最大载荷上限。 ​ 最大报文段长度(Maximum Segment Size)，即MSS，为TCP传输层的最大载荷上限(即应用层数据最大长度) MTU = MSS + TCP首部长度 + IP首部长度 分片发生在IP层，分段发生在tcp层 IP层分片的原因是mtu的限制，tcp层分段的原因是mss的限制 udp不进行分段会在ip层进行分片 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:8:1","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"有了IP地址，为什么还要用MAC地址？ ​ 标识网络中的一台计算机，比较常用的就是IP地址和MAC地址，但计算机的IP地址可由用户自行更改，管理起来相对困难，而MAC地址不可更改，所以一般会把IP地址和MAC地址组合起来使用。 ​ 随着网络中的设备越来越多，整个路由过程越来越复杂，便出现了子网的概念。对于目的地址在其他子网的数据包，路由只需要将数据包送到那个子网即可，这个过程就是上面说的ARP协议。 ​ 如果只是用MAC地址,路由器则需要记住每个MAC地址在哪个子网，这需要路由器有极大的存储空间，是无法实现的。如果只是用IP地址,没办法标志多个子网中唯一的设备. ​ IP地址可以比作为地址，MAC地址为收件人，在一次通信过程中，两者是缺一不可的 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:8:2","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"[网络层]ICMP协议 ​ 网络层协议，主要是实现 IP 协议中未实现的部分功能，是一种网络层协议。该协议并不传输数据，只传输控制信息来辅助网络层通信. 应用: ping ping的作用是测试两个主机的连通性。工作过程: 向目的主机发送多个ICMP回送请求报文 根据目的主机返回的回送报文的时间和成功响应的次数估算出数据包往返时间及丢包率。 TraceRoute ​ 其主要用来跟踪一个分组从源点耗费最少 TTL 到达目的地的路径。TraceRoute 通过逐渐增大 TTL 值并重复发送数据报来实现其功能.(TTL, Time To live生存时间) 首先，TraceRoute 会发送一个 TTL 为 1 的 IP 数据报到目的地，当路径上的第一个路由器收到这个数据报时，它将 TTL 的值减 1，此时 TTL = 0，所以路由器会将这个数据报丢掉，并返回一个差错报告报文， 之后源主机会接着发送一个 TTL 为 2 的数据报，并重复此过程，直到数据报能够刚好到达目的主机。此时 TTL = 0，因此目的主机要向源主机发送 ICMP 终点不可达差错报告报文，之后源主机便知道了到达目的主机所经过的路由器 IP 地址以及到达每个路由器的往返时间。 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:9:0","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"JWT ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:10:0","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"Session、Cookie和Token的主要区别 Cookie ​ Cookie是保存在客户端一个小数据块，其中包含了用户信息。当客户端向服务端发起请求，服务端会像客户端浏览器发送一个Cookie，客户端会把Cookie存起来，当下次客户端再次请求服务端时，会携带上这个Cookie，服务端会通过这个Cookie来确定身份。 Session ​ Session是通过Cookie实现的，和Cookie不同的是，Session是存在服务端的。当客户端浏览器第一次访问服务器时，服务器会为浏览器创建一个sessionid，将sessionid放到Cookie中，存在客户端浏览器。比如浏览器访问的是购物网站，将一本《图解HTTP》放到了购物车，当浏览器再次访问服务器时，服务器会取出Cookie中的sessionid，并根据sessionid获取会话中的存储的信息，确认浏览器的身份是上次将《图解HTTP》放入到购物车那个用户。 Token ​ 客户端在浏览器第一次访问服务端时，服务端生成的一串字符串作为Token发给客户端浏览器，下次浏览器在访问服务端时携带token即可无需验证用户名和密码，省下来大量的资源开销。 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:10:1","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"客户端禁止 cookie 能实现 session 还能用吗 ​ 可以，Session的作用是在服务端来保持状态，通过sessionid来进行确认身份，但sessionid一般是通过Cookie来进行传递的。如果Cooike被禁用了，可以通过在URL中传递sessionid。 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:10:2","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"NAT ​ NAT（Network Address Translation），即网络地址转换，它是一种把内部私有网络地址翻译成公有网络 IP 地址的技术。 ​ 该技术不仅能解决 IP 地址不足的问题，而且还能隐藏和保护网络内部主机，从而避免来自外部网络的攻击。 NAT 的实现方式主要有三种： 静态转换：内部私有 IP 地址和公有 IP 地址是一对一的关系，并且不会发生改变。通过静态转换，可以实现外部网络对内部网络特定设备的访问，这种方式原理简单，但当某一共有 IP 地址被占用时，跟这个 IP 绑定的内部主机将无法访问 Internet。 动态转换：采用动态转换的方式时，私有 IP 地址每次转化成的公有 IP 地址是不唯一的。当私有 IP 地址被授权访问 Internet 时会被随机转换成一个合法的公有 IP 地址。当 ISP 通过的合法 IP 地址数量略少于网络内部计算机数量时，可以采用这种方式。 端口多路复用：该方式将外出数据包的源端口进行端口转换，通过端口多路复用的方式，实现内部网络所有主机共享一个合法的外部 IP 地址进行 Internet 访问，从而最大限度地节约 IP 地址资源。同时，该方案可以隐藏内部网络中的主机，从而有效避免来自 Internet 的攻击。 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:11:0","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"URI 和URL的区别 URI(Uniform Resource Identifier)：中文全称为统一资源标志符，主要作用是唯一标识一个资源。 URL(Uniform Resource Location)：中文全称为统一资源定位符，主要作用是提供资源的路径。 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:12:0","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"路由器和交换机的区别？ 所属网络模型的层级 功能 路由器 网络层 识别IP地址并根据IP地址转发数据包，维护数据表并基于数据表进行最佳路径选择 交换机 数据链库层 识别MAC地址并根据MAC地址转发数据帧 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:13:0","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"在浏览器中输⼊url地址到显示主页的过程 对输入到浏览器的url进行DNS解析，将域名转换为IP地址。 和目的服务器建立TCP连接 向目的服务器发送HTTP请求 服务器处理请求并返回HTTP报文 浏览器解析并渲染页面 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:14:0","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"一个主机可以建立多少连接 客户端 ​ 每一个ip可建立的TCP连接理论受限于ip_local_port_range参数，也受限于65535。但可以通过配置多ip的方式来加大自己的建立连接的能力。 服务器 ​ 每一个监听的端口虽然理论值很大，但这个数字没有实际意义。最大并发数取决你的内存大小，每一条静止状态的TCP连接大约需要吃3.3K的内存 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:15:0","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"操作系统 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:0:0","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"进程管理 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:1:0","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"进程和线程 进程组成 进程控制块PCB，是进程存在的唯一标志，包含进程标识符PID，进程当前状态，程序和数据地址，进程优先级、CPU现场保护区(用于进程切换)，占有的资源清单等。 程序段 数据段 进程创建、终止 进程创建的方法 系统初始化（init） 正在运行的程序执行了创建进程的系统调用（比如 fork） 用户请求创建一个新进程 初始化一个批处理工作 进程终止的方法 正常退出：exit() 发生程序错误后退出(自愿的) 被其他进程杀死(如发送信号kill) 进程和线程的区别 ​ 一个线程只能属于一个进程，而一个进程可以有多个线程，但至少有一个线程。线程依赖于进程而 存在。 调度: 进程是资源管理的基本单位，线程是程序执行的基本单位 切换: 线程上下文切换比进程上下文切换要快得多 拥有资源:进程是拥有资源的一个独立单位，线程不拥有系统资源，但是可以访问隶属于进程的资源。 系统开销:创建或撤销进程时，系统都要为之分配或回收系统资源，如内存空间，I/O 设备等，OS所付出的 开销显著大于在创建(只有栈的开销)或撤销线程时的开销，进程切换的开销也远大于线程切换的开销。 ​ 左侧为进程中每个线程共享的内容，右侧为线程单独的内容 协程，进程，线程的区别 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:1:1","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"进程状态 ​ 进程一共有5 种状态，分别是创建、就绪、运行(执行)、终止、阻塞。 运行状态就是进程正在 CPU上运行。在单处理机环境下，每一时刻最多只有一个进程处于运行状态。 就绪状态就是说进程已处于准备运行的状态，即进程获得了除 CPU之外的一切所需资源，一旦得到 CPU即可 运行。 阻塞状态就是进程正在等待某一事件而暂停运行，比如等待某资源为可用或等待 I/O 完成。即使 CPU空闲， 该进程也不能运行。 运行态→阻塞态:往往是由于等待外设，等待主存等资源分配或等待人工干预而引起的。 阻塞态→就绪态:则是等待的条件已满足，只需分配到处理器后就能运行。 运行态→就绪态:不是由于自身原因，而是由外界原因使运行状态的进程让出处理器，这时候就变成就绪态。例如 时间片用完，或有更高优先级的进程来抢占处理器等。 就绪态→运行态:系统按某种策略选中就绪队列中的一个进程占用处理器，此时就变成了运行态。 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:1:2","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"进程和线程的切换流程 进程切换: 切换页表以使用新的地址空间，一旦去切换上下文，处理器中所有已经缓存的内存地址一瞬间都作废了。 切换内核栈和硬件上下文。 线程切换 ​ 线程切换时因为其共享所在进程的虚拟地址空间的, 所以不需要切换地址空间,只需要切换内核栈和上下文 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:1:3","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"为什么虚拟空间的切换特别耗时? ​ 进程都有自己的虚拟地址空间，把虚拟地址转换为物理地址需要查找页表，页表查找是一个很慢的过程，因此通常使用 Cache 来缓存常用的地址映射，这样可以加速页表查找，这个 Cache 就是 TLB(translation Lookaside Buffer， TLB本质上就是一个 Cache，是用来加速页表查找的),即快表. ​ 显然每个进程都有自己的页表，那么当进程切换后页表也要进行切换，页表切换后 TLB就失效了，Cache 失效导致命 中率降低，那么虚拟地址转换为物理地址就会变慢，表现出来的就是程序运行会变慢 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:1:4","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"进程通信方式 管道 (速度慢，容量有限;) 管道可以分为两类:匿名管道和命名管道。匿名管道是单向的，只能在有亲缘关系的进程间通信;命名管道FIFO以磁盘文件的方式存在，可以实现本机任意两个进程通信。 信号 常用信号: SIGHUP: 用户从终端注销，所有已启动进程都将收到该进程。系统缺省状态下对该信号的处理是终止进程。 SIGINT: 程序终止信号。程序运行过程中，按 Ctrl+C 键将产生该信号。 SIGQUIT:程序退出信号。程序运行过程中，按 Ctrl+\\键将产生该信号 SIGBUS和 SIGSEGV:进程 访问非法地址。 SIGKILL:用户终止进程执行信号。shell 下执行 kill -9 发送该信号。 信号量: 信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程 正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手 段。(不能传递复杂消息，只能用来同步;) 消息队列。 (容量受到系统限制，且要注意第一次读的时候，要考虑上一次没有读完数据的问题;) 共享内存:共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都 可以访问。共享内存是最快的 IPC 方式(能够很容易控制容量，速度快，但要保持同步) Socket: 不同机器间的进程间通信 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:1:5","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"进程间同步的方式 临界区 ​ 通过对多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问。 ​ 优点: 保证在某一时刻只有一个线程能访问数据的简便办法 ​ 缺点: 虽然然临界区同步速度很快，但却只能用来同步 本进程内的线程，而不可用来同步多个进程中的线程。 ​ ​ 冲突解决: 如果有若干进程要求进入空闲的临界区，一次仅允许一个进程进入，如已有进程进入自己的临界区，则其它所 有试图进入临界区的进程必须等待; 进入临界区的进程要在有限时间内退出。 如果进程不能进入自己的临界区，则应让出 CPU，避免进程出现“忙等”现象。 互斥量 ​ 互斥量跟临界区很相似，比临界区复杂，互斥对象只有一个，只 有拥有互斥对象的线程才具有访问资源的权限。 ​ 优点: 使用互斥不仅仅能够在同一应用程序不同线程中实现资源的 安全共享，而且可以在不同进程的线程之间实现对资源的安全共享。 ​ 缺点: 1. 消耗的资源较多 2. 只能针对一个资源进行同步访问,没办法计数 信号量 ​ 为控制一个具有有限数量用户资源而设计。它允许多个线程在同一时刻访问同一资源，但是需要限制在同 一时刻访问此资源的最大线程数目。互斥量是信号量的一种特殊情况，当信号量的最大资源数=1就是互斥量了。 ​ 优点: 适用于对 Socket(套接字)程序中线程的同步。 ​ 缺点: 1. 必须有公共内存，不能用于分布式操作系统，这是它最大的弱点; 2. 对信号量的操作分散，而且难以控制，读写和维护都很困难 ​ ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:1:6","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"线程同步方式 临界区: 当多个线程访问一个独占性共享资源时，可以使用临界区对象。拥有临界区的线程可以访问被保护起来的 资源或代码段，其他线程若想访问，则被挂起，直到拥有临界区的线程放弃临界区为止，以此达到用原子方式操作 共享资源的目的 事件机制: 事件机制，则允许一个线程在处理完一个任务后，主动唤醒另外一个线程执行任务 互斥量: 互斥对象和临 界区对象非常相似，只是其允许在进程间使用，而临界区只限制与同一进程的各个线程之间使用，但是更节省资 源，更有效率 信号量: 当需要一个计数器来限制可以使用某共享资源的线程数目时,可以使用信号量 a. 互斥量与临界区的作用非常相似，但互斥量是可以命名的，也就是说互斥量可以跨越进程使用，但创建互斥量需要的资源更多，所以如果只为了在进程内部是用的话使用临界区会带来速度上的优势并能够减少资源占用 量. b. 互斥量，信号量，事件都可以被跨越进程使用来进行同步数据操作。 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:1:7","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"死锁和死锁产生的条件 ​ 两个或者多个并发进程中，如果每个进程持有某种资源而又等待其它进程释放它或它们现在保持着 的资源，在未改变这种状态之前都不能向前推进，称这一组进程产生了死锁. 四个必要条件 互斥条件:一个资源一次只能被一个进程使用 请求与保持条件:一个进程因请求资源而阻塞时，对已获得资源保持不放 非抢占: 进程获得的资源，在未完全使用完之前，不能强行抢占 循环等待条件:若干进程之间形成一种头尾相接的环形等待资源关系 死锁问题解决: 资源一次性分配，这样就不会再有请求了(破坏请求条件)。 只要有一个资源得不到分配，也不给这个进程分配其他的资源(破坏占有并等待条件)。 可抢占资源:即当进程新的资源未得到满足时，释放已占有的资源，从而破坏不可抢占的条件。 资源有序分配法:系统给每类资源赋予一个序号，每个进程按编号递增的请求资源，释放则相反，从而破坏环路等待的条件 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:1:8","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"进程调度策略 先来先服务: 非抢占式的调度算法，按照请求的顺序进行调度。 ​ 有利于长作业，但不利于短作业，因为短作业 必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很⻓时间，造成了短作业等待时间过长。 另外，对 I/O 密集型进程也不利，因为这种进程每次进行 I/O 操作之后又得重新排队. ​ 短作业优先: 非抢占式的调度算法，按估计运行时间最短的顺序进行调度 ​ 长作业有可能会饿死，处于一直等 待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度 最短剩余时间优先: 最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度 ​ 当一个新的作业到达时， 其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。 时间片轮转: 将所有就绪进程按 FCFS的原则排成一个队列，每次调度时，把 CPU时间分配给队首进程，该进程可 以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU时间分配给队 首的进程。 ​ a. 时间片轮转算法的效率和时间片的大小有很大关系:因为进程切换都要保存进程的信息并且载入新进程的信 息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。而如果时间片过长，那么实时性就不能得到保证。 ​ b. 优先级调度:为每个进程分配一个优先级，按优先级进行调度。为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。 多级队列调度算法: 将系统中的进程就绪队列从一个拆分为若干个，将不同类型或性质的进程固定分配在不同的就绪队列，不同的就绪队列采用不同的调度算法，一个就绪队列中的进程可以设置不同的优先级，不同的就绪队列本身也可以设置不同的优先级。 多级反馈队列调度算法: 为就绪队列赋予不同的优先级数，不同的时间片，按照优先级抢占CPU的调度算法; 优先权越高，队列的时间片越小. 首先调度优先级高的队列中的进程。若高优先级中队列中已没有调度的进程，则调度次优先级队列中的进程 同一个队列中的各个进程，按照 时间片轮转法调度 在低优先级的队列中的进程在运行时，又有新到达的作业，那么在运行完这个时间片后，CPU马上分配给新到达的作业即抢占式调度CPU ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:1:9","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"孤儿进程和僵尸进程 孤儿进程: 父进程已退出，但子进程还在运行的这些子进程都是孤儿进程，孤儿进程将被init进程(1号进程)所收养，并由init进程对他们完成状态收集工作。 僵尸进程: 进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait 获waitpid 获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中的这些进程是僵尸进程。 危害:僵尸进程会占用系统资源, 没有回收导致内存泄漏 避免: 手动杀死父进程,让子进程变成孤儿进程由init进程回收; 严格回收子进程 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:1:10","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"IO多路复用 ​ IO多路复用是指内核一旦发现进程指定的一个或者多个 IO条件准备读取，它就通知该进程。 适用场景 当客户处理多个描述字时(一般是交互式输入和网络套接口)，必须使用 I/O 复用。 当一个客户同时处理多个套接口时，而这种情况是可能的，但很少出现。 如果一个 TCP服务器既要处理监听套接口，又要处理已连接套接口，一般也要用到 I/O 复用。 如果一个服务器即要处理 TCP，又要处理 UDP，一般要使用 I/O 复用。 如果一个服务器要处理多个服务或多个协议，一般要使用 I/O 复用。 与多进程和多线程技术相比，I/O 多路复用技术的最大优势是系统开销小，系统不必创建进程/线程，也不必 维护这些进程/线程，从而大大减小了系统的开销。 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:1:11","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"写时复制 如果进程从来就不需要修改资源，则不需要进行复制,每个进程只要保存一 个指向这个资源的指针就可以了。惰性算法的好处 就在于它们尽量推迟代价高昂的操作，直到必要的时刻才会去执行。 在使用虚拟内存的情况下，写时复制(Copy-On-Write)是以页为基础进行的。所以，只要进程不 修改它全部的地址空间，那么就不必复制整个地址空间。在fork()调用结束后，父进程和子进程都相信它们有一个自己的地址空间，但实际上它们共享父进程的原始页，接下来这些页又可以被其他的父进程或子进程共享。 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:1:12","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"中断 ​ 简单来说就是CPU停下当前的工作任务，去处理其他事情，处理完后回来继续执行刚才的任务，这一过程便是中断。 中断的处理过程**?** 保护现场:将当前执行程序的相关数据保存在寄存器中，然后入栈。 开中断:以便执行中断时能响应较高级别的中断请求。 中断处理 关中断:保证恢复现场时不被新中断打扰 恢复现场:从堆栈中按序取出程序数据，恢复中断前的执行状态。 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:1:13","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"优先级反转问题 ​ 由于多进程共享资源，具有最高优先权的进程被低优先级进程阻塞，反而使具有中优先级的进程先于高 优先级的进程执行，导致系统的崩溃。这就是所谓的优先级反转(Priority Inversion)。 ​ 解决: 优先级继承(priority inheritance) :是指将低优先级任务的优先级提升到等待它所占有的资 源的最高优先级任务的优先级.当高优先级任务由于等待资源而被阻塞时,此时资源的拥有者的优先 级将会自动被提升。 优先级天花板(priority ceilings):是指将申请某资源的任务的优先级提升到可能访问该资 源的所有任务中最高优先级任务的优先级 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:1:14","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"内存管理 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:2:0","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"1. 分页 ​ 把内存空间划分为大小相等且固定的块，作为主存的基本单位。因为程序数据存储在不同的页面中，而页面又离散的分布在内存中，因此需要一个页表来记录映射关系，以实现从页号到物理块号的映射。访问分页系统中内存数据 需要两次的内存访问(一次是从内存中访问页表，从中找到指定的物理块号，加上页内偏移得到实际物理地址;第二 次就是根据第一次得到的物理地址访问内存取出数据)。 ​ 分片是由于分段的粒度太大,容易产生大量外部碎片. 而且对于某一个段进行内存置换代价也过大,因此进行段页式内存管理. ​ 每个页为4KB, 如果要规避分段,只需要跟linux一样将每个段的首地址设置为0,这样寻址则从内存开始出寻址,跟没分段一样. 多级页表 一个进程的页表可能很大, 一次性加载到内存中会浪费空间, 因此产生了多级页表, 一次只加载所需要的页表,用于节省内存空间. 快表 快表（TLB）：提高变换速度→用高速缓冲存储器存放常用的页表项 MMU: 即内存管理单元，该硬件负责处理虚拟地址到物理地址的转化工作。快表也存储在MMU上。 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:2:1","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"2. 分段 ​ 分段是为了满足程序员在编写代码的时候的一些逻辑需求(比如数据共享，数据保 护，动态链接等)。分段内存管理当中，地址是二维的，一维是段号，二维是段内地址;由于分段管理中，每个段内部是连续内存分配，但是段和段之间是离散 分配的，因此也存在一个逻辑地址到物理地址的映射关系，相应的就是段表机制。 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:2:2","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"3. 分段分页的区别 分页对程序员是透明的，但是分段需要程序员显式划分每个段。 分页的地址空间是一维地址空间，分段是二维的。 页的大小不可变，段的大小可以动态改变。 分页主要用于实现虚拟内存，从而获得更大的地址空间;分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护。 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:2:3","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"4. 交换空间是什么 ​ 操作系统把物理内存(physical RAM)分成一块一块的小内存，每一块内存被称为页(page)。当内存资源不足时， Linux 把某些页的内容转移至硬盘上的一块空间上，以释放内存空间。硬盘上的那块空间叫做交换空间(swap space),而这一过程被称为交换(swapping)。物理内存和交换空间的总容量就是虚拟内存的可用容量。 ​ 用途: 物理内存不足时一些不常用的页可以被交换出去，腾给系统。 程序启动时很多内存页被用来初始化，之后便不再需要，可以交换出去。 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:2:4","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"5. 页面置换算法 ​ 在程序运行过程中，如果要访问的页面不在内存中，就发生缺页中断从而将该页调入内存中。此时如果内存已无空闲空间，系统必须从内存中调出一个页面到磁盘对换区中来腾出空间。 最佳算法:所选择的被换出的页面将是最长时间内不再被访问，通常可以保证获得最低的缺页率。这是一种理论上的算法，因为无法知道一个页面多长时间不再被访问。 (先进先出)FIFO: 思路:置换最先调入内存的页面，即置换在内存中驻留时间最久的页面。 实现:按照进入内存的先后次序排列成队列，从队尾进入，从队首删除。 特点:实现简单;性能较差，调出的页面可能是经常访问的 (最近最少使用)LRU: LRU将最近最久未使用的页面换出。 为了实现 LRU，需要在内存中维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。因为每次访问都需要更新链表，因此这种方式实现的 LRU代价很高。 特点:可能达到最优的效果，维护这样的访问链表开销比较大 时钟算法:时钟算法使用环形链表将页面连接起来，再使用一个指针指向最开始的页面。当需要进行页面置换时，时钟指针开始转动寻找可置换页面，直到遇到访问位为0的页号为止。在这个过程中，将遇到的访问位为1的页全部置为0.时钟指针寻找到要被置换的页面后，将新页放于那个位置。 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:2:5","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"6. 缓冲区 ​ 缓冲区又称为缓存，它是内存空间的一部分。也就是说，在内存空间中预留了一定的存储空间，这些存储空间用来缓冲输入或输出的数据，这部分预留的空间就叫做缓冲区 缓冲区溢出 冲区溢出是指当计算机向缓冲区填充数据时超出了缓冲区本身的容量，溢出的数据覆盖在合法数据上。 危害有以下两点: 程序崩溃，导致拒绝服务 跳转并且执行一段恶意代码造成缓冲区溢出的主要原因是程序中没有仔细检查用户输入 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:2:6","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"7. 虚拟内存 ​ 在操作系统中，进程是以页为单位加载到内存中的，按需分页是一种虚拟内存的管理方式。在使用请求分页的系统中，只有在尝试访问页面所在的磁盘并且该页面尚未在内存中时，也就发生了缺页异常，操作系统才会将磁盘页面复制到内存中。 虚拟内存就是说，让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。虚拟内存使用部分加载的技术，让一个进程或者资源的某些页面加载进内存，从而能够加载更多的进程，甚至能加载比内存大的进程，这样看起来好像内存变大了，这部分内存其实包含了磁盘或者硬盘，并且就叫做虚拟内存。 虚拟内存是一种对主存的抽象概念,其为每个进程提供了一个全物理内存的、一致的和私有的地址空间 虚拟内存主要能力: 它将主存看成是一个存储在磁盘上的地址空间的高速缓存，在主存中只保存活动区域，并根据需要 在磁盘和主存之间来回传送数据，通过这种方式，它高效地使用了主存。 操作系统为每个进程提供了一个独立的页表(一致的地址空间)，也就是独立的虚拟地 址空间。多个虚拟页面可以映射到同一个物理页面上。从而简化了内存管理。 它保护了每个进程的地址空间不被其他进程破坏。 为什么引入虚拟内存? 简化链接: 独立的地址空间允许每个进程的内存映像使用相同的基本格式，而不管代码和数据 实际存放在物理内存的何处 简化加载: 加载器从不在磁盘到内存实际复制任何数据，在每个页初次被引用时，虚拟内存系统会按照需要自动的调入数据页 简化共享: 一般来说, 每个进程有各自私有的代码，数据，堆栈，是不和其他进程共享的，这样OS创建页表，将虚拟页映射到不连续的物理页面。 某些情况下，需要进程来共享代码和数据。例如每个进程调用相同的操作系统内核代码， 或者C标准库函数。OS会把不同进程中适当的虚拟页面映射到相同的物理页面。 简化内存分配: 虚拟地址转换到物理地址的过程 ​ 虚拟地址由虚拟页号和页偏移两部分组成。通过虚拟地址的页面号，首先在快表中查询是否有该映射，查询成功，在页表中找到该页对应的物理地址。然后通过页物理地址+页偏移，得到真实的物理地址 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:2:7","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"8. 内存分配和回收 ​ 为了防止内存碎片，把所有的空闲页框分组为11个块链表，每个块链表分别包含大小为1，2，4，8，16，32，64，128，256，512和1024个连续页框的页框块。 ​ 假设要申请一个256个页框的块，先从256个页框的链表中查找空闲块，如果没有，就去512个页框的链表中找，找到了则将页框块分为2个256个页框的块，一个分配给应用，另外一个移到256个页框的链表中。如果512个页框的链表中仍没有空闲块，继续向1024个页框的链表查找，如果仍然没有，则返回错误。页框块在释放时，会主动将两个连续的页框块合并为一个较大的页框块。 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:2:8","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"系统管理 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:3:0","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"1. 内核态和用户态切换 系统调用: 系统调用是操作系统的最小功能单位，是操作系统提供的用户接口，系统调用本身是一种软中断. 异常: 也叫做内中断，是由错误引起的，如文件损坏、缺页故障等。 外部中断: 是通过两根信号线来通知处理器外设的状态变化，是硬中断。 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:3:1","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"2. 内核态和用户态的区别 处于内核态的进程可以访问系统的所有数据，并且cpu不会发生抢占。 处于用户态的进程只能受限得访问内存，并且cpu会被抢占。 操作系统从用户态跳转到内核态 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:3:2","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"3. OS启动过程 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:3:3","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"4. 系统调用 调用 说明 pid = fork() 创建与父进程相同的子进程 pid = waitpid(pid, \u0026statloc,options) 等待一个子进程终止 s = execve(name,argv,environp) 替换一个进程的核心映像 exit(status) 终止进程执行并返回状态 fork()， 它创建一个原有进程的副本，包括所有的文件描述符、寄存器等内容。fork 调用会返回一个值，在子进程中该值为 0 ，并且在父进程中等于子进程的 进程标识符(Process IDentified,PID)。使用返回的 PID，就可以看出来哪个是父进程和子进程。 waitpid：为了等待子进程完成，父进程需要执行 waitpid 系统调用，父进程会等待直至子进程终止（若有多个子进程的话，则直至任何一个子进程终止）。waitpid 可以等待一个特定的子进程，或者通过将第一个参数设为 -1 的方式，等待任何一个比较老的子进程。 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:3:4","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"Linux ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:0:0","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"基础命令 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:0","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"1. 怎么查看当前进程？怎么执行退出？怎么查看当前路径？ ​ 查看当前进程：ps、执行退出：exit、查看当前路径：pwd ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:1","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"2. 查看当前用户id [root@cx-ali ~]# id uid=0(root) gid=0(root) groups=0(root) # 用户id、组id、所属附加群组的id ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:2","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"3. 建立软链接和硬链接 ln -s src dist ln src dist 硬链接就是在目录下创建一个条目，记录着文件名与 inode 编号，这个 inode 就是源文件的 inode。删除任 意一个条目，文件还是存在，只要引用数量不为0。但是硬链接有限制，它不能跨越文件系统，也不能对目录 进行链接。 软链接又叫符号链接文件, 保存着源文件所在的绝对路径，在读取时会定位到源文件上，可以理解为 Windows的快捷方 式。当源文件被删除了，链接文件就打不开了。因为记录的是路径，所以可以为目录建立符号链接。 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:3","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"4. 查看文件命令 vi filename #编辑方式查看，可修改 cat filename #显示全部文件内容 more filename #分页显示文件内容 less filename #与 more 相似，更好的是可以往前翻页 tail filename #仅查看尾部，还可以指定行数 head filename #仅查看头部,还可以指定行数 # 一页一页查看大文件命令 cat filename | more ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:4","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"5.统计文件内容命令 [root@cx-ali ~]# wc -c -l -w .viminfo 47 148 770 .viminfo # -c 统计字节数 -l 统计行数 -w 统计字数 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:5","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"6. grep搜索命令 grep -i \"error\" #忽略大小写区分 grep -v \"grep\" #忽略grep命令本身，在文档中过滤掉包含有grep字符的行 grep [^string] filename #正则表达式搜索 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:6","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"7. 后台运行命令 ​ 使用 \u0026 在命令结尾来让程序自动运行。 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:7","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"8. 查看所有进程 ps -ef # system v 输出 ps -aux # bsd 格式输出 ps -ef | grep pid ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:8","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"9. 查看后台任务 jobs -l ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:9","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"10. 把后台任务调到前台执行使用什么命令?把停下的后台任务在后台执行起来用什么命令? fg # 把后台任务调到前台执行 bg # 把停下的后台任务在后台执行起来 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:10","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"11. 终止进程用什么命令? # kill [-s \u003c信息名称或编号\u003e][程序] 或 kill [-l \u003c信息编号\u003e] kill -9 pid kill -l # 查看系统支持的所有信号 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:11","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"12. 搜索文件的命令 # find \u003c指定目录\u003e \u003c指定条件\u003e \u003c指定动作\u003e # find 直接搜索磁盘，较慢。 find / -name \"string*\" locate 只加文件名 whereis # whereis [-bfmsu][-B \u003c目录\u003e...][-M \u003c目录\u003e...][-S \u003c目录\u003e...][文件...] #-b 只查找二进制文件。 #-B\u003c目录\u003e 只在设置的目录下查找二进制文件。-f 不显示文件名前的路径名称。 #-m 只查找说明文件。 #-M\u003c目录\u003e 只在设置的目录下查找说明文件。-s 只查找原始代码文件。 #-S\u003c目录\u003e 只在设置的目录下查找原始代码文件。-u 查找不包含指定类型的文件。 #which 指令会在 PATH 变量指定的路径中，搜索某个系统命令的位置，并且返回第一个搜索结果。 #-n 指定文件名长度，指定的长度必须大于或等于所有文件中最长的文件名。 #-p 与-n 参数相同，但此处的包括了文件的路径。-w 指定输出时栏位的宽度。 #-V 显示版本信息 #which 只能查可执行文件 #whereis 只能查二进制文件、说明文档，源文件等 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:12","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"13. 使用什么命令查看磁盘使用空间？ [root@cx-ali ~]# df -hl Filesystem Size Used Avail Use% Mounted on # 文件系统 容量 已用 可用 已用% 挂载点 devtmpfs 1.8G 0 1.8G 0% /dev # du 和 df 的定义，以及区别？ # du 显示目录或文件的大小 # df 显示每个\u003c文件\u003e所在的文件系统的信息，默认是显示所有文件系统。 # df 命令获得真正的文件系统数据，而 du 命令只查看文件系统的部分情况。 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:13","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"14. 查看网络 netstat netstat -nlpt # 查看tcp的网络信息 # 查看端口占用 lsof -i:port netstat -tunlp|grep port ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:14","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"15. 对命令取别名 alias la='ls -a' ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:15","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"16. awk cat /etc/passwd |awk -F ':' '{print $1\"\\t\"$7}' # -F 的意思是以':'分隔 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:16","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"17. 列出所有支持的命令 compgen -c ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:17","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"18. 不重启机器的条件下，有什么方法可以把所有正在运行的进程移除呢？ disown -r ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:18","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"19. 定时任务 crontab [-u username]　#省略用户表表示操作当前用户的crontab -e (编辑工作表) -l (列出工作表里的命令) -r (删除工作作) # 实例 * * * * * myCommand # 每分钟执行 3,15 8-11 * * * myCommand # 在上午8点到11点的第3和第15分钟执行 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:19","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"20. 查看路由表 route -n nestat -rn ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:20","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"21. 查看系统资源占用 top # top 命令 第一行 — 任务队列信息: top - 20:45:10 up 10:08, 1 user, load average: 0.00, 0.01, 0.05 内容 意义 20:45:10 当前时间 up 10:08 系统运行时间（10小时08分钟） 1 user 当前登录用户数 load average: 0.00, 0.01, 0.05 系统负载（任务队列的平均长度），分别是1分钟、5分钟、15分钟到现在的平均值 第二行 — 进程信息: Tasks: 105 total, 1 running, 104 sleeping, 0 stopped, 0 zombie 内容 意义 105 total 进程总数 1 running 正在运行的进程数 104 sleeping 睡眠进程数 0 stopped 停止进程数 0 zombie 僵尸进程数 第三行 — CPU信息: Cpu(s): 0.0%us, 0.1%sy, 0.0%ni, 99.9%id, 0.0%wa, 0.0%hi, 0.0%si, 0.0%st 内容 意义 0.0%us 用户空间占CPU百分比 0.1%sy 内核空间占CPU百分比 0.0%ni 用户进程空间内改变过优先级的进程占用CPU百分比 99.9%id 空闲CPU百分比 0.0%wa 等待输入输出的CPU时间百分比 0.0%hi 硬件中断占CPU时间百分比 0.0%si 软件终端占CPU时间百分比 0.0%st 提供给虚拟化环境执行占CPU时间百分比 第四行 — 内存信息: Mem: 288428k total, 257956k used, 30472k free, 40160k buffers 内容 意义 288428k total 物理内存总量 257956k used 使用的物理内存总量 30472k free 空闲内存总量 40160k buffers 用作内核缓存的内存量 第五行 — 内存交换区信息: Swap: 1046524k total, 3856k used, 1042668k free, 82000k cached 内容 意义 1046524k total 交换区总容量 3856k used 使用交换区的总量 1042668k free 空闲交换区总量 82000k cached 缓冲交换区总量 进程信息: PID 进程ID S 进程状态 USER 进程所有者用户名 %CPU CPU 时间占用百分比 PR 优先级 %MEM 进程使用物理内存百分比 NI nice值,负数表示高优先级 TIME+ 进程使用的CPU时间总计 VIRT 进程使用虚拟内存总量（以KB为单位） VIRT=SWAP+RES COMMAND 命令名/命令行 RES 进程使用的未被换出的物理内存大小（以KB为单位） RES=CODE+DATA SHR 共享内存总大小 lsof ​ lsof表示文件列表，我们可以知道哪个进程打开了哪个文件。 查看系统负载 [root@cx-ali ~]# w 12:57:02 up 27 days, 22:54, 1 user, load average: 0.01, 0.02, 0.05 USER TTY FROM LOGIN@ IDLE JCPU PCPU WHAT root pts/0 113.246.112.27 11:35 6.00s 0.06s 0.00s w [root@cx-ali ~]# uptime 12:57:34 up 27 days, 22:55, 1 user, load average: 0.00, 0.02, 0.05 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:21","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"22. 查看物理CPU和CPU核数 cat /proc/cpuinfo|grep -c 'physical id' # CPU数 cat /proc/cpuinfo|grep -c 'processor' # 核数 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:22","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"23. 查看内存信息 [root@centos6 ~ 10:57 #39]# vmstat procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 0 0 0 1783964 13172 106056 0 0 29 7 15 11 0 0 99 0 0 [root@cx-ali ~]# free -m total used free shared buff/cache available Mem: 3733516 1493136 196568 616 2043812 1960704 Swap: 0 # cat /proc/meminfo r即running，表示正在跑的任务数; b即blocked，表示被阻塞的任务数; si表示有多少数据从交换分区读入内存; so表示有多少数据从内存写入交换分区; bi表示有多少数据从磁盘读入内存; bo表示有多少数据从内存写入磁盘 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:23","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"24.网络修改 编辑/etc/sysconfig/network-scripts/ifcft-eth0 文件。重启网络服务service network restart 给一个网卡配置多个ip, 新建一个ifcfg-eth0:1文件,将DEVICE名称改为eth0:1 ,修改ip,重启网络服务即可 在文件 /etc/resolv.conf 中设置DNS ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:24","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"系统管理 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:2:0","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"1. 终端是哪个文件夹下的哪个文件？黑洞文件是哪个文件夹下的哪个命令？ 终端 /dev/tty 黑洞文件 /dev/null ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:2:1","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"2. Linux 中进程有哪几种状态？在 ps 显示出来的信息中，分别用什么符号表示的？ (D)不可中断状态：进程处于睡眠状态，但是此刻进程是不可中断的。不可中断， 指进程不响应异步信号.() (T)停止状态/跟踪状态：向进程发送一个 SIGSTOP 信号，它就会因响应该信号 而进入 TASK_STOPPED 状态;当进程正在被跟踪时，它处于 TASK_TRACED 这个特殊的状态。“正在被跟踪”指的是进程暂停下来，等待跟踪它的进程对它进行操作 就绪状态： (R)运行状态：在 run_queue 队列里的状态 (S)可中断睡眠状态：处于这个状态的进程因为等待某某事件的发生（比如等待 socket 连接、等待信号量），而被挂起 (Z)僵尸 状态：父亲没有通过 wait 系列的系统调用会顺便将子进程的尸体（task_struct）也释放掉 (X)退出状态 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:2:2","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"3. 进程管理 父子进程通信 父进程通过使用管道，套接字，消息队列等与子进程进行通信。 僵尸进程 这是一个执行已完成但进程表中甚至存在信息的进程。由于父进程需要读取子进程的状态，因此发生在父进程中。一旦使用wait系统调用完成了该任务，则僵尸进程将从进程表中删除。这被称为僵尸进程。 异步和非阻塞的区别 异步:调用在发出之后，这个调用就直接返回，不管有无结果;异步是过程。 非阻塞:关注的是程序在等待调用结果(消息，返回值)时的状态，指在不能立刻得到结果之前，该调用不会阻塞当前线程。 进程状态 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:2:3","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"4. 内存管理 buffer和cache如何区分? ​ **Cache是加速“读”，**而buffer是缓冲“写 ​ buffer和cache都是内存中的一块区域，当需要写数据到磁盘时，由于磁盘速度比较慢，所以CPU先把数据存进buffer，然后CPU去执行其他任务，buffer中的数据会定期写入磁盘；当需要从磁盘读入数据时，由于磁盘速度比较慢，可以把即将用到的数据提前存入cache，CPU直接从Cache中拿数据要快的多。 Swap空间 交换空间的主要功能是当全部的 RAM 被占用并且需要更多内存时，用磁盘空间代替 RAM 内存。Linux 计算机中的内存总量是 RAM + 交换分区，交换分区被称为虚拟内存. 内存数据段 预留内存地址（操作系统维护的内存地址，不可访问） 代码段（codesegment/textsegment）：又称文本段，用来存放指令，运行代码的一块内存空间，此空间大小在代码运行前就已经确定。 数据段（datasegment）：可读可写，存储初始化的全局变量和初始化的 static 变量。 bss段（bsssegment）：可读可写，存储未初始化的全局变量和未初始化的 static 变量。 rodata段：只读数据，常量区 栈（stack）：可读可写，存储的是函数或代码中的局部变量(非 static 变量)。 堆（heap）：可读可写，存储的是程序运行期间动态分配的 malloc/realloc 的空间。 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:2:4","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"源码和原理分析 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:3:0","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"1. 进程和线程API 进程API 线程API 描述 fork pthread_create 创建新的控制流 exit pthread_exit 从现有的控制流中退出 waitpid pthread_join 从控制流中得到退出状态 atexit pthread_cancel_push 注册在退出控制流时调用的函数 getpid pthread_self 获取控制流的ID abort pthread_cancel 请求控制流的非正常退出 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:3:1","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"2. select、poll、epoll原理 ​ IO 多路复用的本质是通过一种机制，让单个进程可以监视多个描述符，当发现某个描述符就绪之后，能够通知程序进行相应的读写操作。 ​ select，poll，epoll 都是同步 IO。所谓同步 IO，便是读写是阻塞的，需要在读写事件就绪后自己负责读写，而异步 IO 会把数据从内核拷贝到用户空间，并不需要自己负责读写。 select: ​ 遍历监听的fd_set（1024位的bitmap数组存储） ​ 调用 select 函数时，内核会根据 IO 状态对 fd_set 的内容进行修改，从而通知执行 select 函数的进程哪一个文件或者 Socket 是可读的。select 函数与同步阻塞模型并无过多区别，甚至还多出了一部分操作（监视 socket /调用 select 函数），导致更低的效率。 优点：用户可以在一个线程内同时处理多个 socket 的 IO 请求。用户可以注册多个 socket，然后调用 select 函数读取被激活的 socket，从而实现在同一个线程内同时处理多个 IO 请求，在这点上select 函数与同步阻塞模型不同，因为在同步阻塞模型中需要通过多线程才能达到这个目的。 缺点： 调用 select 函数时，需要把 fd__set_ 集合从用户态拷贝到内核态，当 fd_set 集合很大时，这个开销将会非常巨大 调用 select 函数时，需要在内核遍历传递进来的所有 fd__set_，当 fd_set 集合很大时，这个开销将会非常巨大 内核对被监控的 fd_set 集合大小做了限制 poll ​ 就是对fd_set（链表存储）没有1024的限制了 epoll ​ epoll采用IO多路复用技术,采用事件回调的方式，可以非常高效的处理数以百万计的Socket句柄. ​ epoll 使用一个文件描述符管理多个描述符，它将文件描述符的事件放入内核的一个事件表中，从而在用户空间和内核空间的复制操作只用实行一次即可。 ​ 在获取事件时，epoll 无需遍历整个被监听的描述符集，而是只需遍历被内核 IO 事件异步唤醒而加入 Ready 队列的描述符集合即可。因此，epoll 能显著提高程序在大量并发连接中只有少量活跃的情况下的系统 CPU 利用率。 核心数据结构 ​ epoll的核心数据结构在于红黑树+双向链表 首先调用epoll_create时内核帮我们在epoll文件系统里建了个file结点. 在内核cache里建立红黑树用于存储以后epoll_ctl传来的socket，当有新的socket连接来时，先遍历红黑书中有没有这个socket存在，如果有就立即返回，没有就插入红黑数 然后给内核中断处理程序注册一个钩子函数，每当有事件发生时就通过钩子函数把这些文件描述符放到用来存储就绪事件的链表中。 epoll_wait并不监听文件句柄，而是等待就绪链表不空or收到信号or超时这三种条件后返回。 优点: 没有最大并发连接的限制 不采取轮询的方式，效率高，只会处理活跃的连接，与连接总数无关 select、poll、epoll 总结对比 效率: select 只知道有 IO 事件发生，却不知道是哪几个流，只能采取轮询所有流的方式，故其具有 O(n) 的无差别轮询复杂度，处理的流越多，无差别轮询时间就越长 poll 与 select 并无区别，它的时间复杂度也是 O(n) epoll 会将哪个流发生了怎样的 IO 事件通知我们（当描述符就绪时，系统注册的回调函数会被调用，将就绪描述符放到 readyList 里面），它是事件驱动的，其时间复杂度为 O(1) 操作方式: select 和 poll 都是采取遍历的方式，而 epoll 则是采取了回调的方式 底层实现 select 的底层实现为数组，poll 的底层实现为链表，而 epoll 的底层实现为红黑树 最大链接 select 的最大连接数为 1024 或 2048，而 poll 和 epoll 是无上限的 对文件描述符的拷贝 select 和 poll 每次被调用时都会把描述符集合从用户态拷贝到内核态 epoll 在调用 epoll_ctl 时会拷贝进内核并保存，之后每次 epoll_wait 时不会拷贝 性能 epoll 在绝大多数情况下性能远超 select 和 poll，但在连接数少并且连接都十分活跃的情况下，select 和 poll 的性能可能比 epoll 好，因为 epoll 的通知机制需要很多函数回调 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:3:2","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"3. 编译 编译过程 预处理阶段：处理以 # 开头的预处理命令； 编译阶段：翻译成汇编文件； 汇编阶段：将汇编文件翻译成可重定位目标文件； 链接阶段：将可重定位目标文件和 printf.o 等单独预编译好的目标文件进行合并，得到最终的可执行目标文件。 动态链接和静态链接的过程 静态链接 符号解析：每个符号对应于一个函数、一个全局变量或一个静态变量，符号解析的目的是将每个符号引用与一个符号定义关联起来。 重定位：链接器通过把每个符号定义与一个内存位置关联起来，然后修改所有对这些符号的引用，使得它们指向这个内存位置。 将所有需要的二进制代码都包含到可执行文件中. 动态链接 在给定的文件系统中一个库只有一个文件，所有引用该库的可执行目标文件都共享这个文件，它不会被复制到引用它的可执行文件中； 在内存中，一个共享库的 .text 节（已编译程序的机器代码）的一个副本可以被不同的正在运行的进程共享。 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:3:3","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"Golang ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:0:0","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"基础数据结构 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:0","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"1. go的指针和c的指针 ​ 相同点: ​ 运算符相同, \u0026为取地址, *为解引用 ​ 不同点: 数组名和数组首地址. c语言中arr、\u0026arr[0]为数组的首个元素地址,单位偏移量为元素大小; \u0026arr为数组的首地址,单位偏移量为数组大小. golang中\u0026arr[0]和\u0026arr与c语言中相同, 但是arr表示为整个数组的值. // C int arr[5] = {1, 2, 3, 4, 5}; // Go // 需要指定长度，否则类型为切片 arr := [5]int{1, 2, 3, 4, 5} 指针运算. c语言中指针本质为无符号整数,代表内存地址, 可以进行加减运算. Golang中指针为 *uint32类型非数字,不可以加减运算. Go 标准库中提供了一个 unsafe 包用于编译阶段绕过 Go 语言的类型系统，直接操作内存 uintptr : Go 的内置类型。是一个无符号整数，用来存储地址，支持数学运算。常与 unsafe.Pointer 配合做指针运算 unsafe.Pointer : 表示指向任意类型的指针，可以和任何类型的指针互相转换（类似 C 语言中的 void* 类型的指针），也可以和 uintptr 互相转换 unsafe.Sizeof : 返回操作数在内存中的字节大小，参数可以是任意类型的表达式，例如 fmt.Println(unsafe.Sizeof(uint32(0)))的结果为 4 unsafe.Offsetof : 函数的参数必须是一个字段 x.f，然后返回 f 字段相对于 x 起始地址的偏移量，用于计算结构体成员的偏移量 golang中不能被寻址的类型:(不可变的，临时结果和不安全的。) 常量、字符串、函数或方法、map中的元素… ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:1","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"2. String的底层结构 type StringHeader struct { // 16 字节 Data uintptr Len int } 本质为byte类型的数组 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:2","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"3.slice和array的区别和底层结构 ​ array 为定长数组, slice为不定长数组 底层结构 type slice struct { array unsafe.Pointer // array指针指向底层array的某一个元素，其决定slice所能控制的内存片段的起始位置，这里需要注意的是，array不一定指向底层array的首元素，这与slice的创建有关。 len int //len 代表当前切片的长度,限定slice可直接通过索引(下标)存取元素的范围 cap int // cap 是当前切片的容量,表示slice所引用的array片段的真实大小 } // slice 扩张: slice扩容规则是：在1024字节以内，扩容一倍，大于1024时，增加cap的1/4 初始化方式: // 数组 // 切片 a := [3]int{1,2,3} //指定长度 s := make([]int, 3) //指定长度 a := [...]int{1,2,3} //不指定长度 s := []int{1,2,3} //不指定长度 函数传递 当切片和数组作为参数在函数（func）中传递时，数组传递的是值，而切片传递的是指针。因此当传入的切片在函数中被改变时，函数外的切片也会同时改变。相同的情况，函数外的数组则不会发生任何变化。 nil切片和空切片最大的区别在于指向的数组引用地址是不一样的 所有的空切片指向的数组引用地址都是一样的 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:3","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"4. Map底层结构 用于存储一系列无序的键值对,hashmap作为底层实现 Map基本数据结构: // hashmap的简称 type hmap struct { count int //元素个数 flags uint8 //标记位 B uint8 //buckets的对数, 说明包含2^B个bucket noverflow uint16 //溢出的bucket的个数 hash0 uint32 //hash种子 buckets unsafe.Pointer //指向buckets数组的指针，数组个数为2^B oldbuckets unsafe.Pointer //扩容时使用，buckets长度是oldbuckets的两倍 nevacuate uintptr //扩容进度，小于此地址的buckets已经迁移完成 extra *mapextra //扩展信息 } //当map的key和value都不是指针，并且size都小于128字节的情况下，会把 bmap 标记为不含指针，这样可以避免gc时扫描整个hmap。但是，我们看bmap其实有一个overflow的字段，是指针类型的，破坏了bmap不含指针的设想，这时会把overflow移动到extra字段来。 type mapextra struct { overflow *[]*bmap oldoverflow *[]*bmap //用于扩容 nextOverflow *bmapx //prealloc的地址 } // bucket type bmap struct { tophash [bucketCnt]uint8 //bucketCnt = 8,用于记录8个key哈希值的高8位，这样在寻找对应key的时候可以更快，不必每次都对key做全等判断 // keys [8]keytype // values [8]valuetype // pad uintptr // overflow uintptr } ​ hmap结构图 如何扩容 ​ 触发条件: 1. 装填因子大于6.5(装填因子为2^B); 2. overflow bucket 太多 ​ 解决办法: 双倍扩容:扩容采取了一种称为“渐进式”地方式，原有的 key 并不会一次性搬迁完毕，每次最多只会搬迁2 个 bucket.(条件1) 等量扩容:重新排列，极端情况下，重新排列也解决不了，map成了链表，性能大大降低，此时哈希种子 hash0 的设置，可以降低此类极端场景的发生。(条件2) 赋值操作 在查找key之前，会做异常检测，校验map是否未初始化，或正在并发写操作，如果存在，则抛出异常：（这就是为什么map 并发写回panic的原因） 需要计算key 对应的hash 值，如果buckets 为空（初始化的时候小于一定长度的map 不会初始化数据）还需要初始化一个bucket 通过hash 值，获取对应的bucket。如果map 还在迁移数据，还需要在oldbuckets中找对应的bucket，并搬迁到新的bucket。 拿到bucket之后，还需要按照链表方式一个一个查，找到对应的key， 可能是已经存在的key，也可能需要新增。 插入数据前，会先检查数据太多了，需要扩容，如果需要扩容，那就从第③开始拿到新的bucket，并查找对应的位置。 如果没有空的位置，那就需要在链表后追加一个bucket，拿到kv 最后更新tophash 和 key 的字面值, 并解除hashWriting 约束 数据迁移 先要判断当前bucket是不是已经转移。 (oldbucket 标识需要搬迁的bucket 对应的位置) 如果没有被转移，那就要迁移数据了。数据迁移时，可能是迁移到大小相同的buckets上，也可能迁移到2倍大的buckets上。这里xy 都是标记目标迁移位置的标记：x 标识的是迁移到相同的位置，y 标识的是迁移到2倍大的位置上。 确定bucket位置后，需要按照kv 一条一条做迁移。（目的就是清除空闲的kv） 数据查找 ​ Go语言中 map采用的是哈希查找表，由一个 key 通过哈希函数得到哈希值，64 位系统中就生成一个64bit 的哈希值，由这个哈希值将 key 对应到不同的桶bucket中，当有多个哈希映射到相同的的桶中时，使用链表解决哈希冲突。key 经过 hash 后共64 位，根 据 hmap中 B的值，计算它到底要落在哪个桶时，桶的数量为2^B，如 B=5，那么用64 位最后5 位表示第几号桶，在用 hash 值的高8 位确定在 bucket 中的存储位置，当前 bmap中的 bucket 未找到，则查询对应的 overflow bucket，对应位置有数据则对比完整的哈希值，确定是否是要查找的数据。如果两个不同的 key 落在的同一个桶上，hash 冲突使用链表法接近，遍历 bucket 中的 key ;如果当前处于 map进 行了扩容，处于数据搬移状态，则优先从 oldbuckets 查找。 根据key计算出hash值。 如果存在old table, 首先在old table中查找，如果找到的bucket已经evacuated，转到步骤3。 反之，返回其对应的value。 在new table中查找对应的value。 map 顺序读取方法 ​ 给key排序后读取 set实现 map[string]bool //会有bool的空间占用，可以替换成空结构体 type void struct{} var member void set := make(map[string]void) set[\"test\"] = member ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:4","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"5. Channel 底层结构 type hchan struct { qcount uint // 队列中的数据个数 dataqsiz uint // 环形队列的大小，channel本身是一个环形队列 buf unsafe.Pointer // 存放实际数据的指针，用unsafe.Pointer存放地址，为了避免gc elemsize uint16 closed uint32 // 标识channel是否关闭 elemtype *_type // 数据 元素类型 sendx uint // send的 index recvx uint // recv 的 index recvq waitq // 阻塞在 recv 的队列 sendq waitq // 阻塞在 send 的队列 lock mutex // 锁 } channel本身是一个环形缓冲区，数据存放到堆上面，channel的同步是通过锁实现的，并不是想象中的lock-free的方式，channel中有两个队列，一个是发送阻塞队列，一个是接收阻塞队列。当向一个已满的channel发送数据会被阻塞，此时发送协程会被添加到sendq中，同理，当向一个空的channel接收数据时，接收协程也会被阻塞，被置入recvq中。 ​ 创建channel 缓冲区大小为0: 只需要分配hchansize大小的内存就ok; 缓冲区大小不为0，且channel的类型不包含指针: buf为hchanSize+元素大小*元素个数的连续内存 缓冲区大小不为0，且channel的类型包含指针，则不能简单的根据元素的大小去申请内存，需要通过mallocgc去分配内存(即内存逃逸) channel特性 \u003e 1. 给一个 nil channel 发送数据，造成永远阻塞 从一个 nil channel 接收数据，造成永远阻塞 关闭一个 nil channel 将会发生 panic 给一个已经关闭的 channel 发送数据，引起 panic 当 c.closed != 0 则为通道关闭，此时执行写，源码提示直接 panic，输出的内容就是上面提到的 \"send on closed channel\"。 从一个已经关闭的 channel 接收数据，如果缓冲区中为空，则返回一个零值 c.closed != 0 \u0026\u0026 c.qcount == 0 指通道已经关闭，且缓存为空的情况下（已经读完了之前写到通道里的值） 如果接收值的地址 ep 不为空 那接收值将获得是一个该类型的零值 typedmemclr 会根据类型清理相应地址的内存 这就解释了上面代码为什么关闭的 chan 会返回对应类型的零值 无缓冲的 channel 是同步的，而有缓冲的 channel 是非同步的 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:5","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"6. interface // interface 分为空接口和非空接口，分别用eface 和 iface实现。 // eface type eface struct { _type *_type data unsafe.Pointer //指向数据的数据指针 } //_type 定义 type _type struct { size uintptr // 类型的大小 ptrdata uintptr // size of memory prefix holding all pointers hash uint32 // 类型的Hash值 tflag tflag // 类型的Tags align uint8 // 结构体内对齐 fieldalign uint8 // 结构体作为field时的对齐 kind uint8 // 类型编号 定义于runtime/typekind.go alg *typeAlg // 类型元方法 存储hash和equal两个操作。map key便使用key的_type.alg.hash(k)获取hash值 gcdata *byte // GC相关信息 str nameOff // 类型名字的偏移 ptrToThis typeOff } // iface type iface struct { tab *itab data unsafe.Pointer } // 非空接口的类型信息 type itab struct { inter *interfacetype // 接口定义的类型信息 _type *_type // 接口实际指向值的类型信息 link *itab bad int32 inhash int32 fun [1]uintptr // 接口方法实现列表，即函数地址列表，按字典序排序 } // 非空接口类型，接口定义，包路径等。 type interfacetype struct { typ _type pkgpath name mhdr []imethod // 接口方法声明列表，按字典序排序 } // 接口的方法声明 type imethod struct { name nameOff // 方法名 ityp typeOff // 描述方法参数返回值等细节 } 非空interface与eface不同的，所有空interface的结构是一样的，而非空interface每个都不一样，因为彼此定义的方法可以不一样的，所以相对eface，iface的定义复杂多。 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:6","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"7. reflect t := reflect.TypeOf(stru).Elem() for i := 0; i \u003c t.NumField(); i++ { // 获取Tag t.Field(i).Name, t.Field(i).Tag.Get(\"json\"), t.Field(i).Tag.Get(\"otherTag\") } //reflect.TypeOf(stru).Elem()获取指针指向的值对应的结构体内容。 //NumField()可以获得该结构体的含有几个字段。 //遍历结构体内的字段，通过t.Field(i).Tag.Get(\"json\")可以获取到tag为json的字段。 json包里不能导出私有变量的tag是因为json包里认为私有变量为不可导出的Unexported，所以跳过获取名为json的tag的内容 动态类型判断: 类型开关是在运行时检查变量类型的最佳方式 //1. 类型识别 var data interface{} = \"hello\" strValue, ok := data.(string) if ok { fmt.Printf(\"%s is string type\\n\", strValue) } //2. 类型获取 var str string = \"hello\" fmt.Println(reflect.TypeOf(str)) //3. 类型判断 func typeJudge(x interface{}) { switch x.(type){ case int,int8,int64,int16,int32,uint,uint8,uint16,uint32,uint64: fmt.Println(\"整型变量\") case float32,float64: fmt.Println(\"浮点型变量\") case []byte,[]rune,string: fmt.Println(\"字符串变量\") default: fmt.Println(\"不清楚...\") } } ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:7","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"8. new 和make的区别 new(T) 返回的是 T 的指针：new(T) 为一个 T 类型新值分配空间并将此空间初始化为 T 的零值，返回的是新值的地址，也就是 T 类型的指针 *T，该指针指向 T 的新分配的零值。 make 只能用于 slice,map,channel，返回值是经过初始化之后的 T 的引用 make 分配空间后，会进行初始化 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:8","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"9.struct能不能比较 ​ go中的struct能不能比较取决于struct内部存储的数据，如果struct中的字段都是可比较的，那么该struct就是可比较的，如果其中的字段是不可比较的，那么该struct不可比较。slice,map就无法比较。 struct字段顺序要一致才能比较 数组的长度是类型的一部分，如果数组长度不同，无法比较。 interface{}类型的比较包含该接口变量存储的值和值的类型两部分组成，分别称为接口的动态类型和动态值。只有动态类型和动态值都相同时，两个接口变量才相同。 slice在go设计之初为了和数组区分，不让其可以比较（浅层指针比较没有意义） 1、引用类型，比较地址没有意义。 2、切片有len，cap，比较的维度不好衡量，因此go设计的时候就不允许切片可比较。 3、map的value, 函数均可以包含slice,因而均不可比较 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:9","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"10. defer defer关键字定义的函数是在调用函数返回之后执行，而不是在代码块退出之后执行。defer的执行顺序是先创建的后执行。看做是一个 FILO(First In Last Out) 栈. 所有传入defer函数的参数都是在创建的时候预先计算处理的，而不是调用函数退出的时候计算的 defer等到包含它的程序返回时(包含它的函数执行了return语句、运行到函数结尾自动返回、对应的goroutine panic）defer函数才会被执行。通常用于资源释放、打印日志、异常捕获等 defer 关键字对应的 runtime.deferproc 会将延迟调用函数与调用方所在 Goroutine 进行关联。所以当程序发生崩溃时只会调用当前 Goroutine 的延迟调用函数 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:10","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"11. init函数 整个golang程序初始化顺序 先调用osinit，再调用schedinit，创建就绪队列并新建一个G，接着就是mstart 即设置好本地线程存储，设置好main函数参数，根据环境变量GOMAXPROCS设置好使用的procs，初始化调度器和内存管理等等。 main.main之前的准备 sysmon :Go语言的runtime库会初始化一些后台任务，其中一个任务就是sysmon. 它由物理线程运行.主要处理两个事件：对于网络的epoll以及抢占式调度的检测. 释放闲置超过5 分钟的 span 物理内存; 如果超过2 分钟没有垃圾回收，强制执行; 将长时间未处理的 netpoll 添加到全局队列; 向长时间运行的 G 任务发出抢占调度(超过10ms的 g，会进行 retake); 收回因 syscall 长时间阻塞的 P; scavenger: 只是由goroutine运行.用于执行heap的内存回收给os ​ 先于main函数执行，实现包级别的一些初始化操作 ​ 主要作用: 初始化不能采用初始化表达式初始化的变量; 程序运行前的注册 实现sync.Once功能 ​ 主要特点: init函数先于main函数自动执行，不能被其他函数调用； init函数没有输入参数、返回值； 每个包可以有多个init函数； 包的每个源文件也可以有多个init函数，这点比较特殊； 同一个包的init执行顺序，golang没有明确定义，编程时要注意程序不要依赖这个执行顺序 不同包的init函数按照包导入的依赖关系决定执行顺序 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:11","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"12.包的循环引用 为什么不允许循环引用 ​ 加快编译速度、规范框架设计，使项目结构更加清晰明了 解决办法: 1. mvc 结构,将包规划好 1. 新建公共接口包(父包), 将需要循环调用的函数或方法抽象为接口 1. 新建公共组合包(子包), 在组合包中组合调用 1. 全局存储需要相互依赖的函数, 通过关键字进行调用 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:12","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"13. SELECT select可以用来等待多个channel的可读可写，其中select中的case表达式必须都是channel的读写操作。 当存在default时，select执行的就是非阻塞收发，当不存在时，必须等待某一个channel可读或可写。 当多个channel都可读可写时，会随机选择一个分支。 如果有一个channel已关闭,则每次都执行到这个case; 如果只有一个case,则出现死循环. var c1, c2, c3 chan int var i1, i2 int select { case i1 = \u003c-c1: fmt.Printf(\"received \", i1, \" from c1\\n\") case c2 \u003c- i2: fmt.Printf(\"sent \", i2, \" to c2\\n\") case i3, ok := (\u003c-c3): // same as: i3, ok := \u003c-c3 if ok { fmt.Printf(\"received \", i3, \" from c3\\n\") } else { fmt.Printf(\"c3 is closed\\n\") } default: fmt.Printf(\"no communication\\n\") } x, ok := \u003c-ch,如果ch已经关闭,则ok为false,置ch为nil,则可以继续阻塞. 保证case的优先级 for { select { case \u003c-stopCh: return case job1 := \u003c-ch1: fmt.Println(job1) case job2 := \u003c-ch2: priority: // label for { select { case job1 := \u003c-ch1: fmt.Println(job1) default: break priority } } fmt.Println(job2) } } ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:13","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"14. for range 循环 { for_temp := slice1 len_temp := len(for_temp) for index_temp := 0; index_temp \u003c len_temp; index_temp++ { value_temp := for_temp[index_temp] // index = index_temp // value = value_temp // origin body } } // 新的语句块结束 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:14","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"15. Panic和Recover panic ​ panic的作用是制造一次宕机，宕机就代表程序运行终止，但是已经“生效”的(当前 Goroutine )延迟函数仍会执行（即已经压入栈的defer延迟函数，panic之前的）。 // 嵌套崩溃 func main() { defer fmt.Println(\"in main\") defer func() { defer func() { panic(\"panic again and again\") }() panic(\"panic again\") }() panic(\"panic once\") } $ go run main.go in main panic: panic once panic: panic again panic: panic again and again goroutine 1 [running]: ... exit status 2 recover ​ recover 只有在发生 panic 之后调用才会生效。然而在上面的控制流中，recover 是在 panic 之前调用的，并不满足生效的条件，所以需要在 defer 中使用 recover 关键字。 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:15","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"16. golang函数调用规则 通过堆栈传递参数，入栈的顺序是从右到左，而参数的计算是从左到右 函数返回值通过堆栈传递并由调用者预先分配内存空间； 调用函数时都是传值，接收方会对入参进行复制再计算； ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:16","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"17. go相比于c++线程的优势 开销更小 切换更方便 C线程的上下文切换涉及到模式转换-从用户态到内核态 go的协程中的上下文切换只是在用户态的操作 用户可控制（用户态） 高级调度策略: 任务窃取和减少阻塞 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:17","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"进阶原理 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:2:0","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"1. GMP模型和golang调度原理 ​ go中调度采用GMP算法，G表示一个goroutine，M表示machine一个真实的线程，P表示processor表示一个调度器 P由启动时环境变量 $GOMAXPROCS 或者是由 runtime 的方法 GOMAXPROCS() 决定。这意味着在程序执行的任意时刻都只有 $GOMAXPROCS 个 goroutine 在同时运行。最大256 M的最大限制是10000个，但是内核很难支持这么多的线程数，所以这个限制可以忽略; 一般为CPU数 在P没有足够的M绑定运行时,则会创建一个M;每次创建一个M都会同步创建一个G0，它负责调度其它的G，每个M都有一个G0 每个 P有个局部队列，局部队列保存待执行的 goroutine(流程2)，当 M绑定的 P的的局部队列已经满了之后就 会把 goroutine 放到全局队列(流程2-1) 每个 P和一个 M绑定，M是真正的执行 P中 goroutine 的实体(流程3)，M 从绑定的 P中的局部队列获取 G来 执行 当 M绑定的 P的局部队列为空时，M会从全局队列获取到本地队列来执行 G(流程3.1)，当从全局队列中没有获取到可执行的 G时候，M会从其他 P 的局部队列中偷取 G来执行(流程3.2)，这种从其他 P偷的方式称为 work stealing 当 G因系统调用(syscall)阻塞时会阻塞 M，此时 P会和 M解绑即 hand off，并寻找新的 idle 的 M，若没有 idle 的 M就会新建一个 M(流程5.1)。 当 G因 channel 或者 network I/O 阻塞时，不会阻塞 M，M会寻找其他 runnable 的 G;当阻塞的 G恢复后会重新进入 runnable 进入 P队列等待执行(流程5.3) Work stealing ​ 当本线程无可运行的 G 时，尝试从其他线程绑定的 P 偷取 G，而不是销毁线程。 Hand off 本线程因为 G 进行系统调用阻塞时，线程释放绑定的 P，把 P 转移给其他空闲的线程执行。 利用并行：GOMAXPROCS 设置 P 的数量，最多有 GOMAXPROCS 个线程分布在多个 CPU 上同时运行。GOMAXPROCS 也限制了并发的程度，比如 GOMAXPROCS = 核数/2，则最多利用了一半的 CPU 核进行并行。 抢占：在 coroutine 中要等待一个协程主动让出 CPU 才执行下一个…在 Go 中，一个 goroutine 最多占用 CPU 10ms，防止其他 goroutine 被饿死，这就是 goroutine 不同于 coroutine 的一个地方。 如果没有P或怎样? 调度器把 G都分配到 M上，不同的 G在不同的 M并发运行时，都需要向系统申请资源，比如堆栈内存等，因为资源 是全局的，就会因为资源竞争照成很多性能损耗。 GMP 调度过程中存在哪些阻塞 I/O, select block on syscall channel 等待锁 runtime.Gosched() 抢占式调度 sysmon。这个函数会周期性地做epoll操作，同时它还会检测每个P是否运行了较长时间。如果检测到某个P状态处于syscall超过了一个sysmon的时间周期(20us)，并且还有其它可运行的任务，则切换P。 如果检测到某个P的状态为running，并且它已经运行了超过10ms，则会将P的当前的G的stackguard设置为StackPreempt。这个操作其实是相当于加上一个标记，通知这个G在合适时机进行调度。 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:2:1","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"2. 垃圾回收(GC) 垃圾回收常用方法 1. 引用计数(reference counting) ​ 如C++中的智能指针:shard_ptr; 优点：简单直接，回收速度快 缺点：需要额外的空间存放计数，无法处理循环引用的情况； 标记-清除(mark and sweep) ​ 标记出所有不需要回收的对象，在标记完成后统一回收掉所有未被标记的对象。 优点：简单直接，速度快，适合可回收对象不多的场景 缺点：会造成不连续的内存空间（内存碎片），导致有大的对象创建的时候，明明内存中总内存是够的，但是空间不是连续的造成对象无法分配； 分代搜集(generation) ​ java的jvm 就使用的分代回收的思路。在面向对象编程语言中，绝大多数对象的生命周期都非常短。分代收集的基 本思想是，将堆划分为两个或多个称为代(generation)的空间。新创建的对象存放在称为新生代(young generation)中(一般来说，新生代的大小会比 老年代小很多)，随着垃圾回收的重复执行，生命周期较⻓的对 象会被提升(promotion)到老年代中(这里用到了一个分类的思路，这个是也是科学思考的一个基本思路)。 ​ 因此，新生代垃圾回收和老年代垃圾回收两种不同的垃圾回收方式应运而生，分别用于对各自空间中的对象执行垃 圾回收。新生代垃圾回收的速度非常快，比老年代快几个数量级，即使新生代垃圾回收的频率更高，执行效率也仍 然比老年代垃圾回收强，这是因为大多数对象的生命周期都很短，根本无需提升到老年代。 GOLANG的GC策略 ​ golang采用无分代（对象没有代际之分）、不整理（回收过程中不对对象进行移动与整理）、并发（与用户代码并发执行）的三色标记清扫算法。 ​ 原因: golang的内存分配算法tcmalloc，基本上不会造成内存碎片，因此不需要使用对象整理。 golang对于存活时间短的对象直接分配在栈上面，go程死亡后栈会被回收，不需要gc的参与。 Go 以 STW 为界限，可以将 GC 划分为五个阶段：：栈扫描（开始时STW）;第一次标记（并发）;第二次标记（STW）;清除（并发）,归还 三色标记清扫法 white，grep，black;白色为需要清理的数据，黑色则不要清理。从根对象（全局变量、执行栈、寄存器(主要是指针)）开始循环，能访问到的标记为灰色，然后从灰色队列开始遍历，自身变成黑色。后续没有访问到的直接清理掉。 没有STW的三色标记法 条件1: 一个白色对象被黑色对象引用 (白色被挂在黑色下) 条件2: 灰色对象与它之间的可达关系的白色对象遭到破坏 (灰色同时丢了该白色) 当以上两个条件同时满足时, 就会出现对象丢失现象! 屏障保护 为了减少STW的影响,又防止三色标记法出现对象丢失现象,出现屏障保护技术; 插入写屏障 ​ 垃圾收集器将根对象指向 A 对象标记成黑色并将 A 对象指向的对象 B 标记成灰色；用户程序修改 A 对象的指针，将原本指向 B 对象的指针指向 C 对象，这时触发写屏障将 C 对象标记成灰色；一种相对保守的屏障技术，它会将有存活可能的对象都标记成灰色以满足强三色不变性. ​ 写屏障只会针对堆进行限制. 删除写屏障 ​ 垃圾收集器将根对象指向 A 对象标记成黑色并将 A 对象指向的对象 B 标记成灰色；用户程序将 A 对象原本指向 B 的指针指向 C，触发删除写屏障，但是因为 B 对象已经是灰色的，所以不做改变；用户程序将 B 对象原本指向 C 的指针删除，触发删除写屏障，白色的 C 对象被涂成灰色； ​ 缺点是开始收集器时需要STW快照全局对象 混合写屏障 操作流程: ​ 1、GC开始将栈上的对象全部扫描并标记为黑色(之后不再进行第二次重复扫描，无需STW)， ​ 2、GC期间，任何在栈上创建的新对象，均为黑色。 ​ 3、被删除的对象标记为灰色。(删除写屏障) ​ 4、被添加的对象标记为灰色。(插入写屏障) 该写屏障会将被覆盖的对象标记成灰色并在当前栈没有扫描时将新对象也标记成灰色; 只需要针对堆内存扫描即可. GC触发机制 主动: 通过调用 runtime.GC 来触发 GC，此调用阻塞式地等待当前 GC 运行完毕。 被动: 使用系统监控(sysmon)，当超过两分钟没有产生任何 GC 时，强制触发 GC。 使用步调（Pacing）算法，其核心思想是控制内存增长的比例。(步调算法可以通过gogc传参设置量控制gc的时间。也是go中唯一对外开放的配置gc的参数。默认值为100，也就是达到百分百后触发gc机制) GC细节 增量垃圾收集 ​ 增量地标记和清除垃圾，降低应用程序暂停的最长时间； ​ 传统的垃圾收集算法会在垃圾收集的执行期间暂停应用程序，一旦触发垃圾收集，垃圾收集器会抢占 CPU 的使用权占据大量的计算资源以完成标记和清除工作，然而很多追求实时的应用程序无法接受长时间的 STW。增量式（Incremental）的垃圾收集是减少程序最长暂停时间的一种方案，它可以将原本时间较长的暂停时间切分成多个更小的 GC 时间片，虽然从垃圾收集开始到结束的时间更长了，但是这也减少了应用程序暂停的最大时间。 并发垃圾收集 ​ 利用多核的计算资源，在用户程序执行时并发标记和清除垃圾； GC 如何调优 通过 go tool pprof 和 go tool trace 等工具 控制内存分配的速度，限制 goroutine 的数量，从而提高赋值器对 CPU 的利用率。 减少并复用内存，例如使用 sync.Pool 来复用需要频繁创建临时对象，例如提前分配足够的内存来降低多余的 拷贝。 需要时，增大 GOGC 的值，降低 GC 的运行频率。 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:2:2","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"3. 内存模型和内存管理 内存逃逸 ​ golang程序变量会携带有一组校验数据，用来证明它的整个生命周期是否在运行时完全可知。如果变量通过了这些校验，它就可以在栈上分配。否则就说它 逃逸 了，必须在堆上分配 内存逃逸的情况: 在方法内把局部变量指针返回 发送指针或带有指针的值到 channel 中 在一个切片上存储指针或带指针的值 slice 的背后数组被重新分配了，因为 append 时可能会超出其容量( cap );slice 初始化的地方在编译时是可以知道的，它最开始会在栈上分配。如果切片背后的存储要基于运行时的数据进行扩充，就会在堆上分配。 **在 interface 类型上调用方法。**在 interface 类型上调用方法都是动态调度的 —— 方法的真正实现只能在运行时知道。 查看内存逃逸的情况: go build -gcflags=-m main.go 避免内存逃逸 Noescape函数, 可以在逃逸分析中隐藏一个指针。让这个指针在逃逸分析中不会被检测为逃逸。 func noescape(p unsafe.Pointer) unsafe.Pointer { x := uintptr(p) return unsafe.Pointer(x ^ 0) } noescape() 函数的作用是遮蔽输入和输出的依赖关系。使编译器不认为 p 会通过 x 逃逸， 因为 uintptr() 产生的引用是编译器无法理解的。 内置的 uintptr 类型是一个真正的指针类型，但是在编译器层面，它只是一个存储一个 指针地址 的 int 类型。代码的最后一行返回 unsafe.Pointer 也是一个 int。 闭包 闭包是由函数及其相关引用环境组合而成的实体(即：闭包=函数+引用环境)。 func f(i int) func() int { return func() int { i++ return i } } 不可在栈上分配: 变量i是函数f中的局部变量，假设这个变量是在函数f的栈中分配的，是不可以的。因为函数f返回以后，对应的栈就失效了，f返回的那个函数中变量i就引用一个失效的位置了。所以闭包的环境中引用的变量不能够在栈上分配。 因此以上代码在汇编中就类似于: type Closure struct { F func()() i *int } 在堆中创建结构体, 将函数地址赋值给F, 闭包环境的局部变量在堆上开辟空间,写值后再将地址赋值给i; 返回闭包时并不是单纯返回一个函数，而是返回了一个结构体，记录下函数返回地址和引用的环境中的变量地址 栈空间管理 ​ Go语言的运行环境(runtime)会在goroutine需要的时候动态地分配栈空间，而不是给每个goroutine分配固定大小的内存空间。这样就避免了需要程序员来决定栈的大小。当创建一个goroutine的时候，它会分配一个8KB的内存空间来给goroutine的栈使用。 分段栈 ​ 当检测到函数需要更多栈时，分配一块新栈，旧栈和新栈使用指针连接起来，函数返回就释放。 每个Go函数的开头都有一小段检测代码。这段代码会检查我们是否已经用完了分配的栈空 间。如果是的话，它会调用 morestack 函数。 morestack 函数分配一块新的内存作为栈空间，并且在这块栈空间 的底部填入各种信息(包括之前的那块栈地址)。在分配了这块新的栈空间之后，它会重试刚才造成栈空间不足的函数。这个过程叫做栈分裂(stack split). 2. 在新分配的栈底有个lessstack的函数指针; 当我们从那个函数返回时，它会跳转到 lessstack 。 lessstack 函 数会查看在栈底部存放的数据结构里的信息，然后调整栈指针(stack pointer)。这样就完成了从新的栈块到老的 栈块的跳转。接下来，新分配的这个块栈空间就可以被释放掉了。 问题: 多次循环调用同一个函数会出现“hot split”问题, 即如果函数产生的返回在一个循环或者递归中, 会频繁的alloc/free,导致严重性能问题 每次分配和释放都要额外消耗 连续栈 连续栈的实现方式：当检测到需要更多栈时，分配一块比原来大一倍的栈，把旧栈数据copy到新栈，释放旧栈 栈的扩缩容何时触发? goroutine运行并用完栈空间的时候，与之前的方法一样，栈溢出检查会被 触发 栈的扩缩容大小 扩容为原来的两倍,缩容为原来的1/2 栈的扩缩容过程中做了哪些事? 重新申请一块新栈，然后把旧栈的数据复制到新栈。协程占用的物理内存完全被替换了，而Go在运行时会把指针保存到内存里面，例如：gp.sched.ctxt ，gp._defer ，gp._panic，包括函数里的指针。这部分指针值会被转换成整数型uintptr，然后 + delta进行调整 如果栈空间发现不够用，会调用stackalloc分配一块新的栈，大小比原来大一倍进行扩容 ;栈的缩容主要是发生在GC期间. 内存泄漏 字符串截取: 解决办法: string和[]byte 转化 切片截取 解决办法: append 没有重置丢失的子切片元素中的指针: 原切片元素为指针类型，原切片被截取后，丢失的子切片元素中的指针元素未被置空，导致内存泄漏 解决办法:元素置空 函数数组传参: 由于数组为值类型,赋值和函数传参会复制整个数组; 如果数组较大,短时间内传递多次,会消耗大量内存又来不及gc,就会产生临时性的内存泄漏 解决办法:采用指针传递、使用切片 gorouting :有些编码不当的情况下，goroutine被长期挂住，导致该协程中的内存也无法被释放，就会造成永久性的内存泄漏。例如协程结束时协程中的channel没有关闭，导致一直阻塞；例如协程中有死循环 可见并发和sync包的使用 定时器: 定时器未到触发时间，该定时器不会被gc回收，从而导致临时性的内存泄漏，而如果定时器一直在创建，那么就造成了永久性的内存泄漏了 解决办法:创建timer定时器，每次需要启动定时器的时候，使用Reset方法重置定时器 外部资源没有办法GC的: 如打开的文件句柄 内存泄漏实例 func main() { num := 6 for index := 0; index \u003c num; index++ { resp, _ := http.Get(\"https://www.baidu.com\") _, _ = ioutil.ReadAll(resp.Body) } fmt.Printf(\"此时goroutine个数= %d\\n\", runtime.NumGoroutine()) }// 没有执行resp.Body.Close(), 一共泄漏了3个goroutine 虽然执行了 6 次循环，而且每次都没有执行 Body.Close() ,就是因为执行了ioutil.ReadAll()把内容都读出来了，连接得以复用，因此只泄漏了一个读goroutine和一个写goroutine，最后加上main goroutine，所以答案就是3个goroutine 正常情况下我们的代码都会执行 ioutil.ReadAll()，但如果此时忘了 resp.Body.Close()，确实会导致泄漏。但如果你调用的域名一直是同一个的话，那么只会泄漏一个 读goroutine 和一个写goroutine，这就是为什么代码明明不规范但却看不到明显内存泄漏的原因。 内存对齐 一个非空结构体包含有尾部size为0的变量(字段)，如果不给它分配内存，那么该变量(字段)的指针地址将指向一个超出该结构体内存范围的内存空间。这可能会导致内存泄漏，或者在内存垃圾回收过程中，程序crash掉。 为什么对齐? 操作系统并非一个字节一个字节访问内存，而是按2, 4, 8这样的字长来访问。当被访问的数据长度为 n 字节且该数据地址为n字节对齐，那么操作系统就可以高效地一次定位到数据，无需多次读取、处理对齐运算等额外操作. struct 的对齐是：如果类型 t 的对齐保证是 n，那么类型 t 的每个值的地址在运行时必须是 n 的倍数。 struct 内字段如果填充过多，可以尝试重排，使字段排列更紧密，减少内存浪费 零大小字段要避免作为 struct 最后一个字段，会有内存浪费(零大小也会补一个对齐保证的长度,防止指针错误,内存泄漏) 对齐规则: 对于任意类型的变量 x ，unsafe.Alignof(x) 至少为 1。 对于 struct 结构体类型的变量 x，计算 x 每一个字段 f 的 unsafe.Alignof(x.f)，unsafe.Alignof(x) 等于其中的最大值。 对于 array 数组类型的变量 x，unsafe.Alignof(x) 等于构成数组的元素类型的对齐倍数。 没有任何字段的空 struct{} 和没有任何元素的 array 占据的内存空间大小为 0，不同的大小为 0 的变量可能指向同一块地址。 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:2:3","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"4. 并发和sync包 Data Race ​ 同步访问共享数据是处理数据竞争的一种有效的方法. 可以使用 go run - race 或者 go build -race来进行静态检测。其在内部的实现是,开启多个协程执行同一个命令， 并且记录下每个变 量的状态. go test -race mypkg // 测试包 go run -race mysrc.go // 编译和运行程序 go build -race mycmd // 构建程序 go install -race mypkg // 安装程序 解决数据竞争的方法: 互斥锁: sync.Mutex、sync.WaitGroup 通道: channel ,channel的效率是高于互斥锁的 并发模型 通过channel通知实现并发控制 通过sync包中的WaitGroup实现并发控制 a. Add(), 可以添加或减少 goroutine的数量. b. Done(), 相当于Add(-1). c. Wait(), 执行后会堵塞主线程，直到WaitGroup 里的值减至0. 注意,在 WaitGroup 第一次使用后，不能被拷贝 func main(){ wg := sync.WaitGroup{} for i := 0; i \u003c 5; i++ { wg.Add(1) go func(wg sync.WaitGroup, i int) { fmt.Printf(\"i:%d\", i) wg.Done() }(wg, i) } wg.Wait() fmt.Println(\"exit\") } // error: all goroutines are asleep - deadlock! 因为 wg 给拷⻉传递到了 goroutine 中，导致只有 Add 操作，其实 Done操作是在 wg 的副本执行的。 可以将 传入类型改为 *sync.WaitGroup, 或者使用闭包 Context 上下文 context 包主要是用来处理多个 goroutine 之间共享数据，及多个 goroutine 的管理。Context 对象是线程安全的，你可以把一个 Context 对象传递给任意个数的 gorotuine，对它执行取消 操作时， 所有 goroutine 都会接收到取消信号。 web编程中，一个请求对应多个goroutine之间的数据交互、同步数据，主要是共享数据，如token 超时控制：请求被取消或是处理时间太长，这有可能是使用者关闭了浏览器或是已经超过了请求方规定的超时时间，请求方直接放弃了这次请求结果。这时，所有正在为这个请求工作的 goroutine 需要快速退出，因为它们的“工作成果”不再被需要了。在相关联的 goroutine 都退出后，系统就可以回收相关的资源。 上下文控制 CAS Compare And Swap，直译就是比较交换;是一种实现并发算法时常用到的技术. 作用是让 CPU先进行比较两 个值是否相等，然后原子地更新某个位置的值，其实现方式是给予硬件平台的汇编指令， func CompareAndSwapUint32(addr *uint32, old, new uint32) (swapped bool) 缺陷: CAS在共享资源竞争比较激烈的时候，每个goroutine会容易处于自旋状态，影响效率，在竞争激烈的时候推荐使用锁。 无法解决ABA问题 ABA问题是无锁结构实现中常见的一种问题，可基本表述为： 进程P1读取了一个数值A P1被挂起(时间片耗尽、中断等)，进程P2开始执行 P2修改数值A为数值B，然后又修改回A P1被唤醒，比较后发现数值A没有变化，程序继续执行。 Sync包 互斥锁: sync.Mutex //Mutex 是互斥锁， 零值是解锁的互斥锁， 首次使用后不得复制互斥锁。 type Mutex struct { state int32 sema uint32 } //Locker表示可以锁定和解锁的对象。 type Locker interface { Lock() Unlock() } //锁定当前的互斥量 //如果锁已被使用，则调用goroutine //阻塞直到互斥锁可用。 func (m *Mutex) Lock() //对当前互斥量进行解锁 //如果在进入解锁时未锁定m，则为运行时错误。 //锁定的互斥锁与特定的goroutine无关。 //允许一个goroutine锁定Mutex然后安排另一个goroutine来解锁它。 func (m *Mutex) Unlock() Mutex的几种状态: mutexLocked —表示互斥锁的锁定状态; mutexWoken —表示从正常模式被从唤醒; mutexStarving —当前的互斥锁进入饥饿状态; Mutex的正常模式和饥饿模式: 正常模式**(**非公平锁): 正常模式下，所有等待锁的 goroutine 按照 FIFO(先进先出)顺序等待。唤醒的 goroutine 不会直接拥有锁，而是会 和新请求锁的 goroutine 竞争锁的拥有。但是和正在使用cpu的goroutine相比很大可能失败. 饥饿模式**(**公平锁): 一个等待的 goroutine 超过1ms没有获取锁,或者当前队列只剩下一个 g 的时候那么它将会把锁转 变为饥饿模式。 ​ 饥饿模式下，直接由 unlock 把锁交给等待队列中排在第一位的 G(队头)，同时，饥饿模式下，新进来的 G不会参与 抢锁也不会进入自旋状态，会直接进入等待队列的尾部,这样很好的解决了老的 g 一直抢不到锁的场景 自旋锁: 循环等待锁的释放,一直处于内核态,不进行内核态和用户态切换. 锁已被占用，并且锁不处于饥饿模式 积累的自旋次数小于最大自旋次数(active_spin=4)。 cpu 核数大于1。 有空闲的 P 当前 goroutine 所挂载的 P下，本地待运行队列为空。 ​ 读写锁: sync.RWMutex 1 多个写操作之间是互斥的 2 写操作与读操作之间也是互斥的 3 多个读操作之间不是互斥的 // RWMutex是一个读/写互斥锁，可以由任意数量的读操作或单个写操作持有。 // RWMutex的零值是未锁定的互斥锁。 //首次使用后，不得复制RWMutex。 //如果goroutine持有RWMutex进行读取而另一个goroutine可能会调用Lock，那么在释放初始读锁之前， goroutine不应该期望能够获取读锁定。 //特别是，这种禁止递归读锁定。 这是为了确保锁最终变得可用; 阻止的锁定会阻止新读操作获取锁定。 type RWMutex struct { w Mutex //如果有待处理的写操作就持有 uint32 writerSem int32 // 写操作等待读操作完成的信号量 readerSem uint32 //读操作等待写操作完成的信号量 readerCount int32 // 待处理的读操作数量 readerWait int32 // number of departing readers } //对读操作的锁定 func (rw *RWMutex) RLock() //对读操作的解锁 func (rw *RWMutex) RUnlock() //对写操作的锁定 func (rw *RWMutex) Lock() //对写操作的解锁 func (rw *RWMutex) Unlock() //返回一个实现了sync.Locker接口类型的值，实际上是回调rw.RLock and rw.RUnlock. func (rw *RWMutex) RLocker() Locker ​ 通过记录 readerCount 读锁的数量来进行控制，当有一个写锁的时候，会将读锁数量设置为负数1«30。目的是让 新进入的读锁等待写锁之后释放通知读锁。同样的写锁也会等等待之前的读锁都释放完毕，才会开始进行后续的操 作。而等写锁释放完之后，会将值重新加上1«30,并通知刚才新进入的读锁(rw.readerSem)，两者互相限制。 RWMutex 的读锁不要用于递归调用，比较容易产生死锁。 写锁被解锁后，所有因操作锁定读锁而被阻塞的 goroutine 会被唤醒，并都可以成功锁定读锁。 读锁被解锁后，在没有被其他读锁锁定的前提下，所有因操作锁定写锁而被阻塞的 goroutine，其中等待时间 最⻓的一个 goroutine 会被唤醒。 安全锁: Sync.Map golang中的sync.Map是并发安全的，其实也就是sync包中golang自定义的一个名叫Map的结构体。它通过空间换时间的方式，使用 read 和 dirty 两个 map 来进行读写分离，降低锁时间来提高效率。 type Map struct { mu Mutex // 该锁用来保护dirty read atomic.Value // readOnly// 存读的数据，因为是atomic.value类型，只读类型，所以它的读是并发安全的 dirty map[interface{}]*entry //包含最新的写入的数据，并且在写的时候，会把read中未被删除的数据拷⻉到该dirty中，因为是普通的map存在并发安全问题，需要用到上面的mu字段。 misses int // 从read读数据失败的时候，会将该字段+1，当等于len(misses)的时候，会将dirty拷⻉到read中(从而提升读的性能)。 } func (m *Map) Delete(key i","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:2:4","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"5. golang编译过程 go build -gcflags -S main.go 可以生成中间的汇编代码 词法分析：源码翻译成token（分词） 语法分析：将token序列输出成AST结构 词义分析： 类型检查（类型推断等） 中间码生产：对于不同的操作系统和硬件进行处理；提高后端编译的重用 代码优化： 并行性，充分利用现在多核计算机的特性 流水线，cpu 有时候在处理 a 指令的时候，还能同时处理 b 指令 指令的选择，为了让 cpu 完成某些操作，需要使用指令，但是不同的指令效率有非常大的差别，这里会进行指令优化 利用寄存器与高速缓存，我们都知道 cpu 从寄存器取是最快的，从高速缓存取次之。这里会进行充分的利用 机器码生产： 先生成汇编代码，其汇编器使用GOARCH参数进行初始化，然后调用对应架构便携的特定方法来生成机器码，从而跨平台。 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:2:5","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"}]