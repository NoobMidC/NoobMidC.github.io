[{"categories":[],"content":"数据结构 ","date":"2022-09-13","objectID":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/:0:0","tags":[],"title":"数据结构","uri":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"categories":[],"content":"B树 和 B+树 多路平衡查找树; 即B树 ![截屏2022-09-13 下午5.37.58](https://raw.githubusercontent.com/NoobMidC/pics/main/截屏2022-09-13 下午5.37.58.png) B+树 B+跟B树不同B+树的非叶子节点不保存关键字记录的指针，只进行数据索引，这样使得B+树每个非叶子节点所能保存的关键字大大增加； B+树叶子节点保存了父节点的所有关键字记录的指针，所有数据地址必须要到叶子节点才能获取到。所以每次数据查询的次数都一样； B 和 B+树的区别 B+树的层级更少：相较于B树B+每个非叶子节点存储的关键字数更多，树的层级更少所以查询数据更快； B+树查询速度更稳定：B+所有关键字数据地址都存在叶子节点上，所以每次查找的次数都相同所以查询速度要比B树更稳定; B+树天然具备排序功能：B+树所有的叶子节点数据构成了一个有序链表，在查询大小区间的数据时候更方便，数据紧密性很高，缓存的命中率也会比B树高。 B+树全节点遍历更快：B+树遍历整棵树只需要遍历所有的叶子节点即可，而不需要像B树一样需要对每一层进行遍历，这有利于数据库做全表扫描 B树相对于B+树的优点是，如果经常访问的数据离根节点很近，而B树的非叶子节点本身存有关键字其数据的地址，所以这种数据检索的时候会要比B+树快。 B+的应用场景 B/B+树是为了磁盘或其它存储设备而设计的一种平衡多路查找树；与红黑树相比,在相同的的节点的情况下,一颗B/B+树的高度远远小于红黑树的高度 ","date":"2022-09-13","objectID":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/:1:0","tags":[],"title":"数据结构","uri":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"categories":[],"content":"平衡二叉树 ​ 平衡二叉查找树：简称平衡二叉树。也称为 AVL 树。windows对进程地址空间的管理用到了AVL; 它具有如下几个性质: 可以是空树。 假如不是空树，任何一个结点的左子树与右子树都是平衡二叉树，并且高度之差的绝对值不超过 1。 左节点比根节点小, 右节点比根节点小 ","date":"2022-09-13","objectID":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/:2:0","tags":[],"title":"数据结构","uri":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"categories":[],"content":"红黑树 ​ 学习二叉搜索树、平衡二叉树时，我们不止一次提到，二叉搜索树容易退化成一条链; 这时，查找的时间复杂度从O ( l o g 2 N ) 也将退化成O ( N ) ; 引入对左右子树高度差有限制的平衡二叉树，保证查找操作的最坏时间复杂度也为O ( l o g 2 N ) AVL的左右子树高度差不能超过1，每次进行插入/删除操作时，几乎都需要通过旋转操作保持平衡 在频繁进行插入/删除的场景中，频繁的旋转操作使得AVL的性能大打折扣 红黑树通过牺牲严格的平衡，换取插入/删除时少量的旋转操作，整体性能优于AVL 红黑树插入时的不平衡，不超过两次旋转就可以解决；删除时的不平衡，不超过三次旋转就能解决 红黑树的红黑规则，保证最坏的情况下，也能在O ( l o g 2 N ) 时间内完成查找操作。 红黑树规则: 节点不是红色就是黑色，根节点是黑色 叶节点为黑色（叶节点是指末梢的空节点 Nil或Null） 一个节点为红色，则其两个子节点必须是黑色的（根到叶子的所有路径，不可能存在两个连续的红色节点） 每个节点到叶子节点的所有路径，都包含相同数目的黑色节点（相同的黑色高度） ","date":"2022-09-13","objectID":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/:3:0","tags":[],"title":"数据结构","uri":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"categories":[],"content":"AVL和红黑树的区别 和红黑树相比，AVL树是严格的平衡二叉树，平衡条件必须满足。 平衡二叉树相当于全局平衡，而红黑树相当于局部平衡。维护全局平衡耗费的代价较高 ","date":"2022-09-13","objectID":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/:3:1","tags":[],"title":"数据结构","uri":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"categories":[],"content":"红黑树和哈希表对比 红黑树是有序的，Hash是无序的，根据需求来选择。 红黑树占用的内存更小（仅需要为其存在的节点分配内存），而Hash事先应该分配足够的内存存储散列表,即使有些槽可能弃用 红黑树查找和删除的时间复杂度都是O(logn)，Hash查找和删除的时间复杂度都是O(1)。 ","date":"2022-09-13","objectID":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/:3:2","tags":[],"title":"数据结构","uri":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"categories":[],"content":"红黑树应用场景 多路复用技术的Epoll,其核心结构是红黑树 + 双向链表。IO多路复用epoll的实现采用红黑树组织管理sockfd，以支持快速的增删改查. ngnix中,用红黑树管理timer,因为红黑树是有序的,可以很快的得到距离当前最小的定时器. 广泛应用在C++STL中，比如map和set，Java的TreeMap ","date":"2022-09-13","objectID":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/:3:3","tags":[],"title":"数据结构","uri":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"categories":[],"content":"Hash表 ","date":"2022-09-13","objectID":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/:4:0","tags":[],"title":"数据结构","uri":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"categories":[],"content":"Hash函数构造方法 直接定制法——仅适用于地址大小=关键字的情况 该方法构造的Hash函数为线性函数， H(key)=a*key+b。这种哈希函数构造简单，且不会产生哈希冲突，但限制较大。 除留余数法——最常用 H（key）=key MOD p 数字分析法——数字位数大、且有规律可循（事先知道数据分布） 平方取中位数法——数据位数小（事先不知道数据分布） 折叠法——数字位数大（事先不知道数据分布） ","date":"2022-09-13","objectID":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/:4:1","tags":[],"title":"数据结构","uri":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"categories":[],"content":"Hash冲突解决方法 开放地址方法 ​ 关键字key的哈希地址p=H（key）出现冲突时，以p为基础，产生另一个哈希地址p1，如果p1仍然冲突，再以p为基础，产生另一个哈希地址p2，…，直到找出一个不冲突的哈希地址pi ，将相应元素存入其中; 链式地址法 ​ 将所有哈希地址为i的元素构成一个称为同义词链的单链表，并将单链表的头指针存在哈希表的第i个单元中，因而查找、插入和删除主要在同义词链中进行。链地址法适用于经常进行插入和删除的情况。 建立公共溢出区 ​ 将Hash表分为基本表和溢出表两部分，在基本表中发生冲突的元素都放入溢出表中。 再哈希法 ​ 当哈希地址Hi=RH1（key）发生冲突时，再计算Hi=RH2（key）……，直到冲突不再产生。这种方法不易产生聚集，但增加了计算时间。 ","date":"2022-09-13","objectID":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/:4:2","tags":[],"title":"数据结构","uri":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"categories":[],"content":"排序算法 基础排序 冒泡排序(稳定) func sortArray(nums []int) []int { // 冒泡排序，比较交换，稳定算法，时间O(n^2), 空间O(1) // 每一轮遍历，将该轮最大值放到后面，同时小的往前冒 // 从而形成后部是有序区 // compare and swap for i:=0;i\u003clen(nums);i++ { // 适当剪枝，len()-i到最后的部分都是有序区，避免再排 for j:=1;j\u003clen(nums)-i;j++ { if nums[j-1] \u003e nums[j] { nums[j-1], nums[j] = nums[j], nums[j-1] } } } return nums } 选择排序(不稳定) func sortArray(nums []int) []int { // 选择排序，比较交换，不稳定算法，时间O(n^2)，空间O(1) // 每一轮遍历，该轮的最小值前挪，从而形成前面部分是有序区 // compare and swap for i:=0;i\u003clen(nums);i++ { // 剪枝前面部分，比较后面部分 for j:=i+1;j\u003clen(nums);j++ { if nums[i] \u003e nums[j] { nums[i], nums[j] = nums[j], nums[i] } } } return nums } 插入排序(稳定) func sortArray(nums []int) []int { // 插入排序，比较交换，稳定算法，时间O(n^2)，空间O(1) // 0-\u003elen方向，每轮从后往前比较，相当于找到合适位置，插入进去 // 数据规模小的时候，或基本有序，效率高 n := len(nums) for i := 1; i \u003c n; i++ { tmp := nums[i] j := i - 1 for j \u003e= 0 \u0026\u0026 nums[j] \u003e tmp { //左边比右边大 nums[j+1] = nums[j] //右移1位 j-- //扫描前一个数 } nums[j+1] = tmp //添加到小于它的数的右边 } return nums } 改良排序 希尔排序(不稳定) func sortArray(nums []int) []int { // 希尔排序，比较交换，不稳定算法，时间O(nlog2n)最坏O(n^2), 空间O(1) // 改进插入算法 // 每一轮按照间隔插入排序，间隔依次减小，最后一次一定是1 /* 主要思想： 设增量序列个数为k，则进行k轮排序。每一轮中， 按照某个增量将数据分割成较小的若干组， 每一组内部进行插入排序；各组排序完毕后， 减小增量，进行下一轮的内部排序。 */ gap := len(nums)/2 for gap \u003e 0 { for i:=gap;i\u003clen(nums);i++ { j := i for j-gap \u003e= 0 \u0026\u0026 nums[j-gap] \u003e nums[j] { nums[j-gap], nums[j] = nums[j], nums[j-gap] j -= gap } } gap /= 2 } return nums } 归并排序(稳定) // 递归实现归并算法 func sortArray(nums []int) []int { // 归并排序，基于比较，稳定算法，时间O(nlogn)，空间O(logn) | O(n) // 基于递归的归并-自上而下的合并， // 都需要开辟一个大小为n的数组中转 // 将数组分为左右两部分，递归左右两块，最后合并，即归并 merge := func(left, right []int) []int { res := make([]int, len(left)+len(right)) var l,r,i int // 通过遍历完成比较填入res中 for l \u003c len(left) \u0026\u0026 r \u003c len(right) { if left[l] \u003c= right[r] { res[i] = left[l] l++ } else { res[i] = right[r] r++ } i++ } // 如果left或者right还有剩余元素，添加到结果集的尾部 copy(res[i:], left[l:]) copy(res[i+len(left)-l:], right[r:]) return res } var sort func(nums []int) []int sort = func(nums []int) []int { if len(nums) \u003c= 1 { return nums } // 拆分递归与合并 // 分割点 mid := len(nums)/2 left := sort(nums[:mid]) right := sort(nums[mid:]) return merge(left, right) } return sort(nums) } // 非递归实现归并算法 func sortArray(nums []int) []int { if len(nums) \u003c= 1 {return nums} merge := func(left, right []int) []int { res := make([]int, len(left)+len(right)) var l,r,i int // 通过遍历完成比较填入res中 for l \u003c len(left) \u0026\u0026 r \u003c len(right) { if left[l] \u003c= right[r] { res[i] = left[l] l++ } else { res[i] = right[r] r++ } i++ } // 如果left或者right还有剩余元素，添加到结果集的尾部 copy(res[i:], left[l:]) copy(res[i+len(left)-l:], right[r:]) return res } i := 1 //子序列大小初始1 res := make([]int, 0) // i控制每次划分的序列长度 for i \u003c len(nums) { // j根据i值执行具体的合并 j := 0 // 按顺序两两合并，j用来定位起始点 // 随着序列翻倍，每次两两合并的数组大小也翻倍 for j \u003c len(nums) { if j+2*i \u003e len(nums) { res = merge(nums[j:j+i], nums[j+i:]) } else { res = merge(nums[j:j+i], nums[j+i:j+2*i]) } // 通过index控制每次将合并的数据填入nums中 // 重填入的次数和合并及二叉树的高度相关 index := j for _, v := range res { nums[index] = v index++ } j = j + 2*i } i *= 2 } return nums } 快速排序(不稳定) func quickSort(nums []int, head, tail int) { if head \u003e= tail { return } l, r := head, tail mid := (r + l) / 2 pivot := nums[mid] for l \u003c= r { for l \u003c= r \u0026\u0026 nums[l] \u003c pivot { l ++ } for l \u003c= r \u0026\u0026 nums[r] \u003e pivot { r -- } if l \u003c= r { nums[l], nums[r] = nums[r], nums[l] l++ r-- } } quickSort(nums, head, r) quickSort(nums, l, tail) } 堆排序(不稳定) func sortArray(nums []int) []int { // 堆排序-大根堆，升序排序，基于比较交换的不稳定算法，时间O(nlogn)，空间O(1)-迭代建堆 // 遍历元素时间O(n)，堆化时间O(logn)，开始建堆次数多些，后面次数少 // 主要思路： // 1.建堆，从非叶子节点开始依次堆化，注意逆序，从下往上堆化 // 建堆流程：父节点与子节点比较，子节点大则交换父子节点，父节点索引更新为子节点，循环操作 // 2.尾部遍历操作，弹出元素，再次堆化 // 弹出元素排序流程：从最后节点开始，交换头尾元素，由于弹出，end--，再次对剩余数组元素建堆，循环操作 // 建堆函数，堆化 var heapify func(nums []int, root, end int) heapify = func(nums []int, root, end int) { // 大顶堆堆化，堆顶值小一直下沉 for { // 左孩子节点索引 child := root*2 + 1 // 越界跳出 if child \u003e end { return } // 比较左右孩子，取大值，否则child不用++ if child \u003c end \u0026\u0026 nums[child] \u003c= nums[child+1] { child++ } // 如果父节点已经大于左右孩子大值，已堆化 if nums[root] \u003e nums[child] { return } // 孩子节点大值上冒 nums[root], nums[child] = nums[child], nums[root","date":"2022-09-13","objectID":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/:5:0","tags":[],"title":"数据结构","uri":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"categories":[],"content":"设计模式的分类 创建型模式：单例模式、抽象工厂模式、建造者模式、工厂模式、原型模式。 结构型模式：适配器模式、桥接模式、装饰模式、组合模式、外观模式、享元模式、代理模式。 行为型模式：模版方法模式、命令模式、迭代器模式、观察者模式、中介者模式、备忘录模式、解释器模式、状态模式、策略模式、职责链模式、访问者模式。 ","date":"2022-09-13","objectID":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/:6:0","tags":[],"title":"数据结构","uri":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"categories":[],"content":"单例模式的使用场景 资源共享的情况下，避免由于资源操作时导致的性能或损耗等。如日志文件，应用配置。 控制资源的情况下，方便资源之间的互相通信。如线程池等。 ","date":"2022-09-13","objectID":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/:7:0","tags":[],"title":"数据结构","uri":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"categories":[],"content":"设计原则七大原则 开放封闭原则:对扩展开放，对修改关闭。在程序需要进行拓展的时候，不能去修改原有的代码，实现 一个热插拔的效果。 单一职责原则:一个类、接口或方法只负责一个职责，降低代码复杂度以及变更引起的风险。 依赖倒置原则:针对接口编程，依赖于抽象类或接口而不依赖于具体实现类。 接口隔离原则:将不同功能定义在不同接口中实现接口隔离。 里氏替换原则:任何基类可以出现的地方，子类一定可以出现。 迪米特原则:每个模块对其他模块都要尽可能少地了解和依赖，降低代码耦合度。 合成复用原则:尽量使用组合(has-a)/聚合(contains-a)而不是继承(is-a)达到软件复用的目的。 ","date":"2022-09-13","objectID":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/:8:0","tags":[],"title":"数据结构","uri":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"categories":[],"content":"工厂模式 ","date":"2022-09-13","objectID":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/:9:0","tags":[],"title":"数据结构","uri":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"categories":[],"content":"简单工厂 ​ 简单工厂模式指由一个工厂对象来创建实例,适用于工厂类负责创建对象较少的情况。工厂方法模式指定义一个创建对象的接口，让接口的实现类决定创建哪种对象，让类的实例化推迟到子 类中进行。 ","date":"2022-09-13","objectID":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/:9:1","tags":[],"title":"数据结构","uri":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"categories":[],"content":"抽象工厂模式 ​ 抽象工厂模式指提供一个创建一系列相关或相互依赖对象的接口，无需指定它们的具体类。 ","date":"2022-09-13","objectID":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/:9:2","tags":[],"title":"数据结构","uri":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"categories":[],"content":"单例模式 // 饿汉式实现: 如果singleton创建初始化比较复杂耗时时，加载时间会延长。 type singleton struct{} var ins *singleton = \u0026singleton{} func GetIns() *singleton{ return ins } // 懒汉式实现: 非线程安全。当正在创建时，有线程来访问此时ins = nil就会再创建，单例类就会有多个实例了。 type singleton struct{} var ins *singleton func GetIns() *singleton{ if ins == nil { ins = \u0026singleton{} } return ins } // 懒汉加锁 type singleton struct{} var ins *singleton var mu sync.Mutex func GetIns() *singleton{ mu.Lock() defer mu.Unlock() if ins == nil { ins = \u0026singleton{} } return ins } ","date":"2022-09-13","objectID":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/:10:0","tags":[],"title":"数据结构","uri":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"categories":[],"content":"代理模式 ​ 代理模式为其他对象提供一种代理以控制对这个对象的访问。优点是可以增强目标对象的功能，降低代码耦合度，扩展性好。缺点是在客户端和目标对象之间增加代理对象会导致请求处理速度变慢，增加系统复杂度。 静态代理:在程序运行前就已经存在代理类的字节码文件，代理类和委托类的关系在运行前就确定了。 动态代理:程序运行期间动态的生成，所以不存在代理类的字节码文件。代理类和委托类的关系是在程 序运行时确定。 ","date":"2022-09-13","objectID":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/:11:0","tags":[],"title":"数据结构","uri":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"categories":[],"content":"适配器模式 ​ 适配器模式将一个接口转换成客户希望的另一个接口，使接口不兼容的那些类可以一起工作。(多态) ","date":"2022-09-13","objectID":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/:12:0","tags":[],"title":"数据结构","uri":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"categories":[],"content":"模板模式 ​ 模板模式定义了一个操作中的算法的骨架，并将一些步骤延迟到子类，适用于抽取子类重复代码到公共父类。 ​ 可以封装固定不变的部分，扩展可变的部分。但每一个不同实现都需要一个子类维护，会增加类的数量。 ","date":"2022-09-13","objectID":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/:13:0","tags":[],"title":"数据结构","uri":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"categories":[],"content":"装饰器模式 ​ 装饰者模式可以动态地给对象添加一些额外的属性或行为，即需要修改原有的功能，但又不愿直接去修 改原有的代码时，设计一个Decorator套在原有代码外面; 如struct 直接引用其他的struct ","date":"2022-09-13","objectID":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/:14:0","tags":[],"title":"数据结构","uri":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"categories":[],"content":"观察者模式 ​ 观察者模式表示的是一种对象与对象之间具有依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。 ","date":"2022-09-13","objectID":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/:14:1","tags":[],"title":"数据结构","uri":"/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"categories":[],"content":"Docker ","date":"2022-08-28","objectID":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/:0:0","tags":[],"title":"容器技术","uri":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"categories":[],"content":"Docker架构 K8S:CRI(Container Runtime Interface): 用于对接容器 Client: 客户端;操作docker服务器的客户端(命令行或者界面) Docker_Host:Docker主机;安装Docker服务的主机 Docker_Daemon:后台进程;运行在Docker服务器的后台进程 Containers:容器;在Docker服务器中的容器(一个容器一般是一个应用实例，容器间互相隔离) Images:镜像、映像、程序包;Image是只读模板，其中包含创建Docker容器的说明。容器是由Image运 行而来，Image固定不变。 Registries:仓库;存储Docker Image的地方。 ","date":"2022-08-28","objectID":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/:1:0","tags":[],"title":"容器技术","uri":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"categories":[],"content":"Docker和虚拟机 Docker守护进程可以直接与主操作系统进行通信，为各个Docker容器分配资源；它还可以将容器与主操作系统隔离，并将各个容器互相隔离。虚拟机启动需要数分钟，而Docker容器可以在数毫秒内启动。由于没有臃肿的从操作系统，Docker可以节省大量的磁盘空间以及其他系统资源。 但是也没有必要完全否定虚拟机技术，因为两者有不同的使用场景。虚拟机更擅长于彻底隔离整个运行环境。例如，云服务提供商通常采用虚拟机技术隔离不同的用户。而Docker通常用于隔离不同的应用，例如前端，后端以及数据库。 ","date":"2022-08-28","objectID":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/:1:1","tags":[],"title":"容器技术","uri":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"categories":[],"content":"隔离原理 ​ Docker用Go编程语言编写，并利用Linux内核的多种功能来交付其功能。 Docker使用一种称为名称空间(namespace)的技术来提供容器的隔离工作区。 运行容器时，Docker会为该容器创建一组名称空间。 这些 名称空间提供了一层隔离。 容器的每个方面都在单独的名称空间中运行，并且对其的访问仅限于 该名称空间。 ","date":"2022-08-28","objectID":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/:2:0","tags":[],"title":"容器技术","uri":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"categories":[],"content":"namespace 6项离隔 (资源隔离) namespace类型 系统调用参数 隔离内容 UTS CLONE_NEWUTS 主机和域名 IPC CLONE_NEWIPC 信号量、消息队列和共享内存 PID CLONE_NEWPID 进程编号 Network CLONE_NEWNET 网络设备、网络栈、端口等 Mount CLONE_NEWNS 挂载点(文件系统) User CLONE_NEWUSER 用户和用户组 linux Namespace 是一种Linux Kernel提供的资源隔离方案: 系统为进城分配不同的Namespace 保证不同namespace资源独立分配、进程彼此隔离 // 进程数据结构 struct tash_struct{ ... /* namespace */ struct nsproxy *nsproxy; ... } // namespace 数据结构 struct nsproxy { atomic_t count; struct uts_namespace *uts_ns struct ipc_namespace *ipc_ns struct mnt_namespace *mnt_ns struct pid_namespace *pid_ns_for_children struct net *net_ns } Linux 对namespace操作方法 clone: 在创建新进程的系统调用,可以通过flags参数指定需要新建的namespace类型: // flags 可以为CLONE_NEWCGROUPS / CLONE_NEWIPC ... int clone(int (*fn)(void*), void *child_stack, int flags, void *arg) sets: 该系统调用可以让调用进程加入某个已经存在的namespace中 int setns(int fd, int nstype) unshare : 该系统调用可以将调用进程移动到新的namespace下 int unshare(int flags) ","date":"2022-08-28","objectID":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/:2:1","tags":[],"title":"容器技术","uri":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"categories":[],"content":"隔离机制的问题 ​ 容器的隔离不彻底问题: 多个容器之间使用的还是同一宿主机的操作系统内核 尽管可以在容器里通过 Mount Namespace 单独挂载其他不同版本的操作系统文件, 但这并不能改变共享宿主机内核的事实! 这代表如果要在Windows宿主机上运行Linux容器，或者在低版本的Linux宿主机上运行高版本的Linux容器，都是impossible! Linux内核中很多资源和对象是不能被Namespace化的 最典型的例子：时间; 如果你的容器中的程序使用settimeofday(2)系统调用修改了时间，整个宿主机的时间都会被随之修改，这显然不符合用户的预期; kernel 5.6中已经有time namespace解决此问题 容器给应用暴露出来的攻击面是相当大的 应用“越狱”的难度自然也比虚拟机低得多。尽管可以通过Seccomp等技术过滤和甄别容器内部发起的所有系统调用来进行安全加固, 但一定会拖累容器的性能; 何况，默认情况下，谁也不知道到底该开启哪些系统调用，禁止哪些系统调用。 ","date":"2022-08-28","objectID":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/:2:2","tags":[],"title":"容器技术","uri":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"categories":[],"content":"cgroups 资源限制 ​ Cgroups(control Groups)是linux下用于对一个或一组进程进行资源控制和监控的机制; 可以对诸如CPU使用时间、内存、磁盘IP等进程所需的资源进行限制;不同资源的具体管理工作由相应的Cgroup子系统(Subsystem)来实现; 针对不同类型的资源限制,只需要将限制策略在不同的子系统上进行关联即可; ​ Cgroups在不同的系统资源管理子系统中以层级树(Hierarchy)的方式来组织管理;每个Cgroup都可以包含其他的子Cgroup,因此子Cgroup能使用的资源除了受到本Cgroup配置的资源参数限制,还受到父Cgroups的资源限制;即把一个cgroup目录中的资源划分给它的子目录，子目录可以把资源继续划分给它的子目录，为子目录分配的资源之和不能超过父目录，进程或者线程可以使用的资源受到它们委身的目录的限制。 // 进程数据结构 struct tash_struct{ #ifdef CONFIG_CGROUPS struct css_set__rcu *cgroups; struct list_head cg_list; #endif } // css_set 是cgroup_subsys_state对象的集合数据结构 struct css_set{ struct cgroup_subsys_state *subsys[CGROUP_SUBSYS_COUNT]; } cgroup提供的主要功能如下: 限制进程组可以使用的资源数量（Resource limiting ）。比如：memory子系统可以为进程组设定一个memory使用上限，一旦进程组使用的内存达到限额再申请内存，就会出发OOM（out of memory）。 进程组的优先级控制（Prioritization ）。比如：可以使用cpu子系统为某个进程组分配特定cpu share。 记录进程组使用的资源数量（Accounting ）。比如：可以使用cpuacct子系统记录某个进程组使用的cpu时间 进程组隔离（Isolation）。比如：使用ns子系统可以使不同的进程组使用不同的namespace，以达到隔离的目的，不同的进程组有各自的进程、网络、文件系统挂载空间。 进程组控制（Control）。比如：使用freezer子系统可以将进程组挂起和恢复。 cgroup资源控制系统，每种子系统独立地控制一种资源。功能如下 子系统 功能 cpu 使用调度程序控制任务对CPU的使用 cpuacct(CPU Accounting) 自动生成cgroup中任务对CPU资源使用情况的报告。 cpuset 为cgroup中的任务分配独立的CPU(多处理器系统时)和内存 devices 开启或关闭cgroup中任务对设备的访问 freezer 挂起或恢复cgroup中的任务 memory 设定cgroup中任务对内存使用量的限定，并生成这些任务对内存资源使用 情况的报告 perf_event(Linux CPU性能探测器) 使cgroup中的任务可以进行统一的性能测试 net_cls(Docker未使用) 通过等级识别符标记网络数据包，从而允许Linux流量监控程序(Traic Controller)识别从具体cgroup中生成的数据包 Cgroups主要由task,cgroup,subsystem及hierarchy构成： task：在Cgroups中，task就是系统的一个进程。 cgroup：Cgroups中的资源控制都以cgroup为单位实现的。cgroup表示按照某种资源控制标准划分而成的任务组，包含一个或多个子系统。一个任务可以加入某个cgroup，也可以从某个cgroup迁移到另外一个cgroup。 subsystem：Cgroups中的subsystem就是一个资源调度控制器(Resource Controller)。比如CPU子系统可以控制CPU时间分配，内存子系统可以限制cgroup内存使用量。 hierarchy：hierarchy由一系列cgroup以一个树状结构排列而成，每个hierarchy通过绑定对应的subsystem进行资源调度。hierarchy中的cgroup节点可以包含零或多个子节点，子节点继承父节点的属性。整个系统可以有多个hierarchy。 ","date":"2022-08-28","objectID":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/:2:3","tags":[],"title":"容器技术","uri":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"categories":[],"content":"cgroups 层级结构 ​ 内核使用 cgroup 结构体来表示一个 control group 对某一个或者某几个 cgroups 子系统的资源限制。cgroup 结构体可以组织成一颗树的形式，每一棵cgroup 结构体组成的树称之为一个 cgroups 层级结构。 cgroups层级结构可以 attach 一个或者几个 cgroups 子系统，当前层级结构可以对其 attach 的 cgroups 子系统进行资源的限制。每一个 cgroups 子系统只能被 attach 到一个层级结构中。 创建了 cgroups 层级结构中的节点（cgroup 结构体）之后，可以把进程加入到某一个节点的控制任务列表中，一个节点的控制列表中的所有进程都会受到当前节点的资源限制。同时某一个进程也可以被加入到不同的 cgroups 层级结构的节点中，因为不同的 cgroups 层级结构可以负责不同的系统资源。所以说进程和 cgroup 结构体是一个多对多的关系。 上面这个图从整体结构上描述了进程与 cgroups 之间的关系。最下面的P代表一个进程。每一个进程的描述符中有一个指针指向了一个辅助数据结构css_set（cgroups subsystem set）。 指向某一个css_set的进程会被加入到当前css_set的进程链表中。一个进程只能隶属于一个css_set，一个css_set可以包含多个进程，隶属于同一css_set的进程受到同一个css_set所关联的资源限制。 一个css_set关联多个 cgroups 层级结构的节点时，表明需要对当前css_set下的进程进行多种资源的控制。而一个 cgroups 节点关联多个css_set时，表明多个css_set下的进程列表受到同一份资源的相同限制。 一个task不能存在于同一个hierarchy的不同cgroup，但可以存在在不同hierarchy中的多个cgroup 系统每次新建一个hierarchy时，该系统上的所有task默认构成了这个新建的hierarchy的初始化cgroup，这个cgroup也称为root cgroup。 对于你创建的每个hierarchy，task只能存在于其中一个cgroup中，即一个task不能存在于同一个hierarchy的不同cgroup中，但是一个task可以存在在不同hierarchy中的多个cgroup中。 如果操作时把一个task添加到同一个hierarchy中的另一个cgroup中，则会从第一个cgroup中移除。 如下图，cpu和memory被附加到cpu_mem_cg的hierarchy。而net_cls被附加到net hierarchy。并且httpd进程被同时加到了cpu_mem_cg hierarchy的cg1 cgroup中和net hierarchy的cg3 cgroup中。并通过两个hierarchy的subsystem分别对httpd进程进行cpu,memory及网络带宽的限制。 子task继承父task cgroup的关系 系统中的任何一个task(Linux中的进程)fork自己创建一个子task(子进程)时，子task会自动的继承父task cgroup的关系，在同一个cgroup中，但是子task可以根据需要移到其它不同的cgroup中。父子task之间是相互独立不依赖的。 如下图，httpd进程在cpu_and_mem hierarchy的/cg1 cgroup中并把PID 4537写到该cgroup的tasks中。之后httpd(PID=4537)进程fork一个子进程httpd(PID=4840)与其父进程在同一个hierarchy的统一个cgroup中，但是由于父task和子task之间的关系独立不依赖的，所以子task可以移到其它的cgroup中。 ","date":"2022-08-28","objectID":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/:2:4","tags":[],"title":"容器技术","uri":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"categories":[],"content":"Cgroup版本 ​ 与v1不同，cgroup v2仅具有单个进程层次结构，并且在进程之间进行区分，而不对线程进行区分。在cgroup v2中，所有已安装的控制器都位于一个统一的层次结构中。尽管（不同的）控制器可以同时安装在v1和v2层次结构下，但是不可能同时在v1和v2层次结构下同时安装相同的控制器。 Cgroups v2提供了安装所有控制器所依据的统一层次结构。 不允许“内部”过程。除根cgroup以外，进程只能驻留在叶节点（本身不包含子cgroup的cgroup）中。 必须通过文件cgroup.controllers 和cgroup.subtree_control指定活动的cgroup 。 该任务的文件已被删除。此外，cpuset 控制器使用的 cgroup.clone_children文件已被删除。 cgroup.events文件提供了一种用于通知空cgroup的改进机制 。 ","date":"2022-08-28","objectID":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/:2:5","tags":[],"title":"容器技术","uri":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"categories":[],"content":"cpu绑核操作 使用sched_setaffinity系统调用,可以将某个进程绑定到一个特定的CPU。 int sched_getaffinity(pid_t pid, size_t cpusetsize, cpu_set_t *mask);/* 获得pid所指示的进程的CPU位掩码,并将该掩码返回到mask所指向的结构中 */ 绑定线程到cpu核上使用pthread_setaffinity_np函数系统调用 int pthread_setaffinity_np(pthread_t thread, size_t cpusetsize, const cpu_set_t *cpuset); int pthread_getaffinity_np(pthread_t thread, size_t cpusetsize, cpu_set_t *cpuset); ","date":"2022-08-28","objectID":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/:2:6","tags":[],"title":"容器技术","uri":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"categories":[],"content":"Docker存储 ","date":"2022-08-28","objectID":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/:3:0","tags":[],"title":"容器技术","uri":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"categories":[],"content":"镜像存储 Overlay2 ​ overlay2文件系统: overlay2 的目录是镜像和容器分层的基础，而把这些层统一展现到同一的目录下的过程称为联合挂载（union mount）;overlay2 把目录的下一层叫作lowerdir，上一层叫作upperdir，联合挂载后的结果叫作merged; workdir为临时目录 ​ 总体来说，overlay2 是这样储存文件的：overlay2将镜像层和容器层都放在单独的目录，并且有唯一 ID，每一层仅存储发生变化的文件，最终使用联合挂载技术将容器层和镜像层的所有文件统一挂载到容器中，使得容器中看到完整的系统文件。 镜像中: MergedDir 代表当前镜像层在 overlay2 存储下的目录，LowerDir 代表当前镜像的父层关系，使用冒号分隔，冒号最后代表该镜像的最底层。 容器中:lower 文件为该层的所有父层镜像的短 ID 。diff 目录为容器的读写层，容器内修改的文件都会在 diff 中出现，merged 目录为分层文件联合挂载后的结果，也是容器内的工作目录。 容器run起来时对应的3个层： image layer (只读)，镜像的层 init layer 容器在启动时写入的一些配置文件，发生在 container layer之前 container layer 新增的可写层 镜像存储 ​ Docker镜像由一系列层组成。 每层代表图像的Dockerfile中的一条指令。 容器除最后一层外的每一层都是只读的。 每一层只是与上一层不同的一组。 这些层彼此堆叠。 创建新容器时，可以在基础层之上添加一个新的可写层。 该层通常称为“容器层”。 对运行中 的容器所做的所有更改(例如写入新文件，修改现有文件和删除文件)都将写入此薄可写容 器层。 每层之间如同git一样,只记录不同的部分, 所有层文件合并起来即为所有镜像文件 容器存储 容器和镜像之间的主要区别是可写顶层。 在容器中添加新数据或修改现有数据的所有写操作都存储在此可写层中。 删除容器后，可写层也会被删除。 基础图像保持不变。 因为每个容器都有其自己的可写容器层，并且所有更改都存储在该容器层中，所以多个容器可以共享对同一基础映像的访问， 但具有自己的数据状态。 容量查看 [root@cx-tenc home]# docker ps -s CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES SIZE cf53f0ea23dd nginx \"/docker-entrypoint.…\" 15 seconds ago Up 14 seconds 80/tcp dazzling_carson 1.09kB (virtual 142MB) size: 用于每个容器的可写层的数据量(在磁盘上)。 virtual size:容器使用的用于只读镜像数据的数据量加上容器的可写图层大小。 多个容器可以共享部分或全部只读图像数据。 从同一镜像开始的两个容器共享100%的只读数据，而具有不同图像的两个容器(具有相同的层)共享这些公共层。 因此，不能只对虚拟大小进行总计。这高估了总磁盘使用量，可能是一笔不小的数目。 Copy On Write 写时复制是一种共享和复制文件的策略，可最大程度地提高效率。 如果文件或目录位于映像的较低层中，而另一层(包括可写层)需要对其进行读取访问，则它仅使用现有文件。 另一层第一次需要修改文件时(在构建镜像或运行容器时)，将文件复制到该写层并进行修改。 这样可以将I / O和每个后续层的大小最小化。 镜像如何挑选: busybox:是一个集成了一百多个最常用Linux命令和工具的软件。linux工具里的瑞士军刀 alpine:Alpine操作系统是一个面向安全的轻型Linux发行版经典最小镜像，基于busybox，功能比 Busybox完善。 slim:docker hub中有些镜像有slim标识，都是瘦身了的镜像。也要优先选择 无论是制作镜像还是下载镜像，优先选择alpine类型. 好处是减少镜像体积，提升启动速度， 缺点就是写入的速度慢，所以在 container layer 中不适合进行大量的文件读写，应该使用Volume ","date":"2022-08-28","objectID":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/:3:1","tags":[],"title":"容器技术","uri":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"categories":[],"content":"卷挂载 匿名卷使用 docker run -dP -v :/etc/nginx nginx #docker将创建出匿名卷，并保存容器/etc/nginx下面的内容 ​ 匿名卷在/var/lib/docker/volumes下创建 sha256代码的文件夹, 其中的内容为容器中对应文件夹下的内容; 具名卷使用 docker run -dP -v nginx:/etc/nginx nginx #docker将创建出名为nginx的卷，并保存容器/etc/nginx下面的内容 ​ 如果将空卷装入存在文件或目录的容器中的目录中，则容器中的内容(挂载)到该卷中。如果启动一个容器并指定一个尚不存在的卷，则会创建一个空卷。 bind mount docker run -dP -v /my/nginx:/etc/nginx nginx # bind mount和 volumes 的方式写法区别在于 # 所有以/开始的都认为是 bind mount ，不以/开始的都认为是 volumes. ​ 外部目录覆盖内部容器目录内容，但不是修改。所以谨慎，外部空文件夹挂载方式也会导致容器内部是空文件夹 ","date":"2022-08-28","objectID":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/:3:2","tags":[],"title":"容器技术","uri":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"categories":[],"content":"网络原理 ​ Docker使用Linux桥接，在宿主机虚拟一个Docker容器网桥(docker0)，Docker启动一个容器时会根据Docker网桥的网段分配给容器一个IP地址，称为Container-IP，同时Docker网桥是每个容器的默认网关。 因为在同一宿主机内的容器都接入同一个网桥，这样容器之间就能够通过容器的Container-IP直接通信。​ Docker容器网络就很好的利用了Linux虚拟网络技术，在本地主机和容器内分别创建一个虚拟接口，并让他们彼此联通(这样一对接口叫veth pair); ​ Docker中的网络接口默认都是虚拟的接口。虚拟接口的优势就是转发效率极高(因为Linux是在内核中进 行数据的复制来实现虚拟接口之间的数据转发，无需通过外部的网络设备交换)，对于本地系统和容器 系统来说，虚拟接口跟一个正常的以太网卡相比并没有区别，只是他的速度快很多。 ","date":"2022-08-28","objectID":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/:4:0","tags":[],"title":"容器技术","uri":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"categories":[],"content":"网络模式 网络模式 配置 说明 bridge模式 –net=bridge 默认值，在Docker网桥docker0上为容器创建新的网络 栈 none模式 –net=none 不配置网络，用户可以稍后进入容器，自行配置 container模 式 – net=container:name/id 容器和另外一个容器共享Network namespace。 kubernetes中的pod就是多个容器共享一个Network namespace。 host模式 –net=host 容器和宿主机共享Network namespace 用户自定义 net=自定义网络 用户自己使用network相关命令定义网络，创建容器的时候可以指定为自己定义的网络 自定义网络也使用bridge模式,但是只有用户自定义的网卡可以在容器之间提供自动的 DNS 解析; 缺省的桥接网络上的容器只能通过 IP 地址互相访问，除非使用 –link 参数。官方文档中已经不推荐使用 –link 参数，并且最终可能会被删除，所以最好不要使用 –link 参数来连接两个容器，并且它有多个缺点。 如果使用 –link 参数，需要在容器之间手动创建链接，这些链接需要双向创建，如果容器多于两个的话，将会很困难。或者也可以通过编辑 hosts 文件的方式来指定解析结果，但是这样将会非常难以调试。 ","date":"2022-08-28","objectID":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/:4:1","tags":[],"title":"容器技术","uri":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"categories":[],"content":"容器级别 ","date":"2022-08-28","objectID":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/:5:0","tags":[],"title":"容器技术","uri":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"categories":[],"content":"Docker 组件 docker组件只是一个最外围的入口，为使用者提供一种命令行形式的客户端(CLI)来执行容器的各种操作，使用golang实现。docker客户端将用户输入的命令和参数转换为后端服务的调用参数，通过调用后端服务来实现各类容器操作。 dockerd：dockerd是运行于服务器上的后台守护进程（daemon），负责实现容器镜像的拉取和管理以及容器创建、运行等各类操作。dockerd向外提供RESTful API，其他程序（例如docker客户端）可以通过API来调用dockerd的各种功能，实现对容器的操作。但时至今日，在dockerd中实现的容器管理功能也已经不多，主要是镜像下载和管理相关的功能，其他的容器操作能力已经分离到containerd组件中，通过grpc接口来调用。又被称为docker engine、docker daemon。 containerd：containerd是另一个后台守护进程，是真正实现容器创建、运行、销毁等各类操作的组件，它也包含了独立于dockerd的镜像下载、上传和管理功能。containerd向外暴露grpc形式的接口来提供容器操作能力。dockerd在启动时会自动启动containerd作为其容器管理工具，当然containerd也可以独立运行。containerd是从docker中分离出来的容器管理相关的核心能力组件，是为了支持容器功能实现的灵活性和开放性，更底层的容器操作实现（例如cgroup的创建和管理、namespace的创建和使用等）并不是由containerd提供的，而是通过调用另一个组件runc来实现。 runC: runc实现了容器的底层功能，例如创建、运行等。runc通过调用内核接口为容器创建和管理cgroup、namespace等Linux内核功能，来实现容器的核心特性。 containerd-shim：除了这些主要组件外，图中还有containerd-shim这个组件。containerd-shim位于containerd和runc之间，当containerd需要创建运行容器时，它没有直接运行runc，而是运行了shim，再由shim间接的运行runc; shim主要有3个用途： 让runc进程可以退出，不需要一直运行。这样设计的原因可能还是想让runc的功能集中在容器核心功能本身，同时也便于runc的后续升级。shim作为一个简单的中间进程，不太需要升级，其他组件升级时它可以保持运行，从而不影响已运行的容器。 作为容器中进程的父进程，为容器进程维护stdin等管道fd。如果containerd直接作为容器进程的父进程，那么一旦containerd需要升级重启，就会导致管道和tty master fd被关闭，容器进程也会执行异常而退出。 对于容器运行时来说, 主要有两个级别Low Level(接近内核层)和High Level(接近用户层) lxc: lxc是最早的linux容器技术，早期版本的docker直接使用lxc(后面被runc代替)来实现容器的底层功能。虽然使用者相对较少，但lxc项目仍在持续开发演进中。 **libcontainer：**docker从0.9版本开始自行开发了libcontainer模块来作为lxc的替代品实现容器底层特性，并在1.10版本彻底去除了lxc。在1.11版本拆分出runc后，libcontainer也随之成为了runc的核心功能模块。 CRI：CRI是Container Runtime Interface（容器运行时接口）的缩写。如上文所述，它是k8s团队提出的容器操作接口标准，符合CRI标准的容器模块才能集成到k8s体系中与kubelet交互。符合CRI的容器技术模块包括dockershim（用于兼容dockerd）、rktlet（用于兼容rkt）、containerd(with CRI plugin)、CRI-O等。 rkt与rktlet：rkt是CoreOS公司主导的容器技术，在早期得到了k8s的支持成为k8s集成的两种容器技术之一。随着CRI接口的提出，k8s团队也为rkt提供了rktlet模块用于与rkt交互，rktlet和dockersim的意义基本相同。随着CoreOS被Redhat收购，rkt已经停止了研发，rktlet已停止维护了。 CRI-O：CRI-O是Redhat公司推出的容器技术。从名字就能看出CRI-O的出发点就是一种原生支持CRI接口规范的容器技术。CRI-O同时兼容OCI接口和docker镜像格式。CRI-O的设计目标和特点在于它是一项轻量级的技术，k8s可以通过使用CRI-O来调用不同的底层容器运行时模块，例如runc。 OCI：OCI是Open Container Initiative（开放容器倡议）的缩写。OCI是以docker为首的容器技术公司创建的组织，也是这个组织制定的容器相关标准的统称。OCI标准主要包括两部分：镜像标准和运行时标准。符合OCI运行时标准的容器底层实现模块能够被containerd、CRI-O等容器操作模块集成调用。runc就是从docker中拆分出来捐献给OCI组织的底层实现模块，也是第一个支持OCI标准的模块。除了runc外，还有gVisor（runsc）、kata等其他符合OCI标准的实现。 dockershim：kubelet并没有直接和dockerd交互，而是通过了一个dockershim的组件间接操作dockerd。dockershim提供了一个标准的接口，让kubelet能够专注于容器调度逻辑本身，而不用去适配dockerd的接口变动。而其他实现了相同标准接口的容器技术也可以被kubelet集成使用，这个接口称作CRI。 K8S ","date":"2022-08-28","objectID":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/:5:1","tags":[],"title":"容器技术","uri":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"categories":[],"content":"架构图 ","date":"2022-08-28","objectID":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/:6:0","tags":[],"title":"容器技术","uri":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"categories":[],"content":"K8S组件 ","date":"2022-08-28","objectID":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/:7:0","tags":[],"title":"容器技术","uri":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"categories":[],"content":"OCI标准 OCI即Open Container Initiative(轻量级开放式管理项目),OCI（Open Container Initiative）规范是事实上的容器标准，已经被大部分容器实现以及容器编排系统所采用。任何实现了OCI规范的工具都可以打镜像 OCI主要定义两个规范 Runtime Specification(运行时标准): 文件系统包如何解压至硬盘, 运行时运行方式(以来namespace和cgroups) Image Specification(镜像标准): 如何通过构建系统打包, 生成镜像清单(Manifest)、文件系统序列化文件、镜像配置;(overlays) 规范要求镜像内容包括以下几个部分: 三个必须的: Image Manifest ：提供了镜像的配置和文件系统层定位信息，可以看作是镜像的目录，文件格式为 json Image Layer Filesystem Changeset ：序列化之后的文件系统和文件系统变更，它们可按顺序一层层应用为一个容器的 rootfs，因此通常也被称为一个 layer（与下文提到的镜像层同义），文件格式可以是 tar ，gzip 等存档或压缩格式。 Image Configuration ：包含了镜像在运行时所使用的执行参数以及有序的 rootfs 变更信息，文件类型为 json。 一个可选的: image-index : 图像索引是一种更高级别的清单，它指向特定的图像清单，非常适合一个或多个平台 ","date":"2022-08-28","objectID":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/:8:0","tags":[],"title":"容器技术","uri":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"categories":[],"content":"CRI ​ Container Runtime Interface：容器运行时接口，提供计算资源; ​ Container Runtime实现了CRI gRPC Server，包括RuntimeService和ImageService。该gRPC Server需要监听本地的Unix socket，而kubelet则作为gRPC Client运行。 ImageService : 主要是拉取镜像、查看和删除镜像等操作 RuntimeService : 用来管理 Pod 和容器的生命周期，以及与容器交互的调用（exec/attach/port-forward）等操作 service RuntimeService { // Version returns the runtime name, runtime version, and runtime API version. rpc Version(VersionRequest) returns (VersionResponse) {} // RunPodSandbox creates and starts a pod-level sandbox. Runtimes must ensure // the sandbox is in the ready state on success. rpc RunPodSandbox(RunPodSandboxRequest) returns (RunPodSandboxResponse) {} // StopPodSandbox stops any running process that is part of the sandbox and // reclaims network resources (e.g., IP addresses) allocated to the sandbox. // If there are any running containers in the sandbox, they must be forcibly // terminated. // This call is idempotent, and must not return an error if all relevant // resources have already been reclaimed. kubelet will call StopPodSandbox // at least once before calling RemovePodSandbox. It will also attempt to // reclaim resources eagerly, as soon as a sandbox is not needed. Hence, // multiple StopPodSandbox calls are expected. rpc StopPodSandbox(StopPodSandboxRequest) returns (StopPodSandboxResponse) {} // RemovePodSandbox removes the sandbox. If there are any running containers // in the sandbox, they must be forcibly terminated and removed. // This call is idempotent, and must not return an error if the sandbox has // already been removed. rpc RemovePodSandbox(RemovePodSandboxRequest) returns (RemovePodSandboxResponse) {} // PodSandboxStatus returns the status of the PodSandbox. If the PodSandbox is not // present, returns an error. rpc PodSandboxStatus(PodSandboxStatusRequest) returns (PodSandboxStatusResponse) {} // ListPodSandbox returns a list of PodSandboxes. rpc ListPodSandbox(ListPodSandboxRequest) returns (ListPodSandboxResponse) {} // CreateContainer creates a new container in specified PodSandbox rpc CreateContainer(CreateContainerRequest) returns (CreateContainerResponse) {} // StartContainer starts the container. rpc StartContainer(StartContainerRequest) returns (StartContainerResponse) {} // StopContainer stops a running container with a grace period (i.e., timeout). // This call is idempotent, and must not return an error if the container has // already been stopped. // TODO: what must the runtime do after the grace period is reached? rpc StopContainer(StopContainerRequest) returns (StopContainerResponse) {} // RemoveContainer removes the container. If the container is running, the // container must be forcibly removed. // This call is idempotent, and must not return an error if the container has // already been removed. rpc RemoveContainer(RemoveContainerRequest) returns (RemoveContainerResponse) {} // ListContainers lists all containers by filters. rpc ListContainers(ListContainersRequest) returns (ListContainersResponse) {} // ContainerStatus returns status of the container. If the container is not // present, returns an error. rpc ContainerStatus(ContainerStatusRequest) returns (ContainerStatusResponse) {} // UpdateContainerResources updates ContainerConfig of the container. rpc UpdateContainerResources(UpdateContainerResourcesRequest) returns (UpdateContainerResourcesResponse) {} // ExecSync runs a command in a container synchronously. rpc ExecSync(ExecSyncRequest) returns (ExecSyncResponse) {} // Exec prepares a streaming endpoint to execute a command in the container. rpc Exec(ExecRequest) returns (ExecResponse) {} // Attach prepares a streaming endpoint to attach to a running container. rpc Attach(AttachRequest) returns (AttachResponse) {} // PortForward prepares a streaming endpoint to forward ports from a PodSandbox. rpc PortForward(PortForwardRequest) returns (PortForwardResponse) {} // ContainerStats returns stats of the container. If the container does not // exist, the call returns an error. rpc ContainerStats","date":"2022-08-28","objectID":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/:9:0","tags":[],"title":"容器技术","uri":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"categories":[],"content":"CNI ​ Container Network Interface: 容器网络接口; 是CNCF旗下的一个项目，由一组用于配置Linux容器的网络接口的规范和库组成，同时还包含了一些插件。CNI仅关心容器创建时的网络分配，和当容器被删除时释放网络资源。 CNI的接口中包括以下几个方法： type CNI interface { AddNetworkList(net *NetworkConfigList, rt *RuntimeConf) (types.Result, error) // 添加网络 DelNetworkList(net *NetworkConfigList, rt *RuntimeConf) error // 删除网络 AddNetwork(net *NetworkConfig, rt *RuntimeConf) (types.Result, error) // 添加网络列表 DelNetwork(net *NetworkConfig, rt *RuntimeConf) error // 删除网络列表 } ","date":"2022-08-28","objectID":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/:10:0","tags":[],"title":"容器技术","uri":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"categories":[],"content":"CSI ​ Container Storage Interface: 容器存储接口; CSI 代表容器存储接口，CSI 试图建立一个行业标准接口的规范，借助 CSI 容器编排系统（CO）可以将任意存储系统暴露给自己的容器工作负载。 ","date":"2022-08-28","objectID":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/:11:0","tags":[],"title":"容器技术","uri":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"categories":[],"content":"资源对象 ![截屏2022-09-20 下午6.36.49](https://raw.githubusercontent.com/NoobMidC/pics/main/截屏2022-09-20 下午6.36.49.png) 对于k8s集群应用来说, 所有的程序应用都是 运行在Pod资源对象里 借助于service资源对象向外提供服务访问 借助于各种存储资源实现数据的可持久化 借助于各种配置资源对象实现配置属性、敏感信息饿管理操作 资源对象的分类: 工作负载型资源: Pod、Deployment、Daemonset、Replica、StatefulSet、Job、Cronjob、Operator 服务发现和负载均衡资源: Service、Ingress 配置和存储: configMap、Secret、PersistentVolume、PersistentVolumeChain、 DownwardAPI 动态调整资源: HPA、VPA 资源隔离权限控制资源: namespace、nodes、clusterroles、Roles ","date":"2022-08-28","objectID":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/:12:0","tags":[],"title":"容器技术","uri":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"categories":[],"content":"Pod 工作负载(Workloads)控制一组Pod;Pod控制一组容器(Containers) Pod 天生地为其成员容器提供了两种共享资源: 网络 和 存储 。 一个Pod由一个 Pause容器 设置好整个Pod里面所有容器的网络、名称空间等信息 设计模式 sidecar(边车模式): pod 中的一个额外容器，用于增强或扩展主容器的功能。 Adapter(适配器模式): 转换主容器的输出的容器。 Ambassador(大使模式): 将网络连接代理到主容器的容器。 完整结构 一个pod可以有多个容器, 彼此间共享网络和存储资源; 每个pod中有一个pause容器保存所有容器的状态, 通过管理pause容器达到管理pod中所有容器的效果; 同个pod中的容器总会被调度到相同的Node节点,不同节点间的pod通信是基于虚拟二层网络技术实现的; 每个pod都是应用的一个实例,有专门的ip,与容器暴露的端口组合为一个service的endpoint地址(每个service由kube-proxy转换为本地的ipvs或iptables规则) 每个service的endpoint地址由coredns组件解析为对应的服务名称,其他的service的pod通过访问该名称达到应用间通信的效果 外部流量通过节点网卡进入k8s集群,基于ipvs或iptables规则找到对应的service进而找到对应的pod地址 资源管理 通信机制: pod内又个Pause容器,其有独立的ip地址,其他容器基于container网络模式实现统一的对外服务, 大大简化了关联业务容器之间的通信问题; 存储机制: pod内有专用的数据存储资源对象, 其他容器共享该数据卷, 实现多容器数据信息的统一存储; 所有子应用容器信息都保存在pause容器中, 通过对pause容器的管理, 达到管理所有容器的效果 创建流程 用户向master节点上的API-Server发起创建一个Pod的请求 apiserver 将信息写入etcd scheduluer检测api-Server上有建立Pod请求, 开始调度该Pod到指定的Node, 同时更新信息到etcd kubelet检测到有新的Pod调度过来, 通过Docker引擎运行该pod对象 kubelet通过container runtime 取到Pod状态, 并同步信息到apiserver, 由它更新信息到etcd 生命周期 启动流程: 初始化容器独立于主容器之外, pod可以拥有任意数量init容器、 init容器顺序执行;最后一个init容器执行完成后才启动主容器;(init容器主要是为了为主容器准备应用的功能, 比如向主容器的存储卷写入数据, 然后将存储卷挂在到主容器) 关闭pod流程: 当API服务器接收到删除pod对象的命令后, 按照下面的流程进行: 执行pre stop钩子,等待它执行完毕 向容器的主进程发送SIGTERM信号 等待容器优雅关闭或者等待终止宽限期超时 如果容器没有优雅关闭, 使用SIGKILL信号强制终止进程 临时容器:线上排错。 有些容器基础镜像。线上没法排错。使用临时容器进入这个Pod。临时容器共享了Pod的所有。临时容器有Debug的一些命令，拍错完成以后，只要exit退出容器，临时容器自动删除 生命周期钩子 启动后钩子(post start): 初始化容器启动完成后执行, 与主进程并行运行 运行中钩子: Liveiness(判断当前容器是否处于存活状态); Readiness(判断当前容器是否可以正常的对外提供服务); 停止前钩子(pre stop): 先执行钩子, 并在钩子执行完成后, 想容器发送SIGTERM; 如果没有优雅终止, 则会被强制杀死容器, 不管执行成功与否容器都会终止, 如果未成功则告警 关于钩子函数的执行主要两种方式: Exec: 用于执行一段特定的命令,不过该命令消耗的资源会计入容器 HTTP: 对容器的特定的端点执行HTTP请求 Probe 探针机制 每个容器三种探针(Probe): 启动探针(startupProbe)一次性成功探针。只要启动成功了(initProbe) kubelet 使用启动探针，来检测应用是否已经启动。如果启动完成就可以进行后续的探测检查。慢容器一定指定启动探针。一直在等待启动 启动探针成功以后就不用了，剩下存活探针和就绪探针持续运行 存活探针(livenessProbe), 周期性检测 kubelet 使用存活探针，来检测容器是否正常存活。(有些容器可能产生死锁【应用程序 在运行，但是无法继续执行后面的步骤】)， 如果检测失败就会**重新启动这个容器 ** initialDelaySeconds: 3600(长了导致可能应用一段时间不可用) 5(短了陷入无限启动循环) 就绪探针(readinessProbe) kubelet 使用就绪探针，来检测容器是否准备好了可以接收流量。当一个 Pod 内的所有 容器都准备好了，才能把这个 Pod 看作就绪了。用途就是:Service后端负载均衡多个 Pod，如果某个Pod还没就绪，就会从service负载均衡里面剔除 探针的实现方式: ExecAction: 直接执行命令, 命令成功返回表示探测成功; TCPSocketAction: 端口能正常打开,即成功 HTTPGetAction: 向指定的path发送http请求, 2xx,3xx的响应码表示成功 pod状态 pod状态 描述 Pending APIserver已经创建该server, 但pod内有一个或多个容器的镜像还未创建, 可能还在下载中 Running Pod所有容器已经创建, 且至少一个容器处于运行状态, 正在启动或重启状态 Succeeded 所有容器均成功执行退出, 且不再重启 Failed Pod内所有容器都已经退出, 其中至少一个容器退出失败. Unknown 由于某种原因无法获取到pod状态, 比如网络不通 CrashLookBackOff K8s曾经启动容器成功, 但是后来异常的情况下, 重启次数过多导致异常终止(容器退避算法: 第一次0秒重启, 第二次10秒重启, 第三次20秒后重启…. 如果重启失败,则置为CrashLookBackOff状态; 其他的比如镜像获取就无效了) Error 因为集群配置、安全限制、资源等原因导致pod启动过程中发生了错误 Evicted 集群节点系统内存或硬盘资源不足导致pod出现异常 kubectl explain pods.status.phase # 查看状态 # 业务运行过程中不可避免会出现意外,这个时候有三种策略对pod进行管理: OnFailure、Never、Always(默认) # Always: 容器失效时,即重启 # OnFailure: 容器终止运行, 且退出码不为0时重启 # Never: pod不重启 容器状态 描述 Waiting 容器处于Running和Terminated状态之前的状态 Running 容器能够正常的运行状态 Terminated 容器已经被成功的关闭了 kubectl explain pods.status.containerStatuses.state 流程状态 描述 PodScheduled pod被调度到某个节点 Ready 准备就绪,pod可以处理请求 Initialized pod中所有初始化容器启动完成 Unschedulable 由于资源等限制,导致pod无法被调度 ContainerReady pod中所有容器都启动完毕 kubectl explain pods.status.conditions.status 镜像拉取策略: always: 总是拉取,默认值 IfNotPresent: 如果本地仓库不存在, 再拉取新镜像 Never: 不获取新镜像 Qos ​ QOS是K8S中的一种资源保护机制，其主要是针对不可压缩资源比如内存的一种控制技术。比如在内存中，其通过为不同的Pod和容器构造OOM评分，并且通过内核策略的辅助，从而实现当节点内存资源不足的时候，内核可以按照策略的优先级，优先kill掉那些优先级比较低（分值越高，优先级越低）的Pod。 ​ QoS（Quality of Service），可译为 “服务质量等级”，或者译作 “服务质量保证”，是作用在 Pod 上的一个配置，当 Kubernetes 创建一个 Pod 时，它就会给这个 Pod 分配一个 QoS 等级。 Guaranteed策略: 该策略下，设置的requests 等于 limits, 会存在cpu或memory的request和limit。顾名思义是该容器对资源的最低要求和最高使用量限制。如果我们配置了limit，没有配置request，默认会以limit的值来定义request。 BestEffort策略: 该策略下，没有设置requests 、 limits, 意味着这个容器想跑多少资源就跑多少资源，其资源使用上限实际上即所在node的capacity。 Burstable策略: 该策略下，设置的requests 小于 limits; 当resource.limit和resource.request以上述两种方式以外的形式配置的时候，就会采用本模式。 QoS目前只用cpu和memory来描述，其中cpu可压缩资源，当一个容器的cpu使用率超过limit时会被进行流控，而当内存超过limit时则会被oom_kill。这里kubelet是通过自己计算容器的oom_score，确","date":"2022-08-28","objectID":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/:12:1","tags":[],"title":"容器技术","uri":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"categories":[],"content":"拓扑控制器 拓扑管理器是一个 Kubelet 组件，扮演信息源的角色，以便其他 Kubelet 组件可以做出与拓扑结构相对应的资源分配决定。对所有 QoS 类的 Pod 执行对齐操作。 多种资源管理器在给pod分配设备时，都是独立工作的，不会有一个全局观念，这可能会造成资源分配不合理的问题 Topology Manager就是提供全局的视角，为了尽量将资源分配在同一个numa节点下，提升性能 拓扑管理器有两个主要的配置 作用域(定义了你希望的资源对齐粒度): container （默认）、pod 拓扑策略(对齐时实际使用的策略): 拓扑管理器支持四种分配策略。 none (默认): 不执行任何拓扑对齐。 best-effort: 拓扑管理器存储该容器的首选 NUMA 节点亲和性。 如果亲和性不是首选，则拓扑管理器将存储该亲和性，并且无论如何都将 pod 接纳到该节点。 restricted: 拓扑管理器存储该容器的首选 NUMA 节点亲和性。 如果亲和性不是首选，则拓扑管理器将从节点中拒绝此 Pod 。 这将导致 Pod 处于 Terminated 状态，且 Pod 无法被节点接纳。 single-numa-node: 拓扑管理器确定单 NUMA 节点亲和性是否可能。 如果是这样，则拓扑管理器将存储此信息，然后 建议提供者 可以在做出资源分配决定时使用此信息。 如果不可能，则拓扑管理器将拒绝 Pod 运行于该节点。 这将导致 Pod 处于 Terminated 状态，且 Pod 无法被节点接受。 numa的物理结构： CPU的管理策略 kubelet 使用 CFS 配额 来执行 Pod 的 CPU 约束; CPU 管理策略: None: 默认策略，表示现有的调度行为。显式地启用现有的默认 CPU 亲和方案，不提供操作系统调度器默认行为之外的亲和性策略。 通过 CFS 配额来实现 Guaranteed pods 的 CPU 使用限制。 static: 允许为节点上具有某些资源特征的 pod 赋予增强的 CPU 亲和性和独占性。针对具有整数型 CPU requests 的 Guaranteed Pod ，它允许该类 Pod 中的容器访问节点上的独占 CPU 资源。这种独占性是使用 cpuset cgroup 控制器 来实现的。 CPU 管理器定期通过 CRI 写入资源更新，以保证内存中 CPU 分配与 cgroupfs 一致。 ","date":"2022-08-28","objectID":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/:12:2","tags":[],"title":"容器技术","uri":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"categories":[],"content":"工作负载 ","date":"2022-08-28","objectID":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/:13:0","tags":[],"title":"容器技术","uri":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"categories":[],"content":"部署流程 用户向APIserver中插入一个应用资源的数据形态: 这个数据形态中定义了该资源对象的期望状态, 数据经由APIserver保存到etcd中 kube-controller-manager 中的各种控制器监控APIserver 上与自己相关的资源对象的变动; 比如service controller只负责service资源额度控制等; 一旦APIserver中的资源对象发生变动, 对应controller执行相关的配置代码, 到对应的node上运行; 这些资源对象会在当前节点上, 按照用户期望运行; controller将这些实际的资源对象状态通过APIserver存储到etcd的同一个数据条目的status字段; 资源对象运行过程中,controller会循环的方式向APIserver监控spec和status是否相同; 不相同则只会node节点的资源进行修改,保证两者一致; 状态一直后通过APIserver同步更新到当前资源对象在etcd上的数据; ","date":"2022-08-28","objectID":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/:13:1","tags":[],"title":"容器技术","uri":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"categories":[],"content":"RC\u0026RS RC ​ ReplicationController (RC)用来确保容器应用的副本数始终保持在用户定义的副本数，即如果有容器异常退出，会自动创建新的pod来替代；而异常多出来的容器也会自动回收。 ​ RC定义了一个用户期望场景, 其由Pod的期望状态包括数量(replicas),筛选标签(Label Selector)和模板(template) RS ​ 在新版的Kubernetes中建议使用ReplicaSet (RS)来取代ReplicationController。ReplicaSet跟ReplicationController没有本质的不同，只是名字不一样，但ReplicaSet支持集合式selector。 扩缩容机制 利用 k8s 的 Deployment/RS 的 Scale 机制来实现服务的扩缩容工作 手动扩缩容: 手动设置rs的replicas数量,则实现扩缩容 自动扩缩容: HPA（HorizontalPodAutoscaler） 的控制器，即 Pod 水平扩缩容 周期性的监测目标 Pod 的资源性能指标，获取监视指标后将与 HPA 资源对象中的扩缩容条件进行对比，当满足条件时对 Pod 副本数量进行调整。HPA 控制器依据 Metrics Server 获取资源性能监控指标调整工作负载副本和资源。 HPA工作原理 metrics-server 实现了 Metrics API。该 API 允许你访问集群中 Node 节点和 Pod 的 CPU 和 Memory/内存 使用情况。 metrics-server 的主要作用是 将资源使用指标提供给 K8s 自动缩放器（Scale）组件。 ","date":"2022-08-28","objectID":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/:13:2","tags":[],"title":"容器技术","uri":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"categories":[],"content":"Deployment ​ 一个 Deployment 为 Pods 和 ReplicaSets 提供声明式的更新能力。yaml文件负责描述 Deployment 中的 ，而 Deployment 控制器(Controller) 以受控速率更改实 际状态， 使其变为期望状态 更新机制 仅当 Deployment Pod 模板(即 .spec.template )发生改变时，例如模板的标签或容器镜像被更 新， 才会触发 Deployment 上线。 其他更新(如对 Deployment **执行扩缩容的操作)不会触发上线 动作。 上线动作 原理: 创建新的rs，准备就绪后，替换旧的rs(此时不会删除，因为**revisionHistoryLimit **指定了保留几个版本) 滚动更新 strategy:type:RollingUpdate# 一种是RollingUpdate，即滚动升级。另一种方式为Recreate。即先将所有旧的Pod停止，然后再启动新的pod。默认策略即为RollingUpdate rollingUpdate:maxSurge:10%maxUnavailable:0 maxSurge： 指定在升级时，最大可以创建多少个pod。这个值可以是一个绝对值数字，也可以是个百分比。例如，当这个值指定为30%时，也就是说，新旧pod的总量不能超过130%。简单来讲，就是在滚动升级时，会先启动30%的新的pod。然后开始杀掉旧的pod，每当一个旧的pod被杀掉，一个新的pod的会被启动，始终保持总量不超过130%，直至更新完成。需要说明的是，当maxUnavailable为0时，maxSurge的值不能为0。 maxUnavailable： 指定在升级时，最大不可用的pods的值。可以是一个绝对值数字，也可以是个百分比。例如，当这个值指定为30%时，最少可用的Pod为70%,也就是说，在滚动升级的时候，会先杀掉30%旧的pod，然后开始启动新pod。当一个新的Pod被创建，一个旧的Pod就会被销毁。始终保持可用的pod在总量的70%，直至升级完成。需要说明的是，当maxSurge为0时，maxUnavailable的值不能为0 ","date":"2022-08-28","objectID":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/:13:3","tags":[],"title":"容器技术","uri":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"categories":[],"content":"DaemonSet DaemonSet 控制器确保所有(或一部分)的节点都运行了一个指定的 Pod 副本。 每当向集群中添加一个节点时，指定的 Pod 副本也将添加到该节点上 当节点从集群中移除时，Pod 也就被垃圾回收了 删除一个 DaemonSet 可以清理所有由其创建的 Pod DaemonSet 的典型使用场景有: 在每个节点上运行集群的存储守护进程，例如 glusterd、ceph 在每个节点上运行日志收集守护进程，例如 fluentd、logstash 在每个节点上运行监控守护进程，例如 Prometheus Node Exporter 、 Sysdig Agent 、collectd等 ","date":"2022-08-28","objectID":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/:13:4","tags":[],"title":"容器技术","uri":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"categories":[],"content":"StatefulSet ​ 有状态副本集;Deployment等属于无状态的应用部署(stateless) StatefulSet 使用场景;对于有如下要求的应用程序，StatefulSet 非常适用: 稳定、唯一的网络标识(dnsname) ​ StatefulSet 通过与其相关的无头服务为每个pod提供DNS解析条目 。假如无头服务的DNS条目为:\"$(service name).$(namespace).svc.cluster.local\"，那么pod的解析条目就是\"$(pod name).$(service name).$(namespace).svc.cluster.local\"，每个pod name也是唯一的。 稳定的、持久的存储;【每个Pod始终对应各自的存储路径(PersistantVolumeClaimTemplate)】 有序的、优雅的部署和缩放。【按顺序地增加副本、减少副本，并在减少副本时执行清理】 有序的、自动的滚动更新。【按顺序自动地执行滚动更新】 ","date":"2022-08-28","objectID":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/:13:5","tags":[],"title":"容器技术","uri":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"categories":[],"content":"Job**、**CronJob ​ Kubernetes中的 Job 对象将创建一个或多个 Pod，并确保指定数量的 Pod 可以成功执行到进程正常结 束: 当 Job 创建的 Pod 执行成功并正常结束时，Job 将记录成功结束的 Pod 数量 当成功结束的 Pod 达到指定的数量时，Job 将完成执行 删除 Job 对象时，将清理掉由 Job 创建的 Pod CronJob 按照预定的时间计划(schedule)创建 Job(注意:启动的是Job不是Deploy，rs)。一个 CronJob 对象类似于 crontab (cron table) 文件中的一行记录。该对象根据 Cron 格式定义的时间计划， 周期性地创建 Job 对象。 ","date":"2022-08-28","objectID":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/:13:6","tags":[],"title":"容器技术","uri":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"categories":[],"content":"存储 Kubernetes Volume（数据卷）主要解决了如下两方面问题： 数据持久性：通常情况下，容器运行起来之后，写入到其文件系统的文件暂时性的。当容器崩溃后，kubelet 将会重启该容器，此时原容器运行后写入的文件将丢失，因为容器将重新从镜像创建。 数据共享：同一个 Pod（容器组）中运行的容器之间，经常会存在共享文件/文件夹的需求 ","date":"2022-08-28","objectID":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/:14:0","tags":[],"title":"容器技术","uri":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"categories":[],"content":"数据卷类型 类型 举例 本地数据卷 emptyDir、hostPath、local 云存储数据卷 awsElasticBlockStore 网络存储卷 NFS、gitRepo、NAS、SAN 分布式存储卷 CephFS、rdb、 信息数据卷 flocker、secret等 ","date":"2022-08-28","objectID":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/:14:1","tags":[],"title":"容器技术","uri":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"categories":[],"content":"存储机制 在专用的存储设备上,创建各种类型级别的PV(Persistent Volume)或者通过存储模板文件SC(storageclasses)来自动创建大量不同类型的pv对象 开发人员定制需要的PVC(Persistent Volume Claim),然后关联到pod上 pod通过pvc和pv上请求一块独立大小的网络存储空间,然后直接用 PV和PVC之间的相互作用遵循这个生命周期 ：供应–\u003e绑定–\u003e使用–\u003e 释放–\u003e 循环 随着PV数量的增加，管理员需要不停的定义PV的数量，衍生了通过StorageClass动态生成PV StorageClass通过PVC中声明存储的容量，会调用底层的提供商生成PV。 configMap和secret的热加载原理 ​ 这两种挂载都是将数据以k/v的方式存在etcd中; 在Kubernetes中使用ConfigMap的卷挂载方式时，一旦ConfigMap有更新，由于此ConfigMap和Pod进行了关联，Kubelet在进行Pod同步时会将所关联的卷标记为RequireRemount（需要重新挂载）的卷，而热更新最大的时间延迟则来源于这个同步的间隔， ​ sync-frequency为kubelet同步时间间隔参数, 缺省值为1m ","date":"2022-08-28","objectID":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/:14:2","tags":[],"title":"容器技术","uri":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"categories":[],"content":"网络 ","date":"2022-08-28","objectID":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/:15:0","tags":[],"title":"容器技术","uri":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"categories":[],"content":"企业内DNS解决方案 CoreDNS: K8S集群内部的pod资源的主机名解析 内网DNS: 项目网站架构内部的主机名解析 公网DNS: 项目以来的第三方地址的域名解析 ","date":"2022-08-28","objectID":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/:15:1","tags":[],"title":"容器技术","uri":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"categories":[],"content":"垃圾回收(GC) ​ Kubernetes garbage collector(垃圾回收器)的作用是删除那些曾经有 owner，后来又不再有 owner 的 对象和描述 ","date":"2022-08-28","objectID":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/:16:0","tags":[],"title":"容器技术","uri":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"categories":[],"content":"垃圾收集器如何删除从属对象 ​ 当删除某个对象时，可以指定该对象的从属对象是否同时被自动删除，这种操作叫做级联删除 (cascading deletion)。级联删除有两种模式:后台(background)和前台(foreground) ​ 如果删除对象时不删除自动删除其从属对象，此时，从属对象被认为是孤儿(或孤立的 orphaned) ","date":"2022-08-28","objectID":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/:16:1","tags":[],"title":"容器技术","uri":"/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"categories":[],"content":"gRPC ","date":"2022-08-28","objectID":"/grpc/:0:0","tags":[],"title":"GRPC","uri":"/grpc/"},{"categories":[],"content":"RPC ​ RPC是远程调用过程的简写，是一个协议，处于网络通信协议的第五层：会话层，其下就是TCP/IP协议，在建立在其基础上的通信会话协议。RPC定义了交互的模式，而应用程序使用这些模式，来访问其他服务器的方法，并不需要关系具体的网络上的细节。 ​ RPC 的全称是 Remote Procedure Call 是一种进程间通信方式。它允许程序调用另一个地址空间（通常是共享网络的另一台机器上）的过程或函数，而不用程序员显式编码这个远程调用的细节。即无论是调用本地接口/服务的还是远程的接口/服务，本质上编写的调用代码基本相同。 RPC 会隐藏底层的通讯细节（不需要直接处理Socket通讯或Http通迅) RPC 是一个请求响应模型。客户端发起请求，服务器返回响应（类似于Http的工作方式） RPC 在使用形式上像调用本地函数（或方法）一样去调用远程的函数（或方法）。 ","date":"2022-08-28","objectID":"/grpc/:1:0","tags":[],"title":"GRPC","uri":"/grpc/"},{"categories":[],"content":"RPC包含哪些部分 客户端和服务端建立网络连接模块( server模块、client模块 ) 服务端处理请求模块 协议模块 序列化和反序列模块。 设计一个RPC框架，可以从PRC包含的几个模块去考虑，对每一个模块分别进行设计。 客户端和服务端如何建立网络连接？ 服务端如何处理请求？ 数据传输采用什么协议？ 数据该如何序列化和反序列化？ ","date":"2022-08-28","objectID":"/grpc/:2:0","tags":[],"title":"GRPC","uri":"/grpc/"},{"categories":[],"content":"服务端如何处理请求？有哪些方式？ 同步阻塞方式（BIO）：客户端发一次请求，服务端生成一个对应线程去处理。当客户端同时发起的请求很多时，服务端需要创建多个线程去处理每一个请求，当达到了系统最大的线程数时，新来的请求就无法处理了。 同步非阻塞方式 (NIO)：客户端发一次请求，服务端并不是每次都创建一个新线程来处理，而是通过 I/O 多路复用技术进行处理。就是把多个 I/O 的阻塞复用到同一个 select 的阻塞上，从而使系统在单线程的情况下可以同时处理多个客户端请求。这种方式的优势是开销小，不用为每个请求创建一个线程，可以节省系统开销。 异步非阻塞方式（AIO）：客户端发起一个 I/O 操作然后立即返回，等 I/O 操作真正完成以后，客户端会得到 I/O 操作完成的通知，此时客户端只需要对数据进行处理就好了，不需要进行实际的 I/O 读写操作，因为真正的 I/O 读取或者写入操作已经由内核完成了。这种方式的优势是客户端无需等待，不存在阻塞等待问题。 ","date":"2022-08-28","objectID":"/grpc/:3:0","tags":[],"title":"GRPC","uri":"/grpc/"},{"categories":[],"content":"序列化和反序列化 文本类如 XML/JSON 等 二进制类如 PB/Thrift 等 优点: 解决内存中数据结构到字节序列的映射过程中，如何保留各个结构和字段间的关系而生的技术 。 解决异构系统的数据传输，比如大小端、远端的持久存储； 压缩数据，加快网络传输 ","date":"2022-08-28","objectID":"/grpc/:4:0","tags":[],"title":"GRPC","uri":"/grpc/"},{"categories":[],"content":"gRPC ​ Google远程过程调用（Google Remote Procedure Call，gRPC）是基于HTTP 2.0传输层协议承载的高性能开源RPC软件框架，为管理和配置网络设备提供了一种API接口设计的方法。gRPC提供了多种编程语言，如C、Java、golong、python等。 ​ gRPC可以作为数据传输协议与Telemetry技术配合使用，可实时、高速、精确的监控网络设备的运行状态。此外，网络设备提供了一种基于gRPC方式来管理设备的方法，包括配置、查询和能力获取三种方法。这些方法是通过设备和采集器对接，实现采集设备数据的功能。 ","date":"2022-08-28","objectID":"/grpc/:5:0","tags":[],"title":"GRPC","uri":"/grpc/"},{"categories":[],"content":"gRPC 和Restful ​ REST（Representational State Transfer）表征状态转移，是一种软件架构风格，用于指导WEB架构的设计和开发。REST同样为管理和配置网络设备提供了一种API接口设计的方法。gRPC与REST两者的主要差异如下： REST遵循基于HTTP 1.1的请求-响应通信模型，而gRPC遵循基于HTTP 2.0的客户端-响应通信模型。 HTTP 2.0相对于HTTP 1.1，在速度上有着绝对的优势。虽然REST也可以基于HTTP 2.0进行数据传输，但是为了兼容HTTP 1.1方式，导致其没有充分利用HTTP 2.0的优势。 几乎所有的浏览器都支持RSET，而支持gRPC的浏览器非常有限。这是REST相对于gRPC的主要优势。 REST使用JSON或XML编码格式承载数据，而gRPC默认使用ProtoBuf（Protocol Buffers）编码格式承载数据。 ProtoBuf是二进制的，是以二进制数据进行传输，而JSON或XML编码格式以文本形式传输，所以在传输速率上gRPC更具有优势。 REST不提供内置代码生成功能，需要使用Swagger等工具生成API请求代码。而gRPC具有protoc编译器，具有代码生成功能，而且protoc编译器与多种编程语言兼容。 ","date":"2022-08-28","objectID":"/grpc/:6:0","tags":[],"title":"GRPC","uri":"/grpc/"},{"categories":[],"content":"gRPC工作原理 ","date":"2022-08-28","objectID":"/grpc/:7:0","tags":[],"title":"GRPC","uri":"/grpc/"},{"categories":[],"content":"gRPC协议架构 ​ gRPC是一种用于实现RPC API的技术。由于gRPC是开源框架，通信双方都基于该框架进行二次开发，从而使得通信双方聚焦在业务，无需关注由gRPC软件框架实现的底层通信。如下图，DATA部分即为业务层面内容，DATA下面所有的信息都由gRPC进行封装。","date":"2022-08-28","objectID":"/grpc/:7:1","tags":[],"title":"GRPC","uri":"/grpc/"},{"categories":[],"content":"gRPC模式 四种: 普通rpc 客户端流 服务端流 双向流模式 ","date":"2022-08-28","objectID":"/grpc/:7:2","tags":[],"title":"GRPC","uri":"/grpc/"},{"categories":[],"content":"gRPC protobuf ​ gRPC ProtoBuf是gRPC协议的接口描述语言，是一种与语言无关、平台无关、扩展性好的用于通信协议、数据存储的序列化结构数据格式。gRPC ProtoBuf编码格式也称为GPB（Google Protocol Buffers）编码格式。GPB提供了一种灵活、高效、自动序列化结构数据的机制。GPB与XML、JSON编码类似，也是一种编码方式，但不同的是，它是一种二进制编码，性能好，效率高。 作用: 定义数据结构 定义服务接口 通过序列化和反序列化提升传输效率 微服务","date":"2022-08-28","objectID":"/grpc/:7:3","tags":[],"title":"GRPC","uri":"/grpc/"},{"categories":[],"content":"Kafka ​ Kafka是一个开源的分布式事件流平台(Event Streaming Platform)，广泛应用于高性能数据管道、流分析、数据集成和关键任务应用; ","date":"2022-08-28","objectID":"/kafka/:0:0","tags":[],"title":"Kafka","uri":"/kafka/"},{"categories":[],"content":"消息队列 ​ 企业中比较常见的消息队列产品主要有Kafka、ActiveMQ、RabbitMQ、RocketMQ等。在大数据场景主要采用Kafka作为消息队列 消息队列的模式 点对点模式: 消费者主动拉取数据、消息收到后清除消息 发布/订阅模式 可以有多个topic主题(浏览、点赞、收藏、评论等) 消费者消费数据之后，不删除数据 每个消费者相互独立，都可以消费到数据 ","date":"2022-08-28","objectID":"/kafka/:1:0","tags":[],"title":"Kafka","uri":"/kafka/"},{"categories":[],"content":"应用场景 传统的消息队列的主要应用场景包括：缓存/消峰**、**解耦**和**异步通信。 ","date":"2022-08-28","objectID":"/kafka/:2:0","tags":[],"title":"Kafka","uri":"/kafka/"},{"categories":[],"content":"缓存/消峰 ​ 有助于控制和优化数据流经过系统的速度，解决生产消息和消费消息的处理速度不一致的情况","date":"2022-08-28","objectID":"/kafka/:2:1","tags":[],"title":"Kafka","uri":"/kafka/"},{"categories":[],"content":"解耦 ​ 允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。","date":"2022-08-28","objectID":"/kafka/:2:2","tags":[],"title":"Kafka","uri":"/kafka/"},{"categories":[],"content":"异步通信 ​ 允许用户把一个消息放入队列，但并不立即处理它，然后在需要的时候再去处理它们。","date":"2022-08-28","objectID":"/kafka/:2:3","tags":[],"title":"Kafka","uri":"/kafka/"},{"categories":[],"content":"Kafka架构 Producer：消息生产者，就是向Kafka broker发消息的客户端; Consumer：消息消费者，向Kafka broker取消息的客户端。 **Consumer Group（CG）：消费者组，由多个consumer组成。**消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费；消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。 Broker：一台Kafka服务器就是一个broker。一个集群由多个broker组成。一个broker可以容纳多个topic。 Topic：主题, 可以理解为一个队列，生产者和消费者面向的都是一个topic。 Partition：**为了实现扩展性，一个非常大的topic可以分布到多个broker（即服务器）上，**一个topic可以分为多个partition，每个partition是一个有序的队列。 Replica：副本。一个topic的每个分区都有若干个副本，一个Leader和若干个Follower。 Leader：每个分区多个副本的“主”，生产者发送数据的对象，以及消费者消费数据的对象都是Leader; Follower：每个分区多个副本中的“从”，实时从Leader中同步数据，保持和Leader数据的同步。Leader发生故障时，某个Follower会成为新的Leader。 ","date":"2022-08-28","objectID":"/kafka/:3:0","tags":[],"title":"Kafka","uri":"/kafka/"},{"categories":[],"content":"生产者 ","date":"2022-08-28","objectID":"/kafka/:4:0","tags":[],"title":"Kafka","uri":"/kafka/"},{"categories":[],"content":"生产者消息发送原理 ​ 在消息发送的过程中，涉及到了两个线程——main 线程和 Sender 线程。在 main 线程 中创建了一个双端队列 RecordAccumulator。main 线程将消息发送给 RecordAccumulator， Sender 线程不断从 RecordAccumulator 中拉取消息发送到 Kafka Broker。![截屏2022-09-03 下午9.26.11](https://raw.githubusercontent.com/NoobMidC/pics/main/截屏2022-09-03 下午9.26.11.png) ​ 主线程中，由KafkaProducer创建消息，然后通过可能的拦截器、序列化器和分区器的作用，缓存消息到消息加载器（RecordAccumulator，也称为消息收集器）中，Sender线程负责从消息加载器（RecordAccumulator）中获取消息并将其发送到Kafka中。 拦截器: 对数据进行加工和操作; 如流量拦截和放行处理,如实现白名单 序列化器: 将生产出的消息kv序列化为标准协议 分区器: 根据其存储的元数据, 确定消息发送到哪个分区 消息加载器RecordAccumulator (内存中) ​ 消息加载器（RecordAccumulator）主要用来缓存消息以便Sender线程可以批量发送，进而减少网络传输的资源消耗以提升性能。缓存大小默认为32M; 每个DQuene为发给某个partition的数据队列(一个分区对应一个队列); 即ProducerBatch; 当满足以下两个条件的任意一个之后，消息由sender线程发送。 一个队列中的消息累计达到batch.size，默认是16kb。 等待时间达到linger.ms，默认是0毫秒。 RecordAccumulator 中维护一个内存池; dqueue有数据时请求内存池, 数据发送完毕则将内存归还内存池; 避免了内存的频繁申请和释放; sender线程 ​ Sender线程首先会通过sender读取数据，并创建发送的请求，针对Kafka集群里的每一个Broker，都会有一个InFlightRequests请求队列存放在NetWorkClient中，默认每个InFlightRequests请求队列中缓存5个请求。接着这些请求就会通过Selector发送到Kafka集群中。 kafka集群 ​ 当请求发送到发送到Kafka集群后，Kafka集群会返回对应的acks信息。生产者可以根据具体的情况选择处理acks信息。比如是否需要等有回应之后再继续发送消息，还是不管发送成功失败都继续发送消息。 如果成功; InFlightRequests清理掉对应请求; DQuene清理掉对应数据 如果失败; 则进行重试retires次数, 默认为int最大值 即2147483647 ","date":"2022-08-28","objectID":"/kafka/:4:1","tags":[],"title":"Kafka","uri":"/kafka/"},{"categories":[],"content":"生产者消息发送方式 异步发送 带回调的异步发送 同步发送 ","date":"2022-08-28","objectID":"/kafka/:4:2","tags":[],"title":"Kafka","uri":"/kafka/"},{"categories":[],"content":"生产者分区 分区的优势 便于合理使用存储资源; 每个Partition在一个Broker上存储，可以把海量的数据按照分区切割成一 块一块数据存储在多台Broker上。合理控制分区的任务，可以实现负载均衡的效果。 提高并行度，生产者可以以分区为单位发送数据;消费者可以以分区为单位进行消费数据。 分区策略 指明partition的情况下，直接将指明的值作为partition值; 例如partition=0，所有数据写入 分区0 没有指明partition值但有key的情况下，将key的hash值与topic的 partition数进行取余得到partition值; 例如:key1的hash值**=**5**， **key2**的**hash**值**=6，**topic**的**partition**数**=2**，那 么**key1** 对应的**value1**写入**1**号分区，**key2**对应的**value2**写入**0**号分区。 既没有partition值又没有key值的情况下，Kafka采用Sticky Partition(黏性分区器)，会随机选择一个分区，并尽可能一直使用该分区，待该分区的batch已满或者到linger.ms时间到之后，Kafka再随机一个分区进行使用(和上一次的分区不同)。例如:第一次随机选择0号分区，等0号分区当前批次满了(默认16k)或者linger.ms设置的时间到， Kafka再随机一个分区进行使用(如果还是0会继续随机)。 ","date":"2022-08-28","objectID":"/kafka/:4:3","tags":[],"title":"Kafka","uri":"/kafka/"},{"categories":[],"content":"生产者优化 提高吞吐量 batch.size: 批次大小, 默认为16k, 可以扩大; linger.ms:等待时间，修改为5-100ms; compression.type:设置为snappy, 数据压缩后传输的效率提高了 RecordAccumulator:缓冲区大小，修改为64m 数据可靠性 ACK应答级别 可靠性总结: acks=0，生产者发送过来数据就不管了，可靠性差，效率高; acks=1，生产者发送过来数据Leader应答，可靠性中等，效率中等; acks=-1，生产者发送过来数据Leader和ISR队列里面所有Follwer应答，可靠性高，效率低; ​ 在生产环境中，acks=0很少使用;acks=1，一般用于传输普通日志，允许丢个别数据;acks=-1，一般用于传输和钱相关的数据， 对可靠性要求比较高的场景。 数据去重 数据重复发送的原因 ​ 在ack = -1 时,需要isr中所有的所有节点应答后才返回客户端成功; 如果在某个follower接收到一条数据后, leader挂掉;然后这个follower被选为leader; 由于集群未应答sender成功, 因此selector回重试,这样现在的leader就会有两条相同的数据; 数据传输语义 至少一次(保证数据不丢失,不能保证重复性): 最少发送一次,如果失败则继续发送; ACK级别设置为-1+分区副本大于等于2+ISR里应答的最小副本数量大于等于2 至多一次(不保证数据不丢失,能保证数据不重复): 最多发送一次, 失败成功无所谓; ACK级别设置为0 精确一次: 对于一些非常重要的信息，比如和钱相关的数据，要求数据既不能重复也不丢失; 可以使用幂等性 幂等性 ​ 幂等性就是指Producer不论向Broker发送多少次重复数据，Broker端都只会持久化一条，保证了不重复。 ​ 精确一次(Exactly Once) = 幂等性 + 至少一次( ack=-1 + 分区副本数**\u003e=2 + ISR**最小副本数量**\u003e=2**) ; ​ 重复数据的判断标准:具有\u003cPID, Partition, SeqNumber\u003e相同主键的消息提交时，Broker只会持久化一条。其中PID是Kafka每次重启都会分配一个新的;Partition 表示分区号;Sequence Number是单调自增的。 ​ 所以幂等性只能保证的是在单分区单会话内不重复。 ​ 幂等性使用: 开启参数 enable.idempotence 默认为 true，false 关闭。 生产者事务 ​ 开启事务，必须开启幂等性。 ![截屏2022-09-05 下午12.44.57](https://raw.githubusercontent.com/NoobMidC/pics/main/截屏2022-09-05 下午12.44.57.png) 事务 使用场景 **生产者发送多条消息可以封装在一个事务中，形成一个原子操作。**多条消息要么都发送成功，要么都发送失败。 **read-process-write模式：将消息消费和生产封装在一个事务中，形成一个原子操作。**在一个流式处理的应用中，常常一个服务需要从上游接收消息，然后经过处理后送达到下游，这就对应着消息的消费和生成。 事务配置 对于Producer，需要设置transactional.id属性，这个属性的作用下文会提到。设置了transactional.id属性后，enable.idempotence属性会自动设置为true。 对于Consumer，需要设置isolation.level = read_committed，这样Consumer只会读取已经提交了事务的消息。另外，需要设置enable.auto.commit = false来关闭自动提交Offset功能。 事务特性 原子写 ​ Kafka的事务特性本质上是支持了Kafka跨分区和Topic的原子写操作。在同一个事务中的消息要么同时写入成功，要么同时写入失败。我们知道，Kafka中的Offset信息存储在一个名为_consumed_offsets的Topic中，因此read-process-write模式，除了向目标Topic写入消息，还会向_consumed_offsets中写入已经消费的Offsets数据。因此read-process-write本质上就是跨分区和Topic的原子写操作。Kafka的事务特性就是要确保跨分区的多个写操作的原子性。 拒绝僵尸实例（Zombie fencing) ​ 在分布式系统中，一个instance的宕机或失联，集群往往会自动启动一个新的实例来代替它的工作。此时若原实例恢复了，那么集群中就产生了两个具有相同职责的实例，此时前一个instance就被称为“僵尸实例（Zombie Instance）”。在Kafka中，两个相同的producer同时处理消息并生产出重复的消息（read-process-write模式），这样就严重违反了精确一次(Exactly Once Processing)的语义。这就是僵尸实例问题。 ​ Kafka事务特性通过transaction-id属性来解决僵尸实例问题。所有具有相同transaction-id的Producer都会被分配相同的pid，同时每一个Producer还会被分配一个递增的epoch。Kafka收到事务提交请求时，如果检查当前事务提交者的epoch不是最新的，那么就会拒绝该Producer的请求。从而达成拒绝僵尸实例的目标。 读事务消息 ​ 为了保证事务特性，Consumer如果设置了isolation.level = read_committed，那么它只会读取已经提交了的消息。在Producer成功提交事务后，Kafka会将所有该事务中的消息的Transaction Marker从uncommitted标记为committed状态，从而所有的Consumer都能够消费。 事务原理 查找Tranaction Corordinator ​ Producer向任意一个brokers发送 FindCoordinatorRequest请求来获取Transaction Coordinator的地址。 初始化事务 initTransaction ​ Producer发送InitpidRequest给Transaction Coordinator，获取pid。**Transaction Coordinator在Transaciton Log中记录这\u003cTransactionId,pid\u003e的映射关系。**另外，它还会做两件事： 恢复（Commit或Abort）之前的Producer未完成的事务 对PID对应的epoch进行递增，这样可以保证同一个app的不同实例对应的PID是一样，而epoch是不同的。 开始事务beginTransaction ​ 执行Producer的beginTransacion()，它的作用是Producer在**本地记录下这个transaction的状态为开始状态。**这个操作并没有通知Transaction Coordinator，因为Transaction Coordinator只有在Producer发送第一条消息后才认为事务已经开启。 read-process-write流程 ​ 一旦Producer开始发送消息，Transaction Coordinator会将该\u003cTransaction, Topic, Partition\u003e存于Transaction Log内，并将其状态置为BEGIN。另外，如果该\u003cTopic, Partition\u003e为该事务中第一个\u003cTopic, Partition\u003e，Transaction Coordinator还会启动对该事务的计时（每个事务都有自己的超时时间）。 ​ 在注册\u003cTransaction, Topic, Partition\u003e到Transaction Log后，生产者发送数据，虽然没有还没有执行commit或者abort，但是此时消息已经保存到Broker上了。即使后面执行abort，消息也不会删除，只是更改状态字段标识消息为abort状态。 事务提交或终结 commitTransaction/abortTransaction ​ 在Producer执行commitTransaction/abortTransaction时，Transaction Coordinator会执行一个两阶段提交： 第一阶段，将Transaction Log内的该事务状态设置为PREPARE_COMMIT或PREPARE_ABORT **第二阶段，将Transaction Marker写入该事务涉及到的所有消息（即将消息标记为committed或aborted）。**这一步骤Transaction Coordinator会发送给当前事务涉及到的每个\u003cTopic, Partition\u003e的Leader，Broker收到该请求后，会将对应的Transaction Marker控制信息写入日志。 ​ 一旦Transaction Marker写入完成，Transaction Coordinator会将最终的COMPLETE_COMMIT或COMPLETE_ABORT状态写入Transaction Log中以标明该事务结束。 总结: Transaction Marker与PID提供了识别消息是否应该被读取的能力，从而实现了事务的隔离性。 Offset的更新标记了消息是否被读取，从而将对读操作的事务处理转换成了对写（","date":"2022-08-28","objectID":"/kafka/:4:4","tags":[],"title":"Kafka","uri":"/kafka/"},{"categories":[],"content":"Broker ","date":"2022-08-28","objectID":"/kafka/:5:0","tags":[],"title":"Kafka","uri":"/kafka/"},{"categories":[],"content":"Zookeeper 存储的信息 ","date":"2022-08-28","objectID":"/kafka/:5:1","tags":[],"title":"Kafka","uri":"/kafka/"},{"categories":[],"content":"Broker工作流程 注册: 每次启动一个broker都会到zk中注册节点信息; 选择controller节点: 所以节点的controller去zk抢注册; 谁先注册谁为controller_leader; 监听: 选举出来的controller 监听所有broker的状态 选举: controller_leader决定leader选举; 选举规则: 在ISR中存活为前提, 按照AR排在前面的优先; 如AR[1,0,2], ISR为[1,0,2],则leader会按照1,0,2顺序轮询 同步信息: controller上传节点信息到zk,其他controller从zk同步相关信息 重新选举: 如果leader挂掉, controller监听到节点变化, 向zk拉取节点信息(ISR等),并重新选举leader 更新leader和ISR replica.lag.time.max.ms: ISR中，如果Follower长时间未向Leader发送通信请求或同步数据，则该Follower将被踢出ISR。该时间阈值，默认30s。 ","date":"2022-08-28","objectID":"/kafka/:5:2","tags":[],"title":"Kafka","uri":"/kafka/"},{"categories":[],"content":"开发中的节点服役退役操作 节点服役 启动新节点 执行负载均衡计划,将数据重分配到每个broker上 执行副本存储计划, 重新分配主分区的副本位置 节点退役 执行负载均衡计划, 将数据重分配到后续存活的broker上 执行副本存储计划, 重新分配主分区的副本位置 关闭旧节点 ","date":"2022-08-28","objectID":"/kafka/:5:3","tags":[],"title":"Kafka","uri":"/kafka/"},{"categories":[],"content":"Kafka副本 基本信息 Kafka副本作用：提高数据可靠性。 Kafka默认副本1个，生产环境一般配置为2个，保证数据可靠性；太多副本会增加磁盘存储空间，增加网络上数据传输，降低效率。 Kafka中副本分为：Leader和Follower。Kafka生产者只会把数据发往Leader，然后Follower找Leader进行同步数据。 Kafka分区中的所有副本统称为AR（Assigned Repllicas）。 AR = ISR + OSR ISR，表示和Leader保持同步的Follower集合。如果Follower长时间未向Leader发送通信请求或同步数据，则该Follower将被踢出ISR。该时间阈值由replica.lag.time.max.ms参数设定，默认30s。Leader发生故障之后，就会从ISR中选举新的Leader。 OSR，表示Follower与Leader副本同步时，延迟过多的副本。 Leader选举流程 ​ Kafka集群中有一个broker的Controller会被选举为Controller Leader，负责管理集群broker的上下线，所有topic的分区副本分配和Leader选举等工作; Controller的信息同步工作是依赖于Zookeeper的 故障处理 Follower故障处理 Leader故障处理 分区副本分配 leader尽可能错开, 第一个分配了则第二个broker, 循环往复 follower第一批和leader不间隔, 第二批和leader间隔一个broker, 后面递增 可以手动创建topic并指定每个分区的副本位置 Leader Partition负载平衡 ​ 正常情况下，Kafka本身会自动把Leader Partition均匀分散在各个机器上，来保证每台机器的读写吞吐量都是均匀的。但是如果某 些broker宕机，会导致Leader Partition过于集中在其他少部分几台broker上，这会导致少数几台broker的读写请求压力过高，其他宕机的 broker重启之后都是follower partition，读写请求很低，造成集群负载不均衡。 auto.leader.rebalance.enable，默认是true。 自动Leader Partition 平衡 leader.imbalance.per.broker.percentage， 默认是10%。每个broker允许的不平衡 的leader的比率。如果每个broker超过 了这个值，控制器会触发leader的平衡。 leader.imbalance.check.interval.seconds， 默认值300秒。检查leader负载是否平衡 的间隔时间。 增加副本因子 ​ 在生产环境当中，由于某个主题的重要等级需要提升，我们考虑增加副本。副本数的增加需要先制定计划，然后根据计划执行。 创建topic 手动增加副本存储 （1）创建副本存储计划（所有副本都指定存储在broker0、broker1、broker2中）。 （2）执行副本存储计划。 ","date":"2022-08-28","objectID":"/kafka/:5:4","tags":[],"title":"Kafka","uri":"/kafka/"},{"categories":[],"content":"文件存储(持久化) 文件存储机制 ​ Topic是逻辑上的概念，而partition是物理上的概念，每个partition对应于一个log文件，该log文件中存储的就是Producer生产的数据。Producer生产的数据会被不断追加到该log文件末端，为防止log文件过大导致数据定位效率低下，Kafka采取了分片和索引机制， 将每个partition分为多个segment。每个segment包括:“.index”文件、“.log”文件和.timeindex等文件。这些文件位于一个文件夹下，该 文件夹的命名规则为:topic名称+分区序号，例如:first-0。 index文件和log文件详解 ","date":"2022-08-28","objectID":"/kafka/:5:5","tags":[],"title":"Kafka","uri":"/kafka/"},{"categories":[],"content":"文件清除策略 Kafka中默认的日志保存时间为7天，可以通过调整如下参数修改保存时间。 log.retention.hours，最低优先级小时，默认7天。 log.retention.minutes，分钟。 log.retention.ms，最高优先级毫秒。 log.retention.check.interval.ms，负责设置检查周期，默认5分钟 清除方式 Kafka中提供的日志清理策略有delete和compact两种。 delete: 将过期数据删除 log.cleanup.policy = delete 所有数据启用删除策略 基于时间：默认打开。以segment中所有记录中的最大时间戳作为该文件时间戳。这样就能防止segment中部分超时而删除所有数据的情况; 基于大小：默认关闭。超过设置的所有日志总大小，删除最早的segment。log.retention.bytes，默认等于-1，表示无穷大。 compact日志压缩 ","date":"2022-08-28","objectID":"/kafka/:5:6","tags":[],"title":"Kafka","uri":"/kafka/"},{"categories":[],"content":"高效读写数据 Kafka本身是分布式集群，可以采用分区技术，并行度高 读数据采用稀疏索引，可以快速定位要消费的数据 顺序写磁盘 ​ Kafka的producer生产数据，要写入到log文件中，写的过程是一直追加到文件末端，为顺序写 页缓存 + 零拷贝技术 零拷贝:Kafka的数据加工处理操作交由Kafka生产者和Kafka消费者处理。Kafka Broker应用层不关心存储的数据，所以就不用走应用层，传输效率高。 PageCache页缓存: Kafka重度依赖底层操作系统提供的PageCache功能。当上层有写操作时，操作系统只是将数据写入 PageCache。当读操作发生时，先从PageCache中查找，如果找不到，再去磁盘中读取。实际上PageCache是把尽可能多的空闲内存 都当做了磁盘缓存来使用。 log.flush.interval.messages: 强制页缓存刷写到磁盘的条数，默认是long的最大值，9223372036854775807。一般不建议修改，交给系统自己管理。 log.flush.interval.ms: 每隔多久，刷数据到磁盘，默认是null。一般不建议修改，交给系统自己管理。 ","date":"2022-08-28","objectID":"/kafka/:5:7","tags":[],"title":"Kafka","uri":"/kafka/"},{"categories":[],"content":"消费者 ","date":"2022-08-28","objectID":"/kafka/:6:0","tags":[],"title":"Kafka","uri":"/kafka/"},{"categories":[],"content":"消费模式 pull(拉)模式 consumer采用从broker中主动拉取数据。Kafka采用这种方式 push(推)模式 Kafka没有采用这种方式，因为由broker 决定消息发送速率，很难适应所有消费者的消费速率; pull模式不足之处是，如果Kafka没有数 据，消费者可能会陷入循环中，一直返回 空数据。 ","date":"2022-08-28","objectID":"/kafka/:6:1","tags":[],"title":"Kafka","uri":"/kafka/"},{"categories":[],"content":"工作流程 不同的消费者之前互不影响 一个分区只能由消费者组中的一个消费者消费; 一个消费者可以消费多个分区 消费者的offset由消费者提交给_consumer_offsets主题保存 1.x以前将offset存储在zk中, 由于需要储存每个消费者offset,每次请求都需要向zk拿取offset, 其整个网络传输的负担太大 ","date":"2022-08-28","objectID":"/kafka/:6:2","tags":[],"title":"Kafka","uri":"/kafka/"},{"categories":[],"content":"消费者组原理 Consumer Group(CG):消费者组，由多个consumer组成。形成一个消费者组的条件，是所有消费者的groupid相同。 消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费。 消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。 如果向消费组中添加更多的消费者，超过 主题分区数量，则有一部分消费者就会闲 置，不会接收任何消息。 消费者组之间互不影响。所 有的消费者都属于某个消费者组，即消费者组是逻辑上 的一个订阅者。 消费者组初始化流程 coordinator: 辅助实现消费者组的初始化和分区的分配。 coordinator节点选择 = groupid的hashcode值 % 50(consumer_offsets的分区数量) 例如: groupid的hashcode值 = 1，1% 50 = 1，那么consumer_offsets 主题的1号分区，在哪个broker上，就选择这个节点的coordinator;作为这个消费者组的老大。消费者组下的所有的消费者提交offset的时候就往这个分区去提交offset。 coordinator选出一个consumer作为leader coordinator把要消费的topic信息发给leader leader制定消费方案(即哪些消费者消费哪个topic的哪些分区);并将方案发给coordinator; coordinator下发消费方案给每个消费者 消费者和coordinator保持心跳(默认3s),一旦超时(45s),消费者会被移除,触发再平衡; 或者消费者处理消息时间过长(5min),也会触发再平衡 详细消费过程 发送抓取数据的请求 每批次最小的抓取大小,默认为一字节 一个批次数据最小未到达超时时间为500ms(未达到数据大小也拉取) 每批次最大抓取大小默认为50m 成功回调将数据发给消费者,放在消息队列中; 消费者每次拉取500条数据进行处理(反序列化、拦截器、处理数据) ","date":"2022-08-28","objectID":"/kafka/:6:3","tags":[],"title":"Kafka","uri":"/kafka/"},{"categories":[],"content":"分区分配策略 ​ Kafka有四种主流的分区分配策略: Range、RoundRobin、Sticky、CooperativeSticky。 可以通过配置参数partition.assignment.strategy，修改分区的分配策略。默认策略是Range+ CooperativeSticky。Kafka可以同时使用多个分区分配策略 Range策略 原理 Range 是对每个 topic 而言的。 首先对同一个 topic 里面的分区按照序号进行排序，并对消费者按照字母顺序进行排序 假如现在有 7 个分区，3 个消费者，排序后的分区将会是0,1,2,3,4,5,6;消费者排序完之后将会是C0,C1,C2 通过 partitions数/consumer数 来决定每个消费者应该 消费几个分区。如果除不尽，那么前面几个消费者将会多 消费 1 个分区。 例如，7/3 = 2 余 1 ，除不尽，那么 消费者 C0 便会多 消费 1 个分区。 8/3=2余2，除不尽，那么C0和C1分别多 消费一个。 容易产生数据倾斜! 再分配 ​ 一个消费者挂掉后，消费者组需要按照超时时间 45s 来判断它是否退出，所以需要等待，时间到了 45s 后，判断它真的退出就会把任务分配给其他 broker 执行。 消费者挂掉后其任务会整体被分配到 某一个消费者 再次重新发送消息, 挂掉的被踢出消费者组，然后重新按照 range 方式分配。 RoundRobin策略 原理 ​ RoundRobin 轮询分区策略，是把所有的 partition 和所有的 consumer 都列出来，然后按照 hashcode 进行排序，最后 通过轮询算法来分配 partition 给到各个消费者。 再分区 消费者挂掉后其任务会按照 RoundRobin 的方式，把数据轮询分成多个分区数据，分别其他的消费者消费。 再次重新发送消息, 挂掉的被踢出消费者组，然后重新按照 range 方式分配。 Sticky 策略 ​ 粘性分区定义:可以理解为分配的结果带有“粘性的”。即在执行一次新的分配之前， 考虑上一次分配的结果，尽量少的调整分配的变动，可以节省大量的开销。 ​ 粘性分区是 Kafka 从 0.11.x 版本开始引入这种分配策略，首先会尽量均衡的放置分区 到消费者上面，在出现同一消费者组内消费者出现问题的时候，会尽量保持原有分配的分 区不变化。 再平衡案例 按照粘性规则，尽可能均衡的随机分成 多个分区数据，分别 由 剩余的消费者消费 再次重新发送消息, 挂掉的被踢出消费者组，然保持a步骤中的分区分配不变 ","date":"2022-08-28","objectID":"/kafka/:6:4","tags":[],"title":"Kafka","uri":"/kafka/"},{"categories":[],"content":"Rebalance 机制 Group Coordinator(协调节点) ​ Group Coordinator 是一个服务，每个 Broker在启动的时候都会启动一个该服务。Group Coordinator 的作用是用来存储 Group 的相关 Meta 信息，并将对应 Partition 的 Offset 信息记录到 Kafka 内置Topic(__consumer_offsets) 中。Kafka 在 0.9 之前是基于 Zookeeper 来存储 Partition 的 Offset 信息 (consumers/{group}/offsets/{topic}/{partition})，因为 Zookeeper 并不适用于频繁的写操作，所以在 0.9 之后通过内置 Topic 的方式来记录对应 Partition 的 Offset。 ​ 每个 Group 都会选择一个 Coordinator 来完成自己组内各 Partition 的 Offset 信息，选择的规则如下： 1. 计算 `Group` 对应在 `__consumer_offsets` 上的 `Partition` 1. 根据对应的Partition寻找该Partition的leader所对应的Broker，该Broker上的Group Coordinator即就是该Group的Coordinator 发生 rebalance 的时机 组成员个数发生变化。例如有新的 consumer 实例加入该消费组或者离开组。 订阅的 Topic 个数发生变化。 订阅 Topic 的分区数发生变化。 发生场景: 1. 新成员入组; 2. 组成员离组; 3. 组成员崩溃离组; Rebalance 发生时，Group 下所有 Consumer 实例都会协调在一起共同参与，Kafka 根据分配策略能够保证尽量达到最公平的分配。但是 Rebalance 过程对 Consumer Group 会造成比较严重的影响。在 Rebalance 的过程中 Consumer Group 下的所有消费者实例都会停止工作，等待 Rebalance 过程完成。 Rebalance 发生后的执行过程 Join: Join 顾名思义就是加入组。这一步中，所有成员都向coordinator发送JoinGroup请求，请求加入消费组。一旦所有成员都发送了JoinGroup请求，coordinator会从中选择一个consumer担任leader的角色，并把组成员信息以及订阅信息发给leader——注意leader和coordinator不是一个概念。leader负责消费分配方案的制定。 Sync，这一步leader开始分配消费方案，即哪个consumer负责消费哪些topic的哪些partition。一旦完成分配，leader会将这个方案封装进SyncGroup请求中发给coordinator，非leader也会发SyncGroup请求，只是内容为空。coordinator接收到分配方案之后会把方案塞进SyncGroup的response中发给各个consumer。这样组内的所有成员就都知道自己应该消费哪些分区了。 场景分析 新成员加入组 组成员崩溃 组成员主动离开 提交位移 渐进式 Rebalance 协议 ​ 新的渐进式 Rebalance 协议，在 Rebalance 的时候不需要当前所有的 Consumer 释放所拥有的资源，而是当需要触发 Rebalance 的时候对当前资源进行登记(主要对于每个存活的消费者的offset进行登记)，然后进行渐进式的 Rebalance。 这样做产生的优化效果 - 相较之前进行了更多次数的 Rebalance，但是每次 Rebalance 对资源的消耗都是比较廉价的 - 发生迁移的分区相较之前更少了 - Consumer 在 Rebalance 期间可以继续运行 避免rebalance 避免consumer数量变化: 可以将过期时间设置的久一些,防止误判(session.timeout.ms); 加快心跳频率(heartbeat.interval.ms ); 将消费时间过长问题的参数设置长一些(max.poll.interval.ms); 在消费者挂掉时将其对应的partition也踢出去,这样能保证一个消费者内的对应关系还是正常的, 也就不用rebalance ","date":"2022-08-28","objectID":"/kafka/:6:5","tags":[],"title":"Kafka","uri":"/kafka/"},{"categories":[],"content":"Offset 查看消费者offset ​ 在配置文件 config/consumer.properties 中添加配置 exclude.internal.topics=false， 默认是 true，表示不能消费系统主题。为了查看该系统主题数据，所以该参数修改为 false 然后可以指定topic为__consumer_offsets进行查看 [atguigu@hadoop102 kafka]$ bin/kafka-console-consumer.sh --topic __consumer_offsets --bootstrap-server hadoop102:9092 -- consumer.config config/consumer.properties --formatter \"kafka.coordinator.group.GroupMetadataManager\\$OffsetsMessageForm atter\" --from-beginning 自动提交 enable.auto.commit:是否开启自动提交offset功能，默认是true auto.commit.interval.ms:自动提交offset的时间间隔，默认是5s 手动提交 ​ 手动提交offset的方法有两种:分别是commitSync(同步提交)和commitAsync(异步提交)。两者的相 同点是，都会将本次提交的一批数据最高的偏移量提交;不同点是，同步提交阻塞当前线程，一直到提交成 功，并且会自动失败重试(由不可控因素导致，也会出现提交失败);而异步提交则没有失败重试机制，故有可能提交失败。 commitSync(同步提交):必须等待offset提交完毕，再去消费下一批数据。 commitAsync(异步提交) :发送完提交offset请求后，就开始消费下一批数据了。 漏消费和重复消费 **重复消费：**已经消费了数据，但是offset没提交。 **漏消费：**先提交offset后消费，有可能会造成数据的漏消费。 重复消费: 自动提交引起 漏消费: 漏消费。设置offset为手动提交，当offset被提交时，数据还在内存中未落盘，此时刚好消费者线程被kill掉，那么offset已经提交，但是数据未处理，导致这部分内存中的数据丢失 ","date":"2022-08-28","objectID":"/kafka/:6:6","tags":[],"title":"Kafka","uri":"/kafka/"},{"categories":[],"content":"消费者事务 ​ 如果想完成Consumer端的精准一次性消费，那么需要Kafka消费端将消费过程和提交offset 过程做原子绑定。此时我们需要将Kafka的offset保存到支持事务的自定义介质(比如 MySQL) ","date":"2022-08-28","objectID":"/kafka/:6:7","tags":[],"title":"Kafka","uri":"/kafka/"},{"categories":[],"content":"消费者如何提高吞吐量 如果是Kafka消费能力不足，则可以考虑增加Topic的分区数，并且同时提升消费组的消费者 数量，消费者数 = 分区数。(两者缺一不可) 如果是下游的数据处理不及时:提高每批次拉取的数量。批次拉取数据过少(拉取数据/处理时间 \u003c 生产速度)， 使处理的数据小于生产的数据，也会造成数据积压。 ","date":"2022-08-28","objectID":"/kafka/:6:8","tags":[],"title":"Kafka","uri":"/kafka/"},{"categories":[],"content":"Kraft模式 ​ 左图为 Kafka 现有架构，元数据在 zookeeper 中，运行时动态选举 controller，由 controller 进行 Kafka 集群管理。右图为 kraft 模式架构(实验性)，不再依赖 zookeeper 集群， 而是用三台 controller 节点代替 zookeeper，元数据保存在 controller 中，由 controller 直接进 行 Kafka 集群管理。 优点: Kafka不再依赖外部框架，而是能够独立运行; controller管理集群时，不再需要从zookeeper中先读取数据，集群性能上升; 由于不依赖zookeeper，集群扩展时不再受到zookeeper读写能力限制; controller 不再动态选举，而是由配置文件规定。这样我们可以有针对性的加强 controller 节点的配置，而不是像以前一样对随机 controller 节点的高负载束手无策。 ","date":"2022-08-28","objectID":"/kafka/:7:0","tags":[],"title":"Kafka","uri":"/kafka/"},{"categories":[],"content":"面试题 ","date":"2022-08-28","objectID":"/kafka/:8:0","tags":[],"title":"Kafka","uri":"/kafka/"},{"categories":[],"content":"1. Kafka 是什么?主要应用场景有哪些? Kafka 是一个分布式流式处理平台。 流平台具有三个关键功能: 消息队列:发布和订阅消息流，这个功能类似于消息队列，这也是 Kafka 也被归类为消息队列的原因。 容错的持久方式存储记录消息流:Kafka 会把消息持久化到磁盘，有效避免了消息丢失的风险。 流式处理平台:在消息发布的时候进行处理，Kafka 提供了一个完整的流式处理类库。 Kafka 主要有两大应用场景: 消息队列:建立实时流数据管道，以可靠地在系统或应用程序之间获取数据。 数据处理:构建实时的流数据处理程序来转换或处理数据流。 ","date":"2022-08-28","objectID":"/kafka/:8:1","tags":[],"title":"Kafka","uri":"/kafka/"},{"categories":[],"content":"2. 和其他消息队列相比，Kafka 的优势在哪里? 极致的性能:基于 Scala 和 Java 语言开发，设计中大量使用了批量处理和异步的思想，最高可以每秒处理千 万级别的消息。 生态系统兼容性无可匹敌:Kafka 与周边生态系统的兼容性是最好的没有之一，尤其在大数据和流计算领域。 ","date":"2022-08-28","objectID":"/kafka/:8:2","tags":[],"title":"Kafka","uri":"/kafka/"},{"categories":[],"content":"3. Kafka 的多副本机制了解吗? ​ Kafka 为分区(Partition)引入了多副本(Replica)机制。分区(Partition)中的多个副本之间会有一个叫做 leader 的家伙，其他副本称为 follower。我们发送的消息会被发 送到 leader 副本，然后 follower 副本才能从 leader 副本中拉取消息进行同步。 ​ 生产者和消费者只与 leader 副本交互。你可以理解为其他副本只是 leader 副本的拷贝，它们的存在只是为了保证 消息存储的安全性。当 leader 副本发生故障时会从 follower 中选举出一个 leader,但是 follower 中如果有和 leader 同步程度达不到要求的参加不了 leader 的竞选。 ​ 优势: Kafka 通过给特定 Topic 指定多个 Partition,而各个 Partition 可以分布在不同的 Broker 上,这样便能提供比较 好的并发能力(负载均衡)。 Partition 可以指定对应的 Replica 数,这也极大地提高了消息存储的安全性,提高了容灾能力，不过也相应的增 加了所需要的存储空间。 ","date":"2022-08-28","objectID":"/kafka/:8:3","tags":[],"title":"Kafka","uri":"/kafka/"},{"categories":[],"content":"4. Zookeeper 在 Kafka 中的作用知道吗? Broker 注册:在 Zookeeper 上会有一个专门用来进行 Broker 服务器列表记录的节点。每个 Broker 在启动 时，都会到 Zookeeper 上进行注册，即到/brokers/ids 下创建属于自己的节点。每个 Broker 就会将自己的 IP 地址和端口等信息记录到该节点中去 Topic 注册:在 Kafka 中，同一个 Topic 的消息会被分成多个分区并将其分布在多个 Broker 上，这些分区信 息及与 Broker 的对应关系也都是由 Zookeeper 在维护。比如我创建了一个名字为 my-topic 的主题并且它有 两个分区，对应到 zookeeper 中会创建这些文件夹:/brokers/topics/my- topic/Partitions/0、/brokers/topics/my - topic/Partitions/1 负载均衡:上面也说过了 Kafka 通过给特定 Topic 指定多个 Partition,而各个 Partition 可以分布在不同的 Broker 上,这样便能提供比较好的并发能力。对于同一个 Topic 的不同 Partition，Kafka 会尽力将这些 Partition 分布到不同的 Broker 服务器上。当生产者产生消息后也会尽量投递到不同 Broker 的 Partition 里 面。当 Consumer 消费的时候，Zookeeper 可以根据当前的 Partition 数量以及 Consumer 数量来实现动态 负载均衡。 总而言之, 协助集群管理; 保存了集群的broker元数据、topic元数据, 需要时controller从这里拿取; ","date":"2022-08-28","objectID":"/kafka/:8:4","tags":[],"title":"Kafka","uri":"/kafka/"},{"categories":[],"content":"5.Kafka 如何保证消息的消费顺序? ​ 每次添加消息到 Partition(分区)的时候都会采用尾加法; Kafka 只能为我们保证 Partition(分区)中的 消息有序。消息在被追加到 Partition(分区)的时候都会分配一个特定的偏移量; ​ Kafka 通过偏移量(offset)来保证消息在分区内的顺序性。所以，我们就有一种很简单的保证消 息消费顺序的方法:1 个 Topic 只对应一个 Partition。这样当然可以解决问题，但是破坏了 Kafka 的设计初 衷。 Kafka 中发送1 条消息的时候，可以指定 topic, partition, key,data(数据)4 个参数。如果你发送消息 的时候指定了 Partition 的话，所有消息都会被发送到指定的 Partition。并且，同一个 key 的消息可以保证只 发送到同一个 partition，这个我们可以采用表/对象的 id 来作为 key。 总结: 1 个 Topic 只有一个 Partition。 发送消息的时候指定 key/Partition。 ","date":"2022-08-28","objectID":"/kafka/:8:5","tags":[],"title":"Kafka","uri":"/kafka/"},{"categories":[],"content":"6. Kafka 如何保证消息不丢失? 副本机制 生产者应答机制,设置为-1, 则需要所有ISR同步后返回确认信息; 失败则重试; ","date":"2022-08-28","objectID":"/kafka/:8:6","tags":[],"title":"Kafka","uri":"/kafka/"},{"categories":[],"content":"7. 判断节点活着的条件 节点必须可以维护和 ZooKeeper 的连接，Zookeeper 通过心跳机制检查每个节点的连接; 如果Follower长时间未向Leader发或同步数据，则该Follower将被踢出ISR。该时间阈值，默认30s。 ","date":"2022-08-28","objectID":"/kafka/:8:7","tags":[],"title":"Kafka","uri":"/kafka/"},{"categories":[],"content":"8. Kafka consumer 是否可以消费指定分区消息吗? ​ Kafa consumer 消费消息时，向 broker 发出\"fetch\"请求去消费特定分区的消息，consumer 指定消息在日志中的 偏移量(offset)，就可以消费从这个位置开始的消息，customer 拥有了 offset 的控制权，可以向后回滚去重新 消费之前的消息 ","date":"2022-08-28","objectID":"/kafka/:8:8","tags":[],"title":"Kafka","uri":"/kafka/"},{"categories":[],"content":"9. Kafka 高效文件存储设计特点是什么? Kafka 把 topic 中一个 parition 大文件分成多个小文件段，通过多个小文件段，就容易定期清除或删除已经消费完文件，减少磁盘占用。 通过索引信息可以快速定位 message 和确定 response 的最大大小。 通过 index 元数据全部映射到 memory，可以避免 segment file 的 IO 磁盘操作。 通过索引文件稀疏存储，可以大幅降低 index 文件元数据占用空间大小。 ","date":"2022-08-28","objectID":"/kafka/:8:9","tags":[],"title":"Kafka","uri":"/kafka/"},{"categories":[],"content":"10. partition 的数据如何保存到硬盘? topic 中的多个 partition 以文件夹的形式保存到 broker，每个分区序号从0 递增，且消息有序。 Partition 文件下有多个 segment(xxx.index，xxx.log) segment 文件里的大小和配置文件大小一致可以根据要求修改，默认为1g。如果大小大于1g 时，会滚动一个新的 segment 并且以上一个 segment 最后一条消息的偏移量命名。 ","date":"2022-08-28","objectID":"/kafka/:8:10","tags":[],"title":"Kafka","uri":"/kafka/"},{"categories":[],"content":"11. kafka 维护消费状态跟踪的方法有什么? offset存储在broker的consumer_offset主题中 手动提交offset; 有重复消费的问题 自动提交offset; 有漏消费的问题 ","date":"2022-08-28","objectID":"/kafka/:8:11","tags":[],"title":"Kafka","uri":"/kafka/"},{"categories":[],"content":"12. Kafka 为什么那么快**?** Kafka本身是分布式集群，可以采用分区技术，并行度高 读数据采用稀疏索引，可以快速定位要消费的数据 顺序写磁盘 ​ Kafka的producer生产数据，要写入到log文件中，写的过程是一直追加到文件末端，为顺序写 页缓存 + 零拷贝技术 零拷贝: Kafka的数据加工处理操作交由Kafka生产者和Kafka消费者处理。Kafka Broker应用层不关心存储的数据，所以就不用走应用层，传输效率高。 PageCache页缓存: Kafka重度依赖底层操作系统提供的PageCache功能。当上层有写操作时，操作系统只是将数据写入 PageCache。当读操作发生时，先从PageCache中查找，如果找不到，再去磁盘中读取。实际上PageCache是把尽可能多的空闲内存 都当做了磁盘缓存来使用。 ","date":"2022-08-28","objectID":"/kafka/:8:12","tags":[],"title":"Kafka","uri":"/kafka/"},{"categories":[],"content":"13. Kafka 的流处理是什么意思? ​ 连续、实时、并发和以逐记录方式处理数据的类型，我们称之为 Kafka 流处理。 ","date":"2022-08-28","objectID":"/kafka/:8:13","tags":[],"title":"Kafka","uri":"/kafka/"},{"categories":[],"content":"14. 延迟队列实现 Redis ZSet ​ 我们知道 Redis 有一个有序集合的数据结构 ZSet，ZSet 中每个元素都有一个对应 Score，ZSet 中所有元素是按照其 Score 进行排序的。 入队操作：ZADD KEY timestamp task, 我们将需要处理的任务，按其需要延迟处理时间作为 Score 加入到 ZSet 中。Redis 的 ZAdd 的时间复杂度是O(logN)，N是 ZSet 中元素个数，因此我们能相对比较高效的进行入队操作。 起一个进程定时（比如每隔一秒）通过ZREANGEBYSCORE方法查询 ZSet 中 Score 最小的元素，具体操作为：ZRANGEBYSCORE KEY -inf +inf limit 0 1 WITHSCORES。查询结果有两种情况： 查询出的分数小于等于当前时间戳，说明到这个任务需要执行的时间了，则去异步处理该任务； 查询出的分数大于当前时间戳，由于刚刚的查询操作取出来的是分数最小的元素，所以说明 ZSet 中所有的任务都还没有到需要执行的时间，则休眠一秒后继续查询； (ZRANGEBYSCORE操作的时间复杂度为O(logN + M)，其中N为 ZSet 中元素个数，M为查询的元素个数，因此我们定时查询操作也是比较高效的。) ​ Redis 实现延迟队列的后端架构，其在原来 Redis 的 ZSet 实现上进行了一系列的优化，使得整个系统更稳定、更健壮，能够应对高并发场景，并且具有更好的可扩展性 将延迟的消息任务通过 hash 算法路由至不同的 Redis Key 上，这样做有两大好处： 避免了当一个 KEY 在存储了较多的延时消息后，入队操作以及查询操作速度变慢的问题（两个操作的时间复杂度均为O(logN)）。 系统具有了更好的横向可扩展性，当数据量激增时，我们可以通过增加 Redis Key 的数量来快速的扩展整个系统，来抗住数据量的增长。 每个 Redis Key 都对应建立一个处理进程，称为 Event 进程，通过上述步骤 2 中所述的 ZRANGEBYSCORE 方法轮询 Key，查询是否有待处理的延迟消息。 所有的 Event 进程只负责分发消息，具体的业务逻辑通过一个额外的消息队列异步处理，这么做的好处也是显而易见的： 一方面，Event 进程只负责分发消息，那么其处理消息的速度就会非常快，就不太会出现因为业务逻辑复杂而导致消息堆积的情况。 另一方面，采用一个额外的消息队列后，消息处理的可扩展性也会更好，我们可以通过增加消费者进程数量来扩展整个系统的消息处理能力。 Event 进程采用 Zookeeper 选主单进程部署的方式，避免 Event 进程宕机后，Redis Key 中消息堆积的情况。一旦 Zookeeper 的 leader 主机宕机，Zookeeper 会自动选择新的 leader 主机来处理 Redis Key 中的消息。 Rabbitmq Kafka、RocketMQ、RabbitMQ、ActiveMQ比较 ActiveMQ ​ 优点 单机吞吐量：万级 topic数量都吞吐量的影响： 时效性：ms级 可用性：高，基于主从架构实现高可用性 消息可靠性：有较低的概率丢失数据 功能支持：MQ领域的功能极其完备 ​ **缺点:**官方社区现在对ActiveMQ 5.x维护越来越少，较少在大规模吞吐的场景中使用。 Kafka ​ 号称大数据的杀手锏，谈到大数据领域内的消息传输，则绕不开Kafka，这款为大数据而生的消息中间件，以其百万级TPS的吞吐量名声大噪，迅速成为大数据领域的宠儿，在数据采集、传输、存储的过程中发挥着举足轻重的作用。 优点 性能卓越，单机写入TPS约在百万条/秒，最大的优点，就是吞吐量高。 时效性：ms级 可用性：非常高，kafka是分布式的，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用 消费者采用Pull方式获取消息, 消息有序, 通过控制能够保证所有消息被消费且仅被消费一次; 有优秀的第三方Kafka Web管理界面Kafka-Manager； 在日志领域比较成熟，被多家公司和多个开源项目使用； 功能支持：功能较为简单，主要支持简单的MQ功能，在大数据领域的实时计算以及日志采集被大规模使用 缺点： Kafka单机超过64个队列/分区，Load会发生明显的飙高现象，队列越多，load越高，发送消息响应时间变长 使用短轮询方式，实时性取决于轮询间隔时间； 消费失败不支持重试； 支持消息顺序，但是一台代理宕机后，就会产生消息乱序； 社区更新较慢； 更多消息队列对比点这里 ","date":"2022-08-28","objectID":"/kafka/:8:14","tags":[],"title":"Kafka","uri":"/kafka/"},{"categories":[],"content":"ElasticSearch ​ Elasticsearch是一个开源的高扩展的分布式全文检索引擎，它可以近乎实时的存储、检索数据；本身扩展性很好，可以扩展到上百台服务器，处理PB级别的数据。 ","date":"2022-08-28","objectID":"/elasticsearch/:0:0","tags":[],"title":"Elasticsearch","uri":"/elasticsearch/"},{"categories":[],"content":"ES的特点和优势 分布式实时文件存储，可将每一个字段存入索引，使其可以被检索到。 分布式：索引分拆成多个分片，每个分片可有零个或多个副本。集群中的每个数据节点都可承载一个或多个分片，并且协调和处理各种操作；负载再平衡和路由在大多数情况下自动完成。 实时分析的分布式搜索引擎。 可以扩展到上百台服务器，处理PB级别的结构化或非结构化数据;也可以运行在单台PC上; 支持插件机制，分词插件、同步插件、Hadoop插件、可视化插件等。 ","date":"2022-08-28","objectID":"/elasticsearch/:1:0","tags":[],"title":"Elasticsearch","uri":"/elasticsearch/"},{"categories":[],"content":"ES倒排索引 ​ 倒排索引是首先知道了每个关键词都出现在了哪些文档里，从关键词搜文档（关键词→文档） ","date":"2022-08-28","objectID":"/elasticsearch/:2:0","tags":[],"title":"Elasticsearch","uri":"/elasticsearch/"},{"categories":[],"content":"倒排索引原理 ​ 倒排索引主要由单词词典（Term Dictionary）和倒排列表（Posting List）及倒排文件(Inverted File)组成。 **单词词典（Term Dictionary）：**搜索引擎的通常索引单位是单词，单词词典是由文档集合中出现过的所有单词构成的字符串集合，单词词典内每条索引项记载单词本身的一些信息以及指向“倒排列表”的指针。 **倒排列表(PostingList)：**倒排列表记载了出现过某个单词的所有文档的文档列表及单词在该文档中出现的位置信息及频率（作关联性算分），每条记录称为一个倒排项(Posting)。根据倒排列表，即可获知哪些文档包含某个单词。 **倒排文件(Inverted File)：**所有单词的倒排列表往往顺序地存储在磁盘的某个文件里，这个文件即被称之为倒排文件，倒排文件是存储倒排索引的物理文件。 ","date":"2022-08-28","objectID":"/elasticsearch/:2:1","tags":[],"title":"Elasticsearch","uri":"/elasticsearch/"},{"categories":[],"content":"字典树 ​ Trie树是一种前缀树，我们之前也有介绍过，一般应用在快速查询中，例如搜索提示，当你输入前半部分，会提示后半部分的内容。字典树用一句话表示就是根据字符串的前缀构成的树结构。它的优点是：利用字符串的公共前缀来减少查询时间，最大限度地减少无谓的字符串比较，查询效率比哈希树高 ​ Trie 的核心思想是空间换时间，利用字符串的公共前缀来降低查询时间的开销以达到提高效率的目的。它有 3 个基本性质： 根节点不包含字符，除根节点外每一个节点都只包含一个字符 从根节点到某一节点，路径上经过的字符连接起来，为该节点对应的字符串 每个节点的所有子节点包含的字符都不相同 ​ 对于中文的字典树，每个节点的子节点用一个哈希表存储，这样就不用浪费太大的空间，而且查询速度上可以保留哈希的复杂度 O(1)。 搜索字典项目的方法为：(来自百度百科) 从根结点开始一次搜索； 取得要查找关键词的第一个字母，并根据该字母选择对应的子树并转到该子树继续进行检索； 在相应的子树上，取得要查找关键词的第二个字母,并进一步选择对应的子树进行检索。 迭代过程……(重复123) 在某个结点处，关键词的所有字母已被取出，则读取附在该结点上的信息，即完成查找。 应用实例: 1. 字符串的快速检索;2. 字符串排序; 3. 最长公共前缀; 4, 搜索引擎 ","date":"2022-08-28","objectID":"/elasticsearch/:2:2","tags":[],"title":"Elasticsearch","uri":"/elasticsearch/"},{"categories":[],"content":"不变的倒排索引 ​ 早期的全文检索会为整个文档集合建立一个很大的倒排索引并将其写入到磁盘。 一旦新的索引就绪，旧的就会被其替换，这样最近的修改变化便可以被检索到。 不变性的优点: 不需要锁。如果你从来不更新索引，你就不需要担心多进程同时修改数据的问题 一旦索引被读入内核的文件系统缓存，便会留在哪里，由于其不变性。只要文件系统缓存中还有足够的空间，那么大部分读请求会直接请求内存，而不会命中磁盘。这提供了很大的性能提升; 其它缓存(像 filter 缓存)，在索引的生命周期内始终有效。它们不需要在每次数据改变时被重建，因为数据不会变化; 写入单个大的倒排索引允许数据被压缩，减少磁盘 I/O 和 需要被缓存到内存的索引的使用量。 缺点: 当然，一个不变的索引也有不好的地方。主要事实是它是不可变的! 你不能修改它。如果你需要让一个新的文档可被搜索，你需要重建整个索引。这要么对一个索引所能包含的数据量造成了很大的限制，要么对索引可被更新的频率造成了很大的限制; ","date":"2022-08-28","objectID":"/elasticsearch/:2:3","tags":[],"title":"Elasticsearch","uri":"/elasticsearch/"},{"categories":[],"content":"动态更新的倒排索引 ​ 为了保持倒排索引的不变性同时实现更新, 通过增加新的补充索引来反映最近的修改，而不是直接重写整个倒排索引。每一个倒排索引都会被轮流查询到，从最早的开始查询完后再对结果进行合并（因为不重写索引，所以旧索引要合并减少空间大小）。 ​ Elasticsearch 基于 Lucene, 其中有按段搜索的概念; 每一段本身都是一个倒排索引，但索引在 Lucene 中除表示所有段的集合外，还增加了提交点的概念：一个列出了所有已知段的文件。 按段搜索 新文档被收集到内存索引缓存 不时地，缓存被提交: 一个新的段,即一个追加的倒排索引被写入磁盘; 一个新的包含新段名字的「提交点」 被写入磁盘; 磁盘进行同步，所有在文件系统缓存中等待的写入都刷新到磁盘，以确保它们被写入物理文件. 新的段被开启，让它包含的文档可见以被搜索 内存缓存被清空，等待接收新的文档 按段搜索的好处 当一个查询被触发，所有已知的段按顺序被查询。词项统计会对所有段的结果进行聚合，以保证每个词和每个文档的关联都被准确计算。 这种方式可以用相对较低的成本将新文档添加到索引。 段是不可改变的，所以既不能从把文档从旧的段中移除，也不能修改旧的段来进行反映文档的更新。取而代之的是，每个提交点会包含一个 .del 文件，文件中会列出这些被删除文档的段信息。当一个文档被」删除」时，它实际上只是在 .del 文件中被「标记」删除。一个被标记删除的文档仍然可以被查询匹配到，但它会在最终结果被返回前从结果集中移除。 文档更新也是类似的操作方式：当一个文档被更新时，旧版本文档被标记删除，文档的新版本被检索到一个新的段中。可能两个版本的文档都会被一个查询匹配到，但被删除的那个旧版本文档在结果集返回前就已经被移除。 ","date":"2022-08-28","objectID":"/elasticsearch/:2:4","tags":[],"title":"Elasticsearch","uri":"/elasticsearch/"},{"categories":[],"content":"ES索引文档的过程 请求发送到Coordinating Node，如果该节点不是Master节点，需要将该请求转发到Master.Master节点通过路由算法，确定该分片在哪个节点上： ​ shard = hash(_routing) % (num_of_primary_shards)默认使用文档ID作为_routing值，也可以通过API指定_routing值 分片节点收到请求后，会将请求写入到Memory Buffer，然后定时（默认是每隔1秒）写入到Filesystem Cache(磁盘缓存)，这个从Momery Buffer到Filesystem Cache（磁盘缓存）的过程就叫做Refresh。在写入Buffer的同时，会同时写一个Transaction Log(每个分片会有一个Log文件)。当做refresh时，Buffer会被清空，Transaction Log不会清空。 ES每30分钟，会有一个Flush操作。该操作会调用fsync，将Filesystem Cache中的数据写入segment文件，旧的translog将被删除并开始一个新的translog ES会自动进行Merge操作，该操作会将多个Segment文件合并，在.del文件中被标记为删除的文档将不会被写入Segment，并且清空.del文件中的内容 ","date":"2022-08-28","objectID":"/elasticsearch/:2:5","tags":[],"title":"Elasticsearch","uri":"/elasticsearch/"},{"categories":[],"content":"ES Refresh过程(近乎实时搜索) 创建索引时，数据并不会直接写入Segment文件，而是会先写入一个Index Buffer缓冲区。而将Index Buffer中数据写入Filesystem Cache（磁盘缓存)的过程就叫Refresh. Refresh的频率默认是每秒一次。可通过index.refresh_interval进行配置。Refresh后，数据就可被搜索到了，这也是为什么ES被称为近实时搜索。 Index Buffer被占满时，也会触发Refresh，默认值是JVM的10% ","date":"2022-08-28","objectID":"/elasticsearch/:2:6","tags":[],"title":"Elasticsearch","uri":"/elasticsearch/"},{"categories":[],"content":"Transaction Log ​ Segment写入磁盘的过程相对耗时，所以借助文件系统缓存，Refresh时，先将Segment写入文件缓存中，以开放查询。但为了保证数据不会丢失，所以在创建索引时，会同时写Tansaction Log，类似操作日志。在ES进行Refresh时，Index Buffer会被清空，Transaction Log不会清空。 translog 提供所有还没有被刷到磁盘的操作的一个持久化纪录。当 Elasticsearch 启动的时候，它会从磁盘中使用最后一个提交点去恢复已知的段，并且会重放 translog 中所有在最后一次提交后发生的变更操作。 translog 也被用来提供实时 CRUD。当你试着通过 ID 查询、更新、删除一个文档，它会在尝试从相应的段中检索之前，首先检查 translog 任何最近的变更。这意味着它总是能够实时地获取到文档的最新版本。 默认 translog 是每 5 秒被 fsync 刷新到硬盘， 或者在每次写请求完成之后执行(e.g., index, delete, update, bulk)。这个过程在主分片和复制分片都会发生。 ","date":"2022-08-28","objectID":"/elasticsearch/:2:7","tags":[],"title":"Elasticsearch","uri":"/elasticsearch/"},{"categories":[],"content":"ES Flush Flush操作：调用refresh，清空index buffer; 清空transaction log Flush触发条件：1. 默认30分钟调用一次; 2. Transaction Log 默认达到512M ","date":"2022-08-28","objectID":"/elasticsearch/:2:8","tags":[],"title":"Elasticsearch","uri":"/elasticsearch/"},{"categories":[],"content":"持久化过程 一个文档被索引之后，就会被添加到内存缓冲区，并且追加到了 translog 日志 刷新（refresh）使分片每秒被刷新（refresh）一次： 这些在内存缓冲区的文档被写入到一个新的段(文件缓冲区)中，且没有进行 fsync 操作; 这个段被打开，使其可被搜索;内存缓冲区被清空 这个进程继续工作，更多的文档被添加到内存缓冲区和追加到事务日志 每隔一段时间30min或者 translog 变得足够大，索引被刷新（flush）；一个新的 translog 被创建，并且一个全量提交被执行; 所有在内存缓冲区的文档都被写入一个新的段;缓冲区被清空 一个提交点被写入硬盘 文件系统缓存通过 fsync 被刷新（flush）;老的 translog 被删除 ","date":"2022-08-28","objectID":"/elasticsearch/:2:9","tags":[],"title":"Elasticsearch","uri":"/elasticsearch/"},{"categories":[],"content":"段合并 ​ 每一个段都会消耗文件句柄、内存和 cpu 运行周期。更重要的是，每个搜索请求都必须轮流检查每个段；所以段越多，搜索也就越慢。 ​ Elasticsearch 通过在后台进行段合并来解决这个问题。小的段被合并到大的段，然后这些大的段再被合并到更大的段。段合并的时候会将那些旧的已删除文档从文件系统中清除。被删除的文档（或被更新文档的 旧版本）不会被拷贝到新的大段中。 当检索的时候，刷新（refresh）操作会创建新的段并将段打开以供搜索使用 合并进程选择一小部分大小相似的段，并且在后台将它们合并到更大的段中。这并不会中断检索和搜索、 一旦合并结束，老的段被删除 新的段被刷新（flush）到了磁盘。 写入一个包含新段且排除旧的和较小的段的新提交点 新的段被打开用来搜索; 老的段被删除 合并大的段需要消耗大量的 I/O 和 CPU 资源，如果任其发展会影响搜索性能。Elasticsearch 在默认情况下会对合并流程进行资源限制，所以搜索仍然有足够的资源很好地执行。 ","date":"2022-08-28","objectID":"/elasticsearch/:2:10","tags":[],"title":"Elasticsearch","uri":"/elasticsearch/"},{"categories":[],"content":"查写删的流程 ​ 以下均针对集群而言 ","date":"2022-08-28","objectID":"/elasticsearch/:3:0","tags":[],"title":"Elasticsearch","uri":"/elasticsearch/"},{"categories":[],"content":"ES写数据的流程 客户端发送写请求到某个节点，此节点为协调节点. 其将请求通过路由计算，将请求发到指定的节点。 写请求是写入 primary shard，然后同步给所有的 replica shard； 当主分片把更改转发到副本分片时，它不会转发更新请求。相反，它转发完整文档的新版本。请记住，这些数据更改文档将会异步转发到副本分片，并且不能保证数据更改文档以发送它们相同的顺序到达。如果 Elasticsearch 仅转发更改请求，则可能以错误的顺序应用更改，导致得到损坏的文档。 读请求可以从 primary shard 或 replica shard 读取，采用的是随机轮询算法。 数据到达指定节点后, 对应的primary shard将数据先写入内存 buffer，然后每隔 1s，将数据 refresh 到 os cache，到了 os cache 数据就能被搜索到（所以我们才说 es 从写入到能被搜索到，中间有 1s 的延迟）。每隔 5s，将数据写入 translog 文件（这样如果机器宕机，内存数据全没，最多会有 5s 的数据丢失），translog 大到一定程度，或者默认每隔 30mins，会触发 commit 操作，将缓冲区的数据都 flush 到 segment file 磁盘文件中。 数据写入 segment file 之后(从buffer 刷新到os cache)，同时就建立好了倒排索引。 ","date":"2022-08-28","objectID":"/elasticsearch/:3:1","tags":[],"title":"Elasticsearch","uri":"/elasticsearch/"},{"categories":[],"content":"ES查数据的流程 ​ 找到所有匹配的结果是查询的第一步，来自多个shard上的数据集在分页返回到客户端的之前会被合并到一个排序后的list列表，由于需要经过一步取top N的操作，所以search需要进过两个阶段才能完成，分别是query和fetch。 ​ 流程可以总结为先广播请求到各个分片，然后各个分片取topN，最后再进行整合。 整体流程如下 query阶段: 根据查询获取具体的数据的id 客户端发送search请求到某个node,即协调节点(如node3) 协调节点将查询请求转发到索引的每个主分片或副分片中。 每个分片在本地执行查询，并使用本地的Term/Docuemnt Frequency信息进行打分，添加结果到大小为from+size的本地优先队列中。(在搜索的时候是会查询 Filesystem Cache 的，但是有部分数据还在 Memory Buffer，所以搜索是近实时的) 每个分片返回各自优先队列中所有文档的ID和排序值给协调节点，协调节点合并这些值到自己的优先队列中，产生一个有序全局列表。 查询阶段并不会对搜索请求的内容进行解析，无论搜索什么内容，只看本次搜索需要命中哪些shard，然后针对每个特定shard选择一个副本，转发搜索请求。 Fetch阶段: 根据query过程的获取的id拿出具体的数据 协调节点对query阶段的数据重新截取数据后，获取到真正需要返回的数据的 id 协调节点向相关NODE发送GET请求 分片所在节点向协调节点返回数据。 协调节点等待所有文档被取得，然后返回给客户端。 在搜索的时候是会查询Filesystem Cache的，但是有部分数据还在Memory Buffer，所以搜索是近实时的。 ","date":"2022-08-28","objectID":"/elasticsearch/:3:2","tags":[],"title":"Elasticsearch","uri":"/elasticsearch/"},{"categories":[],"content":"ES删数据的流程 更新操作就是将原来的数据标识为deleted状态，重新写入数据的过程 删除操作，commit 的时候会生成一个 .del 文件，里面将某个 doc 标识为 deleted 状态，那么搜索的时候根据 .del 文件就知道这个 doc 是否被删除了 ","date":"2022-08-28","objectID":"/elasticsearch/:3:3","tags":[],"title":"Elasticsearch","uri":"/elasticsearch/"},{"categories":[],"content":"批量操作 mget(批量读) ​ 用单个 mget 请求取回多个文档所需的步骤顺序: 客户端向 Node 1 发送 mget 请求 Node 1 为每个分片构建多文档获取请求，然后并行转发这些请求到托管在每个所需的主分片或者副本分片的节点上。一旦收到所有答复，Node 1 构建响应并将其返回给客户端 ","date":"2022-08-28","objectID":"/elasticsearch/:3:4","tags":[],"title":"Elasticsearch","uri":"/elasticsearch/"},{"categories":[],"content":"bulk API(批量增删改) ​ bulk API 允许在单个批量请求中执行多个创建、索引、删除和更新请求; bulk API 按执行步骤顺序： 客户端向 Node 1 发送 bulk 请求 Node 1 为每个节点创建一个批量请求，并将这些请求并行转发到每个包含主分片的节点主机 主分片一个接一个按顺序执行每个操作。当每个操作成功时，主分片并行转发新文档（或删除）到副本分片，然后执行下一个操作。一旦所有的副本分片报告所有操作成功，该节点将向协调节点报告成功，协调节点将这些响应收集整理并返回给客户端。 ","date":"2022-08-28","objectID":"/elasticsearch/:3:5","tags":[],"title":"Elasticsearch","uri":"/elasticsearch/"},{"categories":[],"content":"ES集群 ","date":"2022-08-28","objectID":"/elasticsearch/:4:0","tags":[],"title":"Elasticsearch","uri":"/elasticsearch/"},{"categories":[],"content":"路由计算 shard = hash(routing) % number_of_primary_shards 位置 = hash(路由哈希值) $ 分片总数 routing 是一个可变值，默认是文档的 _id ，也可以设置成一个自定义的值。routing 通过 hash 函数生成一个数字，然后这个数字再除以 number_of_primary_shards（主分片的数量）后得到余数。这个分布在 0 到 number_of_primary_shards-1 之间的余数，就是我们所寻求的文档所在分片的位置。 这就解释了为什么我们要在创建索引的时候就确定好主分片的数量并且永远不会改变这个数量：因为如果数量变化了，那么所有之前路由的值都会无效，文档也再也找不到了。 不带 routing 查询时, 协调节点会将查询请求分发到每个分片上,然后聚合每个分片上的查询结果返回给客户端 ","date":"2022-08-28","objectID":"/elasticsearch/:4:1","tags":[],"title":"Elasticsearch","uri":"/elasticsearch/"},{"categories":[],"content":"并发控制 乐观版本控制 ​ 当我们之前使用 index（索引）的 GET 和 DELETE 请求时，可以通过返回结果看到每个文档都有一个 _version（版本号），当文档被修改时版本号递增。Elasticsearch 使用这个 _version 号来确保变更以正确顺序得到执行。如果旧版本的文档在新版本之后到达，它可以被简单的忽略掉，也就是不允许执行。 ​ 我们可以利用 version 号来确保应用中相互冲突的变更不会导致数据丢失。我们通过指定想要修改文档的 version 号来达到这个目的。如果该版本不是当前版本号，我们的请求将会失败。 // 老的版本 ES 在写操作时可以指定版本 http://127.0.1:9200/shopping/_update/1001?version=2 // 新版 url 不能直接操作 _version，如果想操作 _version，只能操作由 _version 衍生出来的 _if_seq_no 和 _if_primary_term http://127.0.1:9200/shopping/_update/1001?if_seq_no=2\u0026if_primary_term=2 外部系统版本控制: ​ 一个常见的设置是使用其它数据库作为主要的数据存储，使用 Elasticsearch 做数据检索，这意味着主数据库的所有更改发生时都需要被复制到 Elasticsearch，如果多个进程负责这一数据同步，你可能遇到类似于之前描述的并发问题。 ​ 如果你的主数据库已经有了版本号或一个能作为版本号的字段值比如时间戳 timestamp，那么你就可以在 Elasticsearch 中通过增加 version_type=external 到查询字符串的方式重用这些相同的版本号， ","date":"2022-08-28","objectID":"/elasticsearch/:4:2","tags":[],"title":"Elasticsearch","uri":"/elasticsearch/"},{"categories":[],"content":"分片策略 分片消耗的资源: 一个分片的底层即为一个 Lucene 索引，会消耗一定文件句柄、内存、以及 CPU 运转 每一个搜索请求都需要命中索引中的每一个分片，如果每一个分片都处于不同的节点还好，但如果多个分片都需要在同一个节点上竞争使用相同的资源就有些糟糕了 用于计算相关度的词项统计信息是基于分片的。如果有许多分片，每一个都只有很少的数据会导致很低的相关度 延迟分片分配机制 对于节点瞬时中断的问题，默认情况，集群会等待一分钟来查看节点是否会重新加入，如果这个节点在此期间重新加入，重新加入的节点会保持其现有的分片数据，不会触发新的分片分配。这样就可以减少 ES 在自动再平衡可用分片时所带来的极大开销。 修改参数 delayed_timeout，可以延长再均衡的时间 ","date":"2022-08-28","objectID":"/elasticsearch/:4:3","tags":[],"title":"Elasticsearch","uri":"/elasticsearch/"},{"categories":[],"content":"ES集群扩张原理 ​ ElasticSearch的节点启动后，它会利用多播(multicast)(或者单播，如果用户更改了配置)寻找集群中的其它节点，并与之建立连接。这个过程如下图所示： ","date":"2022-08-28","objectID":"/elasticsearch/:4:4","tags":[],"title":"Elasticsearch","uri":"/elasticsearch/"},{"categories":[],"content":"集群选举 三种状态 Leader：接受客户端请求，并向Follower同步请求日志，当日志同步到大多数节点上后告诉Follower提交日志。 Follower：接受并持久化Leader同步的日志，在Leader告之日志可以提交之后，提交日志。 Candidate：Leader选举过程中的临时角色。 Elasticsearch 的选主是 ZenDiscovery 模块负责的，主要包含 Ping（节点之间通过这个 RPC 来发现彼此）和 Unicast（单播模块包含一个主机列表以控制哪些节点需要 ping 通）这两部分 Follower只响应其他服务器的请求。如果Follower超时没有收到Leader的消息，它会成为一个Candidate并且开始一次Leader选举。 对所有可以成为 master 的节点（node.master: true）根据 nodeId 字典排序，每次选举每个节点都把自己所知道节点排一次序，然后选出第一个（第 0 位）节点，暂且认为它是 master 节点 如果对某个节点的投票数达到一定的值（可以成为 master 节点数 n/2+1）并且该节点自己也选举自己，那这个节点就是 master。否则重新选举一直到满足上述条件 master 节点的职责主要包括集群、节点和索引的管理，不负责文档级别的管理；data 节点可以关闭 http 功能; 选举使用的Raft算法 ","date":"2022-08-28","objectID":"/elasticsearch/:4:5","tags":[],"title":"Elasticsearch","uri":"/elasticsearch/"},{"categories":[],"content":"脑裂问题 脑裂问题可能的成因 网络问题：集群间的网络延迟导致一些节点访问不到 master，认为 master 挂掉了从而选举出新的 master，并对 master 上的分片和副本标红，分配新的主分片 节点负载：主节点的角色既为 master 又为 data，访问量较大时可能会导致 ES 停止响应造成大面积延迟，此时其他节点得不到主节点的响应认为主节点挂掉了，会重新选取主节点 内存回收：data 节点上的 ES 进程占用的内存较大，引发 JVM 的大规模内存回收，造成 ES 进程失去响应 脑裂问题解决方案 减少误判：discovery.zen.ping_timeout 节点状态的响应时间，默认为 3s，可以适当调大 选举触发: 修改参数为1，discovery.zen.minimum_master_nodes:1 ​ 该参数是用于控制选举行为发生的最小集群主节点数量。当备选主节点的个数大于等于该参数的值，且备选主节点中有该参数个节点认为主节点挂了，进行选举。官方建议为（n/2）+1，n 为主节点个数（即有资格成为主节点的节点个数） 角色分离：即 master 节点与 data 节点分离，限制角色 ","date":"2022-08-28","objectID":"/elasticsearch/:4:6","tags":[],"title":"Elasticsearch","uri":"/elasticsearch/"},{"categories":[],"content":"优化策略 ","date":"2022-08-28","objectID":"/elasticsearch/:5:0","tags":[],"title":"Elasticsearch","uri":"/elasticsearch/"},{"categories":[],"content":"写入速度优化 加大 Translog Flush 间隔， 降低写阻塞(Writeblock) 增加 Index Refresh 间隔，目的是减少 Segment Merge 的次数;由于 Lucene 段合并的计算量庞大，会消耗大量的 I/O，所以 ES 默认采用较保守的策略，让后台定期进行段合并。 批量数据提交 优化存储设备: ES 是一种密集使用磁盘的应用，在段合并的时候会频繁操作磁盘，所以对磁盘要求较高，当磁盘速度提升之后，集群的整体性能会大幅度提高 减少副本数量:写索引时，需要把写入的数据都同步到副本节点，副本节点越多，写索引的效率就越慢;如果我们需要大批量进行写入操作，可以先禁止 Replica 复制，设置 index.number_of_replicas: 0 关闭副本。在写入完成后，Replica 修改回正常的状态。 ","date":"2022-08-28","objectID":"/elasticsearch/:5:1","tags":[],"title":"Elasticsearch","uri":"/elasticsearch/"},{"categories":[],"content":"GC的注意事项 倒排词典的索引需要常驻内存，无法 GC，需要监控 data node 上 segment memory 增长趋势 各类缓存，field cache, filter cache, indexing cache, bulk queue 等等，要设置合理的大小，并且要应该根据最坏的情况来看 heap 是否够用，也就是各类缓存全部占满的时候，还有 heap 空间可以分配给其他任务吗？避免采用 clear cache 等「自欺欺人」的方式来释放内存 避免返回大量结果集的搜索与聚合。确实需要大量拉取数据的场景，可以采用 scan \u0026 scroll api 来实现 ","date":"2022-08-28","objectID":"/elasticsearch/:5:2","tags":[],"title":"Elasticsearch","uri":"/elasticsearch/"},{"categories":[],"content":"Elasticsearch对于大数据量（上亿量级）的聚合如何实现？ ​ Elasticsearch 提供的首个近似聚合是 cardinality 度量。它提供一个字段的基数，即该字段的 distinct 或者 unique 值的数目。它是基于 HLL 算法的。(和Redis中的HLL一样)HLL 会先对我们的输入作哈希运算，然后根据哈希运算的结果中的 bits 做概率估算从而得到基数。其特点是：可配置的精度，用来控制内存的使用（更精确 ＝ 更多内存）；小的数据集精度是非常高的；我们可以通过配置参数，来设置去重需要的固定内存使用量。 ","date":"2022-08-28","objectID":"/elasticsearch/:6:0","tags":[],"title":"Elasticsearch","uri":"/elasticsearch/"},{"categories":[],"content":"在并发情况下，Elasticsearch如果保证读写一致？ 可以通过版本号使用乐观并发控制，以确保新版本不会被旧版本覆盖，由应用层来处理具体的冲突 另外对于写操作，一致性级别支持 quorum/one/all，默认为 quorum，即只有当大多数分片可用时才允许写操作。但即使大多数可用，也可能存在因为网络等原因导致写入副本失败，这样该副本被认为故障，分片将会在一个不同的节点上重建 对于读操作，可以设置 replication 为 sync(默认)，这使得操作在主分片和副本分片都完成后才会返回；如果设置 replication 为 async 时，也可以通过设置搜索请求参数 _preference 为 primary 来查询主分片，确保文档是最新版本 ","date":"2022-08-28","objectID":"/elasticsearch/:7:0","tags":[],"title":"Elasticsearch","uri":"/elasticsearch/"},{"categories":[],"content":"ES查询为什么存在误差 ​ ES执行查询计算分数的时候会包括已删除的文档，这样在进行topN排序时会不准确。 ","date":"2022-08-28","objectID":"/elasticsearch/:8:0","tags":[],"title":"Elasticsearch","uri":"/elasticsearch/"},{"categories":[],"content":"ES中的scroll查询和普通分页对比 size+from的翻页方式，这种翻页方式存在很大的性能瓶颈，时间复杂度O(n)，空间复杂度O(n)。 query阶段: 每次查询都会将转发请求给所有分片, 所有分片返回size*from个数据的id和score给协调节点进行排序; fetch阶段: 丢弃无用的数据id,只留下想要的size个数据,然后获取所有文档数据,返回客户端 SearchAfter ;Search接口另一种翻页方式是SearchAfter，时间复杂度O(n)，空间复杂度O(1)。 ​ SearchAfter是一种动态指针的技术，每次查询都会携带上一次的排序值，这样下次取结果只需要从上次的位点继续扫数据 第一次和size+from的方式一样, 后续查询携带上次查询结果末尾的排序条件,减少命中数据 SeachScroll; 时间复杂度O(1)，空间复杂度O(1) search阶段时: query阶段和size+from一样; 然后将所有排序后的数据存放在缓存队列中, 取前size个进入fetch阶段, fetch返回后,抛弃前size个文档id (类似于打了个快照) scroll阶段时: 直接从缓存中取id, 然后进入fetch阶段. 在scroll查询时, 都会设置有效时间, 过了有效时间这个缓存就被清理了; 而且es也做了很多压缩处理,大量的ID可以被很好的存在缓存中; ","date":"2022-08-28","objectID":"/elasticsearch/:9:0","tags":[],"title":"Elasticsearch","uri":"/elasticsearch/"},{"categories":[],"content":"X-Pack for Elasticsearch的功能和重要性 ​ X-Pack 是与 Elasticsearch 一起安装的扩展程序。 ​ X-Pack 的各种功能包括安全性(基于⻆色的访问，特权/权限，⻆色和用户安 全性)，监视，报告，警报等。 ","date":"2022-08-28","objectID":"/elasticsearch/:10:0","tags":[],"title":"Elasticsearch","uri":"/elasticsearch/"},{"categories":[],"content":"Elasticsearch 在部署时，对 Linux 的设置有哪些优化方法? 关闭缓存 swap; 堆内存设置为:Min(节点内存/2, 32GB); 设置最大文件句柄数; 线程池+队列大小根据业务需要做调整; 磁盘存储 raid 方式——存储有条件使用 RAID10，增加单节点性能以及避 免单节点存储故障。 ","date":"2022-08-28","objectID":"/elasticsearch/:11:0","tags":[],"title":"Elasticsearch","uri":"/elasticsearch/"},{"categories":[],"content":"ES和Mysql对比 ​ 基于分词后的全文检索 ​ es分词后，每个字都可以利用FST高速找到倒排索引的位置，并迅速获取文档id列表 精确检索 ​ mysql的非聚合索引用上了覆盖索引，无需回表，则速度可能更快 ​ es还是通过FST找到倒排索引的位置并获取文档id列表，再根据文档id获取文档并根据相关度算分进行排序，但es还有个杀手锏，即天然的分布式使得在大数据量面前可以通过分片降低每个分片的检索规模，并且可以并行检索提升效率 ​ 用filter时更是可以直接跳过检索直接走缓存 聚合查询对比 ​ mysql做例子，如果没有建立索引，我们需要全遍历一份，到内存进行排序，如果有索引，会在索引树上进行进行范围查询（因为索引是排序了的） ​ es中，如果是做排序，lucene会查询出所有的文档集合的排序字段，然后再次构建出一个排序好的文档集合。es是面向海量数据的，这样一来内存爆掉的可能性是十分大的 总结：ElasticSearch为了提高检索性能，无所不用的压缩数据，减少磁盘的随机读，以及及其苛刻的使用内存，使用各种快速的搜索算法等手段 追求更快的检索算法 — 倒排，二分 更小的数据传输— 压缩数据（FST，ROF，公共子前缀压缩） 更少的磁盘读取— 顺序读（DocValue顺序读） ","date":"2022-08-28","objectID":"/elasticsearch/:12:0","tags":[],"title":"Elasticsearch","uri":"/elasticsearch/"},{"categories":[],"content":"Redis ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:0:0","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"Redis 简介 Redis 是完全开源免费的，遵守 BSD 协议，是一个高性能的 key-value 数据库。 特点: Redis 支持数据的持久化 Redis 不仅仅支持简单的 key-value 类型的数据，同时还提供 list， set，zset，hash 等数据结构的存储。 Redis 支持数据的备份，即 master-slave 模式的数据备份 优势: 性能极高– Redis 能读的速度是110000 次/s,写的速度是81000 次/s 。 丰富的数据类型– Redis 支持二进制案例的 Strings, Lists, Hashes, Sets 及 Ordered Sets 数据类型操作。 原子性– Redis 的所有操作都是原子性的，意思就是要么成功执行要么失败完全不执行。单个操作是原子性的。 多个操作也支持事务，即原子性，通过 MULTI 和 EXEC 指令包起来。 丰富的特性– Redis 还支持 publish/subscribe,通知, key 过期等等特性。 ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:1:0","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"为什么单线程能这么快 纯内存访问。 非阻塞IO,Redis 使用epoll作为IO多路复用技术的实现。加上Redis自身的事件处理模型将epoll中的链接、读写、关闭都转换成时间，不在网络IO上浪费过多的时间。 单线程避免了线程切换和静态产生的消耗 ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:1:1","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"缓存的分类 类型：本地缓存、分布式缓存和多级缓存。 本地缓存：进程的内存中进行缓存。本地缓存是内存访问，没有远程交互开销，性能最好，但是受限于单机容量，一般缓存较小且无法扩展。 分布式缓存：分布式缓存一般都具有良好的水平扩展能力，对较大数据量的场景也能应付自如。缺点就是需要进行远程请求，性能不如本地缓存。 多级缓存：为了平衡这种情况，实际业务中一般采用多级缓存，本地缓存只保存访问频率最高的部分热点数据，其他的热点数据放在分布式缓存中。 ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:1:2","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"数据类型 ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:2:0","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"字符串String 特点: String是Redis最基本的类型, 是二进制安全的。意味着Redis的string可以包含任何数据,比如jpg图片或者序列化的对象; Redis中字符串value最多可以是512M ​ 常用命令: set,get,decr,incr,mget 等。 ​ String的数据结构为简单动态字符串(Simple Dynamic String,缩写SDS)是可以修改的字符串，内部结构实现上类似于golang的slice，采用预分配冗余空间的方式来减少内存的频繁分配. 扩容策略: 内部为当前字符串实际分配的空间capacity一般要高于实际字符串长度len。当字符串长度小于1M时，扩容都是加倍现有的空间，如果超过1M，扩容时一次只会多扩1M的空间. ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:2:1","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"列表List 特点: 单键多值; 简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边） **常用命令：**lpush,rpush,lpop,rpop,lrange等。 它的底层实际是个双向链表，对两端的操作性能很高，通过索引下标的操作中间的节点性能会较差。其数据结构也是个快速列表quickList 在列表元素较少的情况下会使用一块连续的内存存储，这个结构是ziplist，也即是压缩列表;它将所有的元素紧挨着一起存储，分配的是一块连续的内存。 数据量多的时候将ziplist连接起来,这样可以节省中间所有节点的prev和next的指针空间 ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:2:2","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"集合set 特点: 功能与list类似，特殊之处在于set是可以自动排重的;set提供了判断某个成员是否在一个set集合内的重要接口 ​ 常用命令： sadd,spop,smembers,sunion 等。 ​ Redis的Set是string类型的无序集合。它底层其实是一个value为同一个内部值的hash表，所以添加，删除，查找的复杂度都是O(1)。 ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:2:3","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"有序集合zset 特点: Redis有序集合zset与普通集合set非常相似，是一个没有重复元素的字符串集合。不同之处是有序集合的每个成员都关联了一个评分（score）,这个评分（score）被用来按照从最低分到最高分的方式排序集合中的成员。集合的成员是唯一的，但是评分可以是重复的 。 常用命令： zadd,zrange,zrem,zcard等 zset底层使用了两个数据结构: hash表, hash的作用就是关联元素value和权重score, 保障元素value的唯一性，可以通过元素value找到相应的score值。 跳跃表，跳跃表的目的在于给元素value排序，根据score的范围获取元素列表。 跳跃表 ​ 有序集合在生活中比较常见，例如根据成绩对学生排名，根据得分对玩家排名等。对于有序集合的底层实现，可以用数组、平衡树、链表等。数组不便元素的插入、删除；平衡树或红黑树虽然效率高但结构复杂；链表查询需要遍历所有效率低。Redis采用的是跳跃表。跳跃表效率堪比红黑树，实现远比红黑树简单。 要查找值为51的元素: 从第2层开始，1节点比51节点小，向后比较。 21节点比51节点小，继续向后比较，后面就是NULL了，所以从21节点向下到第1层 在第1层，41节点比51节点小，继续向后，61节点比51节点大，所以从41向下 在第0层，51节点为要查找的节点，节点被找到，共查找4次。 从此可以看出跳跃表比有序链表效率要高 ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:2:4","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"哈希(Hash) ​ Redis hash是一个string类型的field和value的映射表，hash特别适合用于存储对象 常用命令: HDEL、HEXISTS、HGET、HGETALL、HINCRBY、HKEYS、HMGET、HSCAN、HVALS ​ Hash类型是Redis中非常重要的复合型结构，通过(K,V)来实现，采用链地址法来处理哈希冲突，整体数据结构与Java中的HashMap极为相似，都是采用数组+链表(Redis中不会将链表改为红黑树)的结构来实现 ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:2:5","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"Bitmaps Bitmaps就是通过一个 bit 位来表示某个元素对应的值或者状态，其中的 key 就是对应元素本身. **常用命令：**hget,hset,hgetall 等。 Bitmaps 和set的对比 ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:2:6","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"HyperLogLog 用来做基数统计的算法，提供了不精确的去重计数方案; 如统计UV（Unique Visitor，独立访客）,即每个用户访问次数 特点: 在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定 的、并且是很小的。每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基 数; HyperLogLog 只会根据输入元素来计算基数，而不会储存输入元素本身，所以 HyperLogLog 不能像集合那样，返回输入的各个元素。(比如数据集 {1, 3, 5, 7, 5, 7, 8}， 那么这个数据集的基数集为 {1, 3, 5 ,7, 8}, 基数(不重复元素总数)为 5。 基数估计就是在误差可接受的范围内，快速计算基数。 总结就是去掉重复的元素，只存储不重复元素的个数，不会储存元素本身。 HyperLogLog底层原理: ​ 它的主要精髓在于通过记录下低位连续零位的最大长度K（也就是上面我们说的kmax），来估算随机数的数量n。 ​ 从这个bit串的低位开始计算，直到出现第一个1为止，这就好比上面的伯努利试验抛硬币，一直抛硬币直到出现第一个正面为止（只是这里是数字0和1，伯努利试验中使用的硬币的正与反，并没有区别）。而HyperLogLog估算的随机数的数量，比如我们统计的UV，就好比伯努利试验中试验的次数。 转为比特串 ​ 通过hash函数，将输入的数据装换为比特串，比特串中的0和1可以类比为硬币的正与反，这是实现估值统计的第一步 分桶 ​ 分桶就是上面估值优化中的分多轮，这样做的的好处可以使估值更加准确 ​ 分桶通过一个单位是bit，长度为L的大数组S，将数组S平均分为m组，m的值就是多少轮，每组所占有的比特个数是相同的，设为 P。得出如下关系： L = S.length L = m * p 数组S的内存 = L / 8 / 1024 (KB) 在HyperLogLog中，我们都知道它需要12KB的内存来做基数统计，原因就是HyperLogLog中m=16834，p=6，L=16834 * 6，因此内存为=16834 * 6 / 8 / 1024 = 12 (KB)，这里为何是6位来存储kmax，因为6位可以存储的最大值为64，现在计算机都是64位或32位操作系统，因此6位最节省内存，又能满足需求。 桶分配 ​ 假设不同的数值计算得到不同的hash值，相同的数值得到相同的hash值（这也是HyperLogLog能用来统计UV的一个关键点），此时我们需要计算值应该放到那个桶中 ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:2:7","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"Geo 主要用于存储地理位置信息，并对存储的信息进行操作 Geo底层原理 底层实现使用zset和geohash 其底层是使用zset进行实现的, 可以使用zset的指令对GEO进行操作 对经纬度编码以后的值, 作为score可以快速实现对经纬度的索引 geohash将二维的经纬度数据编码成一维数据，再使用B树索引快速查找出需要的数据 ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:2:8","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"Module(模块) BloomFilter(布隆过滤器)模块 ​ 布隆过滤器可以用于检索一个元素是否在一个集合中。它可以告诉你某种东西一定不存在或者可能存在。当布隆过滤器说，某种东西存在时，这种东西可能不存在；当布隆过滤器说，某种东西不存在时，那么这种东西一定不存在。 ​ 优点: 空间效率高，占用空间少 查询时间短 有一定的误判率 元素不能删除 BloomFilter的原理 ​ 它实际上是由一个很长的二进制(0或1)向量和一系列随机映射函数组成。当一个元素加入集合时, 使用多个哈希函数对元素key (bloom中不存value) 进行哈希，算出一个整数索引值，然后对位数组长度进行取模运算得到一个位置，每个无偏哈希函数都会得到一个不同的位置，把它们置为1。 ​ 检索时，我们只要看看这些点是不是都是1就（大约）知道集合中有没有它了： 如果这些点有任何一个为0（如下图的e），则被检元素一定不在； 如果都是1（如下图的d），并不能完全说明这个元素就一定存在其中，有可能这些位置为1是因为其他元素的存在，这就是布隆过滤器会出现误判的原因。 BloomFilter的应用场景 解决缓存穿透 黑名单校验 web拦截器 RediSearch模块 ​ RediSearch 是一个高性能的全文搜索引擎 Redis-ML模块 ​ 实时机器学习的机器学习模型服务器, 基于Redis-ML的机器学习周期: ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:2:9","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"发布和订阅 ​ Redis 发布订阅 (pub/sub) 是一种消息通信模式：发送者 (pub) 发送消息，订阅者 (sub) 接收消息。 ​ Redis 客户端可以订阅任意数量的频道 订阅/发布消息图： 新消息通过 PUBLISH 命令发送给频道 channel1 时， 这个消息就会被发送给订阅它的三个客户端 ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:3:0","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"原理 通过 SUBSCRIBE 命令订阅某频道后，redis-server 里维护了一个字典，字典的键就是一个个 channel ，而字典的值则是一个链表，链表中保存了所有订阅这个 channel 的客户端。SUBSCRIBE 命令的关键，就是将客户端添加到给定 channel 的订阅链表中。 通过 PUBLISH 命令向订阅者发送消息，redis-server 会使用给定的频道作为键，在它所维护的 channel 字典中查找记录了订阅这个频道的所有客户端的链表，遍历这个链表，将消息发布给所有订阅者. 发布的消息没有持久化，如果在订阅的客户端收不到订阅前的消息，只能收到订阅后发布的消息。 使用场景：Redis 的 Pub/Sub 系统可以构建实时的消息系统，群聊等 ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:3:1","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"事务和锁 ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:4:0","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"事务 ​ Redis 事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。 ​ Redis事务三个阶段: 开始事务、命令入队、执行事务 三大特性 单独的隔离操作 事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断 没有隔离级别的概念(直接串行化) 队列中的命令没有提交之前都不会实际被执行，因为事务提交前任何指令都不会被实际执行 不保证原子性 队列中如果有一条命令执行失败，其后的命令仍然会被执行，没有回滚 ​ 三大指令: multi(开始事务)、 exec(执行事务)、discard(执行事务前(exec)，结束事务指令（理解为手动回滚）) 错误处理 组队中某个命令出现了报告错误(Multi 中)，执行时整个的所有队列都会被取消 如果执行阶段(exec)某个命令报出了错误，则只有报错的命令不会被执行，而其他的命令都会执行，不会回滚. ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:4:1","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"锁 ​ redis使用的是乐观锁的 check-and-set 机制实现事务的。 ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:5:0","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"watch 一旦 watch 某个 key，则会一直监视这个 key，如果 key 发生了变化，就返回提示。 作用: ​ 在执行 multi 之前，先执行 watch key1 [key2]，可以监视一个(或多个) key ，如果在事务 exec 执行之前这个(或这些) key 被其他命令所改动，那么事务将被打断 使用场景: ​ 很多人同时对一个值进行操作，一旦这个值被修改，且被其他人监听，则其他人无法修改这个值 ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:5:1","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"秒杀案例 使用ab工具模拟并发 超卖问题: 超卖即卖出的数量超过了 库存数量,可以用事务解决 库存遗留问题: 库存遗留问题即系统告诉用户已经秒光，可是还有库存。原因：就是乐观锁导致很多请求都失败，先点的没秒到，后点的可能秒到了 ​ 通过 lua 脚本解决争抢问题，实际上是 Redis 利用其单线程的特性，用任务队列的方式解决多任务并发问题。 ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:5:2","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"持久化 ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:6:0","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"RDB（Redis DataBase） ​ 在指定的时间间隔内将内存中的数据集快照写入磁盘， 也就是行话讲的 Snapshot 快照，它恢复时是将快照文件直接读到内存里。 备份是如何执行的 ​ Redis 会单独创建（fork）一个子进程来进行持久化，会先将数据写入到一个临时文件 中，待持久化过程都结束了，再用这个临时文件替换上次持久化好的文件。 ​ 整个过程中，主进程是不进行任何 IO 操作的，这就确保了极高的性能 ​ 如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那 RDB 方式要比 AOF 方式更加的高效。 ​ RDB 的缺点 是最后一次持久化后的数据可能丢失。 Fork 的作用是复制一个与当前进程一样的进程。新进程的所有数据（变量、环境变量、程序计数器等）数值都和原进程一致，但是是一个全新的进程，并作为原进程的子进程 。 在 Linux 程序中，fork() 会产生一个和父进程完全相同的子进程，但子进程在此后多会 exec 系统调用，出于效率考虑，Linux 中引入了「写时复制技术」。 一般情况父进程和子进程会共用同一段物理内存，只有进程空间的各段的内容要发生变化时，才会将父进程的内容复制一份给子进程 RDB持久化流程 文件名: 默认的 RDB 配置文件名为 dump.rdb 文件路径: 默认为 Redis 启动时命令行所在的目录下 备份策略: RDB 是整个内存的压缩过的 Snapshot，RDB 的数据结构，可以配置复合的快照触发条件，默认: 如果 1 个 key 发生改变（新增，删除，修改），则 1 个小时后备份一次 如果 100 个 key 发生改变（新增，删除，修改），则 5 分钟后备份一次 如果 10000 个 key 发生改变（新增，删除，修改），则 1 分钟后备份一次 手动备份命令: save：save 时只管保存，其它不管，全部阻塞。手动保存。不建议 bgsave：Redis 会在后台异步进行快照操作，快照同时还可以响应客户端请求。推荐 通过 lastsave 命令获取最后一次成功执行快照的时间 优化配置: flushall, 刷新缓存到文件中 Stop-writes-on-bgsave-error：如果配置为 no，表示你不在乎数据不一致或者有其他的手段发现和控制，默认为 yes。 rbdcompression：压缩文件。对于存储到磁盘中的快照，可以设置是否进行压缩存储。如果是的话，Redis 会采用 LZF 算法进行压缩，如果你不想消耗 CPU 来进行压缩的话，可以设置为关闭此功能。 rdbchecksum：检查完整性。在存储快照后，还可以让 Redis 使用 CRC64 算法来进行数据校验，但是这样做会增加大约 10% 的性能消耗，如果希望获取到最大的性能提升，可以关闭此功能。默认为 yes。 RDB禁用 如果想禁用 RDB 持久化的策略，有两种方式： 配置文件 ​ 只要在配置文件不设置任何 save 指令，或者给 save 传入一个空字符串参数也可以。 命令 redis-cli config set save \"\" # save 后给空值，表示禁用保存策略 RDB备份 config get dir 查询 rdb 文件的目录, 然后将.rdb文件copy到别处即可 RDB恢复 关闭 Redis 服务 把备份的文件拷贝到 Redis 工作 / 安装目录下,如 cp /opt/dump.rdb /usr/local/bin/dump.rdb 重新启动 Redis，备份数据会直接加载 RDB 优缺点 优点: RDB文件是紧凑的二进制文件，节省磁盘空间; 比较适合做冷备，全量复制的场景。 RDB对Redis对外提供的读写服务，影响非常小 相对于AOF持久化机制来说，直接基于RDB数据文件来重启和恢复Redis进程，更加快速； 缺点： Fork 的时候，内存中的数据被克隆了一份，大致 2 倍的膨胀性需要考虑 虽然 Redis 在 fork 时使用了写时拷贝技术,但是如果数据庞大时还是比较消耗性能 在备份周期在一定间隔时间做一次备份，所以如果 Redis 意外 down 掉的话， 就会丢失最后一次快照后的所有修改 ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:6:1","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"AOF ​ 以日志的形式来记录每个写操作（增量保存），将 Redis 执行过的所有写指令记录下来(读操作不记录)，只许追加文件但不可以改写文件，Redis 启动之初会读取该文件重新构建数据，换言之，redis 重启的话就根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作。 AOF持久化流程 客户端的请求写命令会被 append 追加到 AOF 缓冲区内； AOF 缓冲区根据 AOF 持久化策略[always,everysec,no]将操作 sync 同步到磁盘的 AOF 文件中； AOF 文件大小超过重写策略或手动重写时，会对 AOF 文件 rewrite 重写，压缩 AOF 文件容量； Redis 服务重启时，会重新 load 加载 AOF 文件中的写操作达到数据恢复的目的； AOF开启 AOF默认不开启, 在 redis.conf 中配置文件里，将 appendonly no 改为 appendonly yes即可开启 AOF 的默认配置文件名叫 appendonly.aof AOF 文件默认的保存路径，同 RDB 的路径一致 AOF 和 RDB 同时开启，系统默认取 AOF 的数据（数据不会存在丢失） AOF同步频率 appendfsync always: 始终同步，每次 Redis 的写入都会立刻记入日志；性能较差但数据完整性比较好 appendfsync everysec: 每秒同步，每秒记入日志一次，如果宕机，本秒的数据可能丢失。 appendfsync no: redis 不主动进行同步，把同步时机交给操作系统。 AOF恢复流程 将有数据的 aof 文件复制一份保存到对应目录(查看目录：config get dir) 如遇到 AOF 文件损坏，通过/usr/local/bin/redis-check-aof–fix appendonly.aof 进行恢复 重启 redis，然后重新加载 AOF重写(Rewrite)机制 ​ AOF 采用文件追加方式，文件会越来越大为避免出现此种情况，新增了重写机制，当 AOF 文件的大小超过所设定的阈值时，Redis 就会启动 AOF 文件的内容压缩，只保留可以恢复数据的最小指令集，可以使用命令 bgrewriteaof。 重写原理 ​ AOF 文件持续增长而过大时，会 fork 出一条新进程来将文件重写(也是先写临时文件最后再 rename)，redis4.0 版本后的重写，是指把 rdb 的快照，以二级制的形式附在新的 aof 头部，作为已有的历史数据，替换掉原来的流水账操作。 no-appendfsync-on-rewrite：yes时,代表不写入 AOF 文件，只写入缓存，用户请求不会阻塞，但是在这段时间如果宕机会丢失这段时间的缓存数据。（降低数据安全性，提高 性能） 如果 no-appendfsync-on-rewrite 改为 no，还是会把数据往磁盘里刷，但是遇到重写操作，可能会发生阻塞。（数据安全，但是性能降低） 触发重写机制 ​ Redis 会记录上次重写时的 AOF 大小，默认配置是当 AOF 文件大小是上次 rewrite 后大小的一倍且文件大于 64M 时触发。重写虽然可以节约大量磁盘空间，减少恢复时间。但是每次重写还是有一定的负担的，因此设定 Redis 要满足一定条件才会进行重写。 auto-aof-rewrite-percentage：设置重写的基准值，文件达到 100% 时开始重写（文件是原来重写后文件的 2 倍时触发） auto-aof-rewrite-min-size：设置重写的基准值，最小文件 64MB。达到这个值开始重写 重写流程 bgrewriteaof 触发重写，判断是否当前有 bgsave 或 bgrewriteaof 在运行，如果有，则等待该命令结束后再继续执行 主进程 fork 出子进程执行重写操作，保证主进程不会阻塞 子进程遍历 redis 内存中数据写到临时文件，客户端的写请求同时写入 aof_buf 缓冲区和 aof_rewrite_buf 重写缓冲区保证原 AOF 文件完整以及新 AOF 文件生成期间的 新的数据修改动作不会丢失 子进程写完新的 AOF 文件后，向主进程发信号，父进程更新统计信息 主进程把 aof_rewrite_buf 中的数据写入到新的 AOF 文件 使用新的 AOF 文件覆盖旧的 AOF 文件，完成 AOF 重写 AOF优缺点 优点: 备份机制更稳健，丢失数据概率更低 AOF日志文件以append-only模式写入，写入性能比较高 AOF日志文件即使过大的时候，出现后台重写操作，也不会影响客户端的读写。 适合做灾难性的误删除紧急恢复 缺点 对于同一份数据来说，AOF日志文件通常比RDB数据快照文件更大，恢复速度慢 每次读写都同步的话，有一定的性能压力 存在个别 Bug，造成恢复不能 ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:6:2","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"总结 官方推荐两个都启用。如果对数据不敏感，可以选单独用 RDB。不建议单独用 AOF，因为可能会出现 Bug。如果只是做纯内存缓存，可以都不用。 RDB 持久化方式能够在指定的时间间隔内对你的数据进行快照存储 AOF 持久化方式记录每次对服务器写的操作，当服务器重启的时候会重新执行这些命令来恢复原始的数据，AOF 命令以 Redis 协议追加保存每次写的操作到文件末尾 Redis 还能对 AOF 文件进行后台重写，使得 AOF 文件的体积不至于过大 只做缓存，如果你只希望你的数据在服务器运行的时候存在，你也可以不使用任何持久化 同时开启两种持久化方式 在这种情况下，当 Redis 重启的时候会优先载入 AOF 文件来恢复原始的数据，因为在通常情况下 AOF 文件保存的数据集要比 RDB 文件保存的数据集要完整 RDB 的数据不实时，同时使用两者时服务器重启也只会找 AOF 文件，那要不要只使用 AOF 呢？建议不要，因为 RDB 更适合用于备份数据库（AOF 在不断变化不好备份），快速重启，而且不会有 AOF 可能潜在的 Bug，留着作为一个万一的手段 性能建议 因为 RDB 文件只用作后备用途，建议只在 Slave 上持久化 RDB 文件，而且只要 15 分钟备份一次就够 了，只保留 save 900 1 这条规则。 如果使用 AOF ，好处是在最恶劣情况下也只会丢失不超过两秒数据，启动脚本较简单只 load 自己的 AOF 文件就可以了，代价： 一是带来了持续的 IO 二是 AOF rewrite 的最后将 rewrite 过程中产生的新数据写到新文件造成的阻塞几乎是不可避免的 只要硬盘许可，应该尽量减少 AOF rewrite 的频率，AOF 重写的基础大小默认值 64M 太小了，可以设到 5G 以上，默认超过原大小 100% 大小重 写可以改到适当的数值 如果不使用 AOF ，仅靠 Master-Slave Repllcation 实现高可用性也可以，能省掉一大笔 IO，也减少了 rewrite 时带来的系统波动。代价是如果 Master/Slave 同时倒掉，会丢失十几分钟的数据， 启动脚本也要比较两个 Master/Slave 中的 RDB 文件，载入较新的那个，微博就是这种架构 ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:6:3","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"主从复制 ​ 主从复制，是指将一台 Redis 服务器的数据，复制到其他的 Redis 服务器。前者称为主节点 (master/leader)，后者称为从节点(slave/follower)；数据的复制是单向的，只能由主节点到从节点。Master 以写为主，Slave 以读为主。 ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:7:0","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"作用 数据冗余：主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式 故障恢复：当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；实际上是一种服务的冗余 负载均衡：在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务 （即写 Redis 数据时应用连接主节点，读 Redis 数据时应用连接从节点），分担服务器负载；尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高 Redis 服务器的并发量 高可用基石：除了上述作用以外，主从复制还是哨兵和集群能够实施的基础，因此说主从复制是 Redis 高可用的基础 ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:7:1","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"薪火相传 ​ 上一个 Slave 可以是下一个 Slave 的 Master，Slave 同样可以接收其他 Slaves 的连接和同步请求，那么该 Slave 作为了链条中下一个的 Master，可以有效减轻 Master 的写压力，去中心化降低风险","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:7:2","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"反客为主 ​ 当一个 master 宕机后，后面的 slave 可以立刻升为 master，其后面的 slave 不用做任何修改。 有两种方式可以产生新的主机： 从机手动执行命令 slaveof no one，这样执行以后从机会独立出来成为一个主机 使用哨兵模式（自动选举） ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:7:3","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"主从复制原理 Slave 启动成功连接到 Master 后会发送一个 sync 命令 Master 接到命令，做一次 bgsave，同时收集所有接收到的用于修改数据集命令，在后台进程执行完毕之后，Master 将传送整个RDB数据文件到 Slave，并完成一次完全同步; 完全同步完成后，再通知主节点将期间修改的操作记录同步到复制节点进行重放就完成了同步过程。 全量复制：而 Slave 服务在接收到数据库文件数据后，将其存盘并加载到内存中 增量复制：Master 继续将新的所有收集到的修改命令依次传给 Slave，完成同步 但是只要是重新连接 Master，一次完全同步（全量复制）将被自动执行 ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:7:4","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"哨兵模式 ​ 主从切换: 当主服务器宕机后，需要手动把一台从服务器切换为主服务器，这就需要人工干预，费事费力，还会造成一段时间内服务不可用。 ​ 哨兵模式是一种特殊的模式，首先 Redis 提供了哨兵的命令，哨兵是一个独立的进程，作为进程，它会独立运行。其原理是 哨兵通过发送命令，等待 Redis 服务器响应，从而监控运行的多个 Redis 实例 ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:8:0","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"原理 第一个定时任务： 每个sentinel节点每隔1s向所有的master、slaver、别的sentinel节点发送一个PING命令，作用：心跳检测 第二个定时任务： 每个sentinel每隔2s都会向master的__sentinel__:hello这个channel中发送自己掌握的集群信息和自己的一些信息（比如host,ip,run id），这个是利用redis的pub/sub功能，每个sentinel节点都会订阅这个channel，也就是说，每个sentinel节点都可以知道别的sentinel节点掌握的集群信息，作用：**信息交换，了解别的sentinel的信息和他们对于主节点的判断** 第三个定时任务： 每个sentinel节点每隔10s都会向master和slaver发送INFO命令，作用：发现最新的集群拓扑结构 ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:8:1","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"宕机检测 主观下线 这是第一个线程做的事情: 当sentinel节点向master发送一个PING命令，如果超过own-after-milliseconds（默认是30s，这个在sentinel的配置文件中可以自己配置）时间都没有收到有效回复，不好意思，我就认为你挂了，就是说为的主观下线（SDOWN），修改其flags状态为SRI_S_DOWN 客观下线 每个主观下线的sentinel节点都会向其他sentinel节点发送信息来询问其它sentinel是否同意服务下线。 每个收到信息的sentinel则会判断是否下线, 如果下线了则回复 sentinel收到回复之后，根据quorum的值，判断达到这个值，如果大于或等于，就认为这个master客观下线 quorum：如果要认为master客观下线，最少需要主观下线的sentinel节点个数 majority：如果确定了master客观下线了，就要把其中一个slaver切换成master，做这个事情的并不是整个sentinel集群，而是sentinel集群会选出来一个sentinel节点来做;有一个原则就是需要大多数节点都同意这个sentinel来做故障转移才可以，这个大多数节点就是这个参数; 注意：如果sentinel节点个数5，quorum=2，majority=3，那就是3个节点同意就可以，如果quorum=5，majority=3，这时候majority=3就不管用了，需要5个节点都同意才可以。 ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:8:2","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"领头sentinel的选举 ​ 已经知道了master客观下线，那就需要一个sentinel来负责故障转移，那到底是哪个sentinel节点来做这件事呢？需要通过选举实现，具体的选举过程如下： 判断客观下线的sentinel节点向其他节点发送客观下线通知 目标sentinel回复，由于这个选择领头sentinel的过程符合先到先得的原则(举例：sentinel1判断了客观下线，向sentinel2发送了第一步中的命令，sentinel2回复了sentinel1，说选你为领头，这时候sentinel3也向sentinel2发送第一步的命令，sentinel2会直接拒绝回复) 当sentinel发现选自己的节点个数超过majority（注意上面写的一种特殊情况quorum\u003emajority）的个数的时候，自己就是领头节点 如果没有一个sentinel达到了majority的数量，等一段时间，重新选举 ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:8:3","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"故障迁移 ​ 在进行选择之前需要先剔除掉一些不满足条件的slaver，这些slaver不会作为变成master的备选 剔除列表中已经下线的从服务 剔除有5s没有回复sentinel的info命令的slaver 剔除与已经下线的主服务连接断开时间超过一定宕机时长的slaver 选主过程 选择优先级最高的节点，通过sentinel配置文件中的replica-priority配置项，这个参数越小，表示优先级越高 如果第一步中的优先级相同，选择offset最大的，offset表示主节点向从节点同步数据的偏移量，越大表示同步的数据越多 如果第二步offset也相同，选择run id较小的 领头sentinel向别的slaver发送slaveof命令，告诉他们新的master是谁谁谁，你们向这个master复制数据 如果之前的master重新上线时，领头sentinel同样会给起发送slaveof命令，将其变成从节点 ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:8:4","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"脑裂问题 ​ 当集群中的master的网络出现了问题，和集群中的slaver和sentinel通信出现问题，但是本身并没有挂，由于sentinel连接不上master，就会重新选择一个新的slaver变成master，这时候如果client还么有来得及切换，就会把数据写入到原来的那个master中，一旦网络恢复，原来的master就会被变成slaver，从新的master上复制数据，那client向原来的master上写的数据就丢失了。 解决办法 配置项: min-slavers-to-write 1 min-slavers-max-lag 10 ​ 这两个配置项组合在一起配置的意思就是至少有一个slaver和master数据同步延迟不超过10s,如果所有的slaver都超过10s，那master就会拒绝接收请求，为什么加了这两个参数就可以解决问题呢？如果发生脑裂，如果client向旧的master写数据，旧的master不能向别的slaver同步数据，所以client最多只能写10s的数据。这里有些萌新可能就会有问题了，如果发生脑裂的时候，之前集群中的master和一个slaver都与别的slaver和sentinel无法通信了，但是这两个哥们还可以通信，那这个slaver不就可以正常从master同步数据吗，不就满足了上面的两个条件了吗，对，确实会这样^_^，所以你可以把min-slavers-to-write配置大一点 ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:8:5","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"集群模式 ​ Redis 集群实现了对 Redis 的水平扩容，即启动 N 个 redis 节点，将整个数据库分布存储在这 N 个节点中，每个节点存储总数据的 1/N。这样就做到了去中心化. ​ Redis 集群通过分区（partition）来提供一定程度的可用性（availability）：即使集群中有一部分节点失效或者无法进行通讯，集群也可以继续处理命令请求。 ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:9:0","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"插槽slot ​ 插槽数量固定为16384, 尽管crc16能得到65535个值; 因为16384的消息只占用了2k，而65535则需要8k; 传输大量心跳包的时候, 正常的心跳包携带节点的完整配置, 这样就会导致大量的数据在网路中,导致堵塞. ​ 每个节点负责一部分插槽。即 16384 个插槽分成N份给N个节点。集群使用公式 CRC16(key) % 16384 来计算键 key 属于哪个槽， 其中 CRC16(key) 语句用于计算键 key 的 CRC16 校验和. 缺点: 客户端每次录入、查询键值是都会计算出该 key 应该送往的插槽, 如果不在对应服务器则会重定向; 不在一个 slot 下的键值，是不能使用 mget、mset 等多键操作 可以通过 {} 来定义组的概念，从而使 key 中 {} 内相同内容的键值对放到一个 slot 中去 ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:9:1","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"集群故障恢复 如果主节点下线？从节点能否自动升为主节点？ ​ 15秒超时后, 从节点自动变成主节点, 即使后面主节点重启,也会是从节点. 如果所有某一段插槽的主从节点都宕掉，Redis 服务是否还能继续？ 如果某一段插槽的主从都挂掉，而 cluster-require-full-coverage 为 yes ，那么 ，整个集群都挂掉 如果某一段插槽的主从都挂掉，而 cluster-require-full-coverage 为 no ，那么，该插槽数据全都不能使用，也无法存储; 可以通过充分配插槽的方式,来让这些插槽转移; ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:9:2","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"集群优缺点 优点： 实现扩容 分摊压力 无中心配置相对简单 缺点: 多键操作是不被支持的 多键的 Redis 事务是不被支持的。lua 脚本不被支持 由于集群方案出现较晚，很多公司已经采用了其他的集群方案，而代理或者客户端分片的方案想要迁移至 redis cluster，需要整体迁移而不是逐步过渡，复杂度较大 ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:9:3","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"分布式锁 ​ 分布式系统多线程、多进程并且分布在不同机器上，这将使原单机部署情况下的并发控制锁策略失效; 分布式锁主流的实现方案 基于数据库实现分布式锁 基于缓存（Redis 等） 基于 Zookeeper 每一种分布式锁解决方案都有各自的优缺点： 性能：Redis 最高 可靠性：zookeeper 最高 分布式锁代码实现逻辑: 加锁（setnx 指令),添加过期时间（setnx 指令加时间） 第一步可以用下面命令原子性解决: set key value [EX seconds] [PX milliseconds] [NX|XX] EX seconds：设置失效时长，单位秒 PX milliseconds：设置失效时长，单位毫秒 NX：key不存在时设置value，成功返回OK，失败返回(nil) XX：key存在时设置value，成功返回OK，失败返回(nil) 添加唯一标识如：uuid（将 uuid 放入 Reids，然后操作时获取 uuid，添加 if 判断）,防止误删 添加原子性，用 LUA 脚本实现 ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:10:0","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"6.0 新功能 ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:11:0","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"ACL （访问控制列表) ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:11:1","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"IO多线程 ​ IO多线程其实指客户端交互部分的网络IO交互处理模块多线程，而非执行命令多线程。Redis6执行命令依然是单线程。 ​ 。Redis 的多线程部分只是用来处理网络数据的读写和协议解析，执行命令仍然是单线程。之所以这么设计是不想因为多线程而变得复杂，需要去控制 key、lua、事务，LPUSH/LPOP等等的并发问题。整体的设计大体如下:","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:11:2","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"缓存问题 ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:12:0","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"缓存穿透 ​ 产生这个问题的原因可能是外部的恶意攻击，例如，对用户信息进行了缓存，但恶意攻击者使用不存在的用户id频繁请求接口，导致查询缓存不命中，然后穿透 DB 查询依然不命中。这时会有大量请求穿透缓存访问到 DB。网络安全中也有人恶意使用这种手段进行攻击被称为洪水攻击。 解决方案 布隆过滤器(Bloom Filter) ​ 布隆过滤器可以用于检索一个元素是否在一个集合中。它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难。 ​ 对所有可能查询的参数以 Hash 的形式存储，以便快速确定是否存在这个值，在控制层先进行拦截校验，校验不通过直接打回，减轻了存储系统的压力。 缓存空值 ​ 如果一个查询返回的数据为空（不管是数据是否不存在），我们仍然把这个空结果（null）进行缓存，用于处理后续这个请求，设置空结果的过期时间会很短，最长不超过五分钟。 这样做有一个缺陷：存储空对象也需要空间，大量的空对象会耗费一定的空间，存储效率并不高。解决这个缺陷的方式就是设置较短过期时间 即使对空值设置了过期时间，还是会存在缓存层和存储层的数据会有一段时间窗口的不一致，这对于需要保持一致性的业务会有影响。 访问白名单 ​ 使用 bitmaps 类型定义一个可以访问的名单，名单 id 作为 bitmaps 的偏移量，每次访问和 bitmap 里面的 id 进行比较，如果访问 id 不在 bitmaps 里面，进行拦截，不允许访问。 进行实时监控 ​ 当发现 Redis 的命中率开始急速降低，需要排查访问对象和访问的数据，和运维人员配合，可以设置黑名单限制服务。 ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:12:1","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"缓存击穿 ​ 相较于缓存穿透，缓存击穿的目的性更强，一个存在的 key，在缓存过期的一刻，同时有大量的请求，这些请求都会击穿到 DB，造成瞬时 DB 请求量大、压力骤增。这就是缓存被击穿，只是针对其中某个 key 的缓存不可用而导致击穿，但是其他的 key 依然可以使用缓存响应。 解决方案 设置热点数据永不过期 ​ 在 redis 高峰访问之前，把一些热门数据提前存入到 redis 里面，加大这些热门数据 key 的时长，这样就不会出现热点数据过期的情况，但是当Redis内存空间满的时候也会清理部分数据，而且此种方案会占用空间，一旦热点数据多了起来，就会占用部分空间。 加互斥锁(分布式锁) 在缓存失效的时候（判断拿出来的值为空），不是立即去 load db 先使用缓存工具的某些带成功操作返回值的操作（比如 Redis 的 SETNX）去 set 一个 mutex key 当操作返回成功时，再进行 load db 的操作，并回设缓存，最后删除 mutex key 当操作返回失败，证明有线程在 load db，当前线程睡眠一段时间再重试整个 get 缓存的方法 缓存雪崩 ​ 大量的 key 设置了相同的过期时间，导致在缓存在同一时刻全部失效，此时若有大量并发请求过来，立即造成瞬时 DB 请求量大、压力骤增，引起雪崩。 ​ 缓存雪崩与缓存击穿的区别在于这里针对很多 key 缓存，前者则是某一个 key 产生原因 大量key的集中过期 缓存集群服务器某个节点宕机或断网(此情况压力不可预估, 危害更大) 解决方案 构建多级缓存架构 ​ nginx 缓存 + redis 缓存 +其他缓存（ehcache 等）。或者多增设几台 Redis，这样一台挂掉之后其他的还可以继续工作，其实就是搭建的集群。 使用锁或队列 ​ 用加锁或者队列的方式保证来保证不会有大量的线程对数据库一次性进行读写，从而避免失效时大量的并发请求落到底层存储系统上。不适用高并发情况。 设置过期标志更新缓存 ​ 记录缓存数据是否过期（设置提前量），如果过期会触发通知另外的线程在后台去更新实际 key 的缓存。 将缓存失效时间分散开 ​ 比如我们可以在原有的失效时间基础上增加一个随机值，比如 1-5 分钟随 机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。 限流降级 ​ 在缓存失效后，通过加锁或者队列来控制读数据库写缓存的线程数量。比如对某个 key 只允许一个线程查询数据和写缓存，其他线程等待。 数据预热 ​ 就是在正式部署之前，我先把可能的数据先预先访问一遍，这样部分可能大量访问的数据就会加载到缓存中。在即将发生大并发访问前手动触发加载缓存不同的key，设置不同的过期时间，让缓存失效的时间点尽量均匀 ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:12:2","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"Redis 使用场景 热点数据的缓存; 限时业务的运用 排行榜/计数器相关问题：：许多系统都会使用Redis作为系统的实时计数器，可以快速实现计数和查询的功能。 分布式锁 会话缓存(Session Cache)、共享用户Session 队列:Reids 在内存存储引擎领域的一大优点是提供 list 和 set 操作，这使得 Redis 能作为一个很好的消息队列平台来使 用。 ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:13:0","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"Redis 做缓存的两种模式 ​ 什么情况下使用索引 不需要实时更新又极其消耗数据库的数据 需要实时更新，但更新的频率不高 ​ 简单来说，就是需要在应用程序中新增缓存逻辑处理的代码。Redis就是旁路缓存，因为需要应用程序调用它。电脑内存里的磁盘文件就不是旁路缓存，因为是自动调用的，对应用程序透明。 模式一: 只读缓存 ​ 加强读请求性能。查询数据时，缓存缺失需要从DB加载。更新数据时到DB更新，Redis上的老数据直接删除。 模式二: 读写缓存 ​ 读操作和只读缓存一样。写操作分为同步直写和异步写回两种模式，根据实际的业务场景需求来进行选择: 同步直写模式: Redis和DB同时删改写回。侧重于保证数据可靠性。 异步写回模式: 只写Redis，数据要被淘汰时再写回DB。侧重于提供低延迟访问。 ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:13:1","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"替换策略**(**缓存满了怎么办**)** Redis总共有6种淘汰策略: 不进行数据淘汰的策略， noeviction:默认禁止驱逐数据。内存不够使用时，对申请内存的命令报错。 会进行数据淘汰的策略: 在设置了过期时间的数据中进行淘汰 volatile-lru:从已设置过期时间的数据集中，挑选最近最少使用的数据淘汰 volatile-ttl:从已设置过期时间的数据集中，选择将要过期的数据进行淘汰 volatile-random:从已设置过期时间的数据集中，随机选择数据进行淘汰 所有数据范围内进行淘汰 allkeys-lru:从数据集中，挑选最近最少使用的数据淘汰 allkeys-random:从数据集中，随机选择数据进行淘汰 如果数据呈现幂律分布，也就是一部分数据访问频率高，一部分数据访问频 率 低， 则使用 allkeys-lru。如果数据呈现平等分布， 也就是所有的数据访问频率都相同， 则使用 allkeys-random。 传统的LRU算法，需要维护一个大链表，随着数据访问，更新数据在链表中的位置。Redis 中对 LRU 算法进行了简化，简单来说就是增加了一个随机选取候选集合的操作; ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:14:0","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"redis与memcache的区别 ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:15:0","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"存储内容 redis 支持更为丰富的数据类 memcache所有的值均是简单的字符串 ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:15:1","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"数据安全 redis可以持久化 memcache不能持久化 ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:15:2","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"应用场景 redis不仅仅能作为NoSQL数据库使用，还能用途消息队列、数据堆栈、数据缓存等 memcache适合缓存sql语句，数据集，用户临时数据等 ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:15:3","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"基础架构 redis处理网络请求采用单线程模型， memcache采用多线程异步IO的方式 ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:15:4","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"Redis过期策略 定时删除，redis默认是每100ms就随机抽取一些设置了过期时间的key，并检查其是否过期，如果过期就删除。因此该删除策略并不会删除所有的过期key。 惰性删除，在客户端需要获取某个key时，redis将首先进行检查，若该key设置了过期时间并已经过 期就会删除。 定期删除:每隔一段时间程序就对数据库进行一次检查，删除里面的过期键。至于要删除多少过期键，以及 要检查多少个数据库，则由算法决定。 实际上redis结合上述两种手段结合起来，保证删除过期的key。 ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:16:0","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"Redis 如何做内存优化? ​ 尽可能使用哈希表(hash)，哈希表(是说散列表里面存储的数少)使用的内存非常小，所以你应该尽可能的将你的数据模型抽象到一个散列表里面。比如你的 web 系统中有一个用户对象，不要为这个用户的名称，姓氏，邮 箱，密码设置单独的 key,而是应该把这个用户的所有信息存储到一张哈希表里面。 ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:17:0","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"Redis 回收进程如何工作的? 一个客户端运行了新的命令，添加了新的数据 Redi 检查内存使用情况，如果大于 maxmemory 的限制,则根据设 定好的策略进行回收(如果设置为noeviction则报错) ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:18:0","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"Redis如何做异步队列 ​ 一般使用 list 结构作为队列，rpush 生产消息，lpop 消费消息。当 lpop 没有消息的时候，要适当 sleep 一会再重试。 如果不用 sleep 呢? ​ list 还有个指令叫 blpop，在没有消息的时候，它会阻塞住直到消息到来。 2. 如果对方追问能不能生产一次消费多次呢? ​ 使用 pub/sub 主题订阅者模式，可以实现1:N 的消息队列。 3. pub/sub 有什么缺点? ​ 在消费者下线的情况下，生产的消息会丢失，得使用专业的消息队列如 RabbitMQ 等。 4. redis 如何实现延时队列? ​ 使用 sortedset，拿时间戳作为 score，消息内容作为 key 调用 zadd 来生产消息，消费者用 range by score 指令获取 N 秒之前的数据轮询进行处理 ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:19:0","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"什么是缓存预热?如何实现缓存预热? 缓存预热 ​ 在刚启动的缓存系统中，如果缓存中没有任何数据，如果依靠用户请求的方式重建缓存数据，那么对数据库的压力非常大，而且系统的性能开销也是巨大的。 ​ 此时，最好的策略是启动时就把热点数据加载好。这样，用户请求时，直接读取的就是缓存的数据，而无需去读取 DB 重建缓存数据。举个例子，热门的或者推荐的商品，需要提前预热到缓存中。 如何实现 一般来说，有如下几种方式来实现: 数据量不大时，项目启动时，自动进行初始化。 写个修复数据脚本，手动执行该脚本。 写个管理界面，可以手动点击，预热对应的数据到缓存中。 ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:20:0","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"应用问题 MySQL 里有2000w 数据，Redis 中只存20w 的数据，如何保证 redis 中 的数据都是热点数据? ​ Redis 内存数据集大小上升到一定大小的时候，就 会施行数据淘汰策略。 假如 Redis 里面有1 亿个 key，其中有10w 个 key 是以某个固定的已知的 前缀开头的，如果将它们全部找出来? ​ 使用 keys 指令可以扫出指定模式的 key 列表。 如果这个 redis 正在给线上的业务提供服务，那使用 keys 指令会有什么问题? ​ redis 的单线程的。keys 指令会导致线程阻塞一段时间，线上服务会停 顿，直到指令执行完毕，服务才能恢复。这个时候可以使用 scan 指令，scan 指令可以无阻塞的提取出指定模式的 key 列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用 keys指令长。 ​ 数据库和缓存如何同步? 延迟双删策略 先删除缓存 更新数据库数据 在更新数据库过程中如果发生了读,则缓存中有旧数据, 则需要再次删除, 至于过了多久再删,需要评估; 如果第二次删除失败了怎么解决? 删除缓存、更新数据库数据 数据库会将操作信息写入binlog日志当中 订阅程序提取出所需要的数据以及key 另起一段非业务代码，获得该信息 尝试删除缓存操作，发现删除失败 将这些信息发送至消息队列 重新从消息队列中获得该数据，重试操作,直到成功。 ","date":"2022-08-28","objectID":"/redis%E5%85%AB%E8%82%A1%E6%96%87/:21:0","tags":[],"title":"Redis八股文","uri":"/redis%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"Mysql数据库 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:0:0","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"逻辑架构 MySQL基架大致包括如下几大模块组件: MySQL向外提供的交互接口（Connectors）: ​ Connectors组件，是MySQL向外提供的交互组件，如java,.net,php等语言可以通过该组件来操作SQL语句，实现与SQL的交互。 管理服务组件和工具组件(Management Service \u0026 Utilities): ​ 提供对MySQL的集成管理，如备份(Backup),恢复(Recovery),安全管理(Security)等 连接池组件(Connection Pool): ​ 负责监听对客户端向MySQL Server端的各种请求，接收请求，转发请求到目标模块。每个成功连接MySQL Server的客户请求都会被创建或分配一个线程，该线程负责客户端与MySQL Server端的通信，接收客户端发送的命令，传递服务端的结果信息等。 SQL接口组件(SQL Interface): ​ 接收用户SQL命令，如DML,DDL和存储过程等，并将最终结果返回给用户。 查询分析器组件(Parser): ​ 首先分析SQL命令语法的合法性，并尝试将SQL命令分解成数据结构，若分解失败，则提示SQL语句不合理。 优化器组件（Optimizer）: ​ 对SQL命令按照标准流程进行优化分析。 缓存主件（Caches \u0026 Buffers）: ​ 缓存和缓冲组件 MySQL存储引擎: ​ 关系型数据库的存储是以表的形式进行的，对于表的创建，数据的存储，检索，更新等都是由MySQL存储引擎完成的 物理文件（File System） ​ 实际存储MySQL 数据库文件和一些日志文件等的系统。 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:1:0","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"MySQL 执行查询的过程 客户端通过 TCP 连接发送连接请求到 MySQL 连接器，连接器会对该请求进行权限验证及连接资源分配 查缓存。（当判断缓存是否命中时，MySQL 不会进行解析查询语句，而是直接使用 SQL 语句和客户端发送过来的其他原始信息。所以，任何字符上的不同，例如空格、注解等都会导致缓存的不命中。） 语法分析。 如何把语句给到预处理器(分析器)，检查数据表和数据列是否存在，解析别名看是否存在歧义。 优化器。是否使用索引，生成执行计划。 交给执行器，将数据保存到结果集中，同时会逐步将数据缓存到查询缓存中，最终将结果集返回给客户端。 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:1:1","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"MySQL存储引擎 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:1:2","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"InnoDB存储引擎 ​ MySQL5.5版本之后，MySQL的默认内置存储引擎已经是InnoDB了. 主要特点: 支持ACID事务。默认的事务隔离级别为可重复度，通过MVCC（并发版本控制）来实现的。 使用的锁粒度为行级锁，可以支持更高的并发； 支持外键 在InnoDB中存在着缓冲管理，通过缓冲池，将索引和数据全部缓存起来，加快查询的速度； 主键索引采用聚集索引(索引的数据域存储数据文件本身),二级索引的数据域存储主键的值;因此从二级索引查找数据，需要先通过二级索引找到主键值，再访问聚集索引；最好使用自增主键，防止插入数据时，为维持B+树结构，文件的大调整。 InnoDB四大特性 插入缓存（insert buffer) ​ 索引数据存储在磁盘上，主键索引由于天然自增，无须磁盘的随机 I/O，只需不断追加即可。但普通索引大概率无序，默认情况下需要进行随机磁盘 I/O 操作，效率极差.为了解决普通索引插入效率低下的问题，InnoDB 存储引擎引入 Insert Buffer 的概念. 原理: 对于普通索引（非聚集索引）不是直接插入到索引页中，而是先判断插入的非聚集索引页是否在缓存池中，如果在直接插入，否则先放入 Insert buffer 对象中，然后以一定频率和辅助索引页子节点进行合并操作，此时通常能将多个插入合并到一个操作中，提高插入性能 使用前提: 非聚集索引, 且索引不唯一 ​ 因为如果要保证索引唯一, 每次操作还得去判断当前索引值是否已存在，而判断又涉及到磁盘随机 I/O，从而发挥不出插入缓存的优势. 二次写(double write) ​ InnoDB 索引页一般 16KB 大小，而操作系统写文件以 4KB 为单位，这就导致同一页需要分四块分别写入。此时就存在写完一块系统崩溃或者断电等特殊情况，此时就导致写入数据不完整的问题. ​ 二次写就是为了解决该问题，double write 分为两部分，一部分 doublewrite buffer，其大小 2MB，另一部分是磁盘上共享表空间中连续的 128 个页，也是2MB 原理: 先将脏数据写入 doublewrite buffer，doublewrite buffer 每次 1MB 写入共享表空间的磁盘上，完成以上两步后调用 fsync 函数，将数据同步到各个表空间. ​ 如果操作系统在将页写入磁盘的过程中崩溃，InnoDB 重启发现页数据损坏后，可以从共享表的 doublewrite 中找到副本，用于数据恢复. 自适应哈希索引(ahi) ​ InnoDB 虽然主要使用 B+ 树作为索引结构，但在某些特殊场景下用到哈希索引。InnoDB 会监控对表上索引的查找，如果发现某个索引频繁被访问，则建立哈希索引。InnoDB 会自动根据访问的频率和模式来为某些页建立哈希索引. 预读(read ahead) ​ 请求一页的数据时，可以把后面几页的数据也一起返回，放到数据缓冲池中，这样如果下次刚好需要下一页的数据，就不再需要到磁盘读取 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:1:3","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"MyISAM存储引擎 ​ 一个MyISAM表三个文件: 表结构.frm、索引.myi、数据 .myd, ​ 主要特点为： 不支持事务 不支持外键;如果强行增加外键,不会提示错误,只是外键不其作用; 对数据的查询缓存只会缓存索引，不会像InnoDB一样缓存数据，而且是利用操作系统本身的缓存； 默认的锁粒度为表级锁，所以并发度很差，加锁快，锁冲突较少，所以不太容易发生死锁； 采用非聚集索引,索引文件的数据存储指向数据文件的指针; 存储表的总行数, count(*) 速度快 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:1:4","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"MyISAM 和InnoDB区别 InnoDB 支持事务、外键，MyISAM 都不支持 InnoDB 是聚集索引，数据文件是和索引绑在一起的，必须要有主键，通过主键索引效率很高；MyISAM 是非聚集索引，数据文件是分离的，索引保存的是数据文件的指针，主键索引和辅助索引是独立的。 Innodb 不支持全文索引，而 MyISAM 支持全文索引，查询效率上 MyISAM 要高； InnoDB 不保存表的具体行数，MyISAM 用一个变量保存了整个表的行数。(select count(*)) MyISAM 采用表级锁(table-level locking)；InnoDB 支持行级锁(row-level locking)和表级锁,默认为行级锁。所以InnoDB相对于MyISAM来说，更容易发生死锁，锁冲突的概率更大，而且上锁的开销也更大，因为需要为每一行加锁； InnoDB比MyISAM支持更高的并发 InnoDB数据与索引一起保存.ibd，MyISAM表结构.frm 索引.myi 数据.myd ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:1:5","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"引擎的选择(使用的场景) MyISAM：以读写插入为主的应用程序，比如博客系统、新闻门户网站。 Innodb：更新（删除）操作频率也高，或者要保证数据的完整性；并发量高，支持事务和外键。 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:1:6","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"索引 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:2:0","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"什么是索引 ​ 索引是一种特殊的文件(InnoDB数据表上的索引是表空间的一个组成部分)，它们包含着对数据表里所有记录的引用指针。索引是一种数据结构。数据库索引，是数据库管理系统中一个排序的数据结构，以协助快速查询、更新数据 库表中数据。索引的实现通常使用 B树及其变种 B+树。 ​ 更通俗的说，索引就相当于目录。为了方便查找书中的内容，通过对内容建立索引形成目录。索引是一个文件，它是要占据物理空间的。 优点 可以大大加快数据的检索速度，这也是创建索引的最主要的原因。 通过使用索引，可以在查询的过程中，使用优化隐藏器，提高系统的性能。 缺点 时间方面:创建索引和维护索引要耗费时间，具体地，当对表中的数据进行增加、删除和修改的时候，索引也 要动态的维护，会降低增/改/删的执行效率; 空间方面:索引需要占物理空间。 索引类型 主键索引(聚集索引) 数据列不允许重复，不允许为 NULL，一个表只能有一个主键。 唯一索引 数据列不允许重复，允许为 NULL值，一个表允许多个列创建唯一索引。 普通索引 基本的索引类型，没有唯一性的限制，允许为 NULL值。 全文索引 是目前搜索引擎使用的一种关键技术。 联合索引 hash索引:(InnoDB和myIsam都不支持hash索引) ​ 适用于快速找到等值比较查询的数据, 但是不适合范围查询和排序 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:2:1","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"数据结构: B+树 ​ 在数据库中，B+Tree的高度一般都在2~4层。mysql的innoDB存储引擎在设计时是将根节点常驻内存的，也就是说查找某一键值的行记录时最多只需要1~3次磁盘I/O操作。 B+树的非叶子节点不保存关键字记录的指针,只进行数据索引，这样使得B+树每个非叶子节点所能保存的关键字大大增加 B+树叶子节点保存了父节点的所有关键字记录的指针，所有数据地址必须要到叶子节点才能获取到。所以每次数据查询的次数都一样； 为什么使用B+树,而不是B树 B+数的层级更少: 相较于B树B+每个非叶子节点存储的关键字数更多，树的层级更少所以查询数据更快； B+树查询速度更稳定：B+所有关键字数据地址都存在叶子节点上，所以每次查找的次数都相同所以查询速度要比B树更稳定; B+树天然具备排序功能：B+树所有的叶子节点数据构成了一个有序链表，在查询大小区间的数据时候更方便，数据紧密性很高，缓存的命中率也会比B树高。 B+树全节点遍历更快：B+树遍历整棵树只需要遍历所有的叶子节点即可，而不需要像B树一样需要对每一层进行遍历，这有利于数据库做全表扫描。 B树相对于B+树的优点是，如果经常访问的数据离根节点很近，而B树的非叶子节点本身存有关键字其数据的地址，所以这种数据检索的时候会要比B+树快。 B+树和红黑树对比 B+数查询次数更少: 数高更低 磁盘预读: 为了减少IO操作,往往不严格按需读取,而是预读.B+树叶子结点存储相临，读取会快一些。 存储更多索引结点: B+树只在叶子结点储存数据，非叶子结点存索引，而一个结点就是磁盘一个内存页，内存页大小固定，那么相比B树这些可以存更多的索引结点，出度更大，树高矮，查询次数少，磁盘IO少。 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:2:2","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"使用索引一定会提高性能吗? ​ 通常，通过索引查询数据比全表扫描要快。但是我们也必须注意到它的代价。 ​ 索引需要空间来存储，也需要定期维护，每当有记录在表中增减或索引列被修改时，索引本身也会被修改。这意味着每条记录的 INSERT，DELETE， UPDATE 将为此多付出4，5 次的磁盘 I/O。因为索引需要额外的存储空间和处理，那些不必要的索引反而会使查询 反应时间变慢。 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:2:3","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"聚簇索引和非聚簇索引 聚簇索引 ​ 将数据存储与索引放到了同一个文件中，找到索引也就找到了数据(即索引的叶子结点存储真正的数据) 特点 聚簇索引具有唯一性: 由于聚簇索引是将数据跟索引结构放到一块，因此一个表仅有一个聚簇索引。 表中行的物理顺序和索引中行的物理顺序是相同的: 在创建任何非聚簇索引之前创建聚簇索引，这是因为聚簇索引改变了表中行的物理顺序，数据行 按照一定的顺序排列，并且自动维护这个顺序； 聚簇索引默认是主键; 如果表中没有定义主键，InnoDB 会选择一个唯一且非空的索引代替。 MyISAM使用的是非聚簇索引 优点 索引和数据存储在一起, 同一页会有多刚数据, 可以一次加载一页到缓存中, 节省再次访问和范围访问的IO次数, 提高效率 建议使用自增ID作为主键: ​ 当使用主键为聚簇索引时，主键最好不要使用uuid，因为uuid的值太过离散，不适合排序且可能出线新增加记录的uuid，会插入在索引树中间的位置，导致索引树调整复杂度变大，消耗更多的时间和资源。 ​ 聚簇索引的数据的物理存放顺序最好与索引顺序是一致的, 这样能够一页一页写入物理数据, 索引结构相对紧凑，磁盘碎片少，效率也高. 非聚簇索引 将数据存储与索引分开，索引结构的叶子节点指向了数据的对应行，myisam通过 key_buffer 把索引先缓存到内存中，当需要访问数据时(通过索引访问数据)，在内存中直接搜索索引，然 后通过索引找到磁盘相应数据，这也就是为什么索引不在 key buffer 命中时，速度慢的原因。 联合索引 ​ 当有多个查询条件时，我们推荐使用复合索引。索引的组合使用（索引合并）效率是低于复合索引的。 ​ 比如：我们经常按照 A列 B列 C列进行查询时，通常的做法是建立一个由三个列共同组成的复合索引而不是对每一个列建立普通索引。 联合索引的优点: 减少开销: 建一个联合索引(Gid,Cid,SId)，实际相当于建了(Gid)、(Gid,Cid)、(Gid,Cid,SId)三个索引。每多一个索引，都会增加写操作的开销和磁盘空间的开销。对于大量数据的表，使用联合索引会大大的减少开销！ 覆盖索引: 对联合索引(Gid,Cid,SId), 对于查询这三个字段的sql可以通过遍历索引就能得到所需全部数据, 无需回表; 减少io操作. 效率高: 索引列越多, 通过索引筛选出的数据越少, 因而需要回表的数据就少. 缺点: 在增删改数据的同时, 需要维护索引,这是很花时间的,而且索引所需的磁盘空间不少. 注意事项 最左前缀匹配原则: mysql以最左边的为起点任何连续的索引都能匹配上。同时遇到范围查询(\u003e、\u003c、between、like)就会停止匹配。 ​ 如b = 2 如果建立(a,b)顺序的索引，是匹配不到(a,b)索引的；但是如果查询条件是a = 1 and b = 2或者a=1(又或者是b = 2 and b = 1)就可以，因为优化器会自动调整a,b的顺序。再比如a = 1 and b = 2 and c \u003e 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，因为c字段是一个范围查询，它之后的字段会停止匹配 如果我们创建了(a, b,c)的复合索引，那么其实相当于创建了(a,b,c)、(a,b)、(a)三个索引，这被称为最佳左前缀特性;根据最左匹配原则, 写sql时需要将范围查询写在最后. ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:2:4","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"有索引以后查询的流程 从索引里自上而下查询 走到叶子节点查询到id 根据id去聚簇索引中查找真正的数据，这个过程叫做回表 如果你要的数据索引都有了不需要回表，就叫索引覆盖。 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:2:5","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"哪些情况适合建索引 频繁作为where条件语句查询的字段 关联字段需要建立索引，例如外键字段等 排序字段可以建立索引 分组字段可以建立索引，因为分组的前提是排序 统计字段可以建立索引，例如count(),max() ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:2:6","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"哪些情况不适合建索引 频繁更新的字段不适合建立索引 where条件中用不到的字段不适合建立索引 表数据可以确定比较少的不需要建索引 数据重复且发布比较均匀的的字段不适合建索引（唯一性太差的字段不适合建立索引），例如性别，真假值. 参与列计算的列不适合建索引，索引会失效 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:2:7","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"索引不会包含NULL值的列 单列索引无法储null值，复合索引无法储全为null的值。 查询时，采用is null条件时，不能利用到索引，只能全表扫描。 ​ 原因: 索引是有序的。NULL值进入索引时，无法确定其应该放在哪里。 如果需要把空值存入索引，方法有二：其一，把NULL值转为一个特定的值，在WHERE中检索时，用该特定值查找。其二，建立一个复合索引. create index ind_a on table(col1,1); 通过在复合索引中指定一个非空常量值，而使构成索引的列的组合中，不可能出现全空值。 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:2:8","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"排序的索引问题 ​ mysql查询只使用一个索引，因此如果where子句中已经使用了索引的话，那么order by中的列是不会使用索引的。因此数据库默认排序可以符合要求的情况下不要使用排序操作；尽量不要包含多个列的排序，如果需要最好给这些列创建复合索引。 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:2:9","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"Mysql索引失效的几种情况 如果条件中有or，即使其中有条件带索引也不会使用(这也是为什么尽量少用or的原因)要想使用or，又想让索引生效，只能将or条件中的每个列都加上索引 复合索引不满足最左原则就不能使用索引 like查询以%开头 如果mysql估计使用全表扫描要比使用索引快,则不使用索引 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:2:10","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"Explain 关键字 explain关键字可以模拟MySQL优化器执行SQL语句，可以很好的分析SQL语句或表结构的性能瓶颈。 type类型 ALL : 全表扫描(Full Table Scan)， MySQL将遍历全表以找到匹配的行。 index: 全索引扫描(Full Index Scan)， index 与 ALL 区别为 index 类型只遍历索引树。MYSQL 遍历整个索引来查找匹配的行。 range: 索引范围扫描， 常见于 ‘\u003c'， ‘\u003c='， ‘\u003e'， ‘\u003e='， ‘between’ 等操作符 ref: 使用非唯一性索引或者唯一索引的前缀扫描， 返回匹配某个单独值的记录行。 Eq_ref : 类似ref， 区别就在使用的索引是唯一索引。在联表查询中使用 primary key 或者 unique key 作为关联条件。 Const/system: 当 MySQL 对查询某部分进行优化， 并转换为一个常量时， 使用这些类型访问。如将主键置于 where 列表中， MySQL 就能将该查询转换为一个常量， system 是 const 类型的特例， 当查询的表只有一行的情况下使用 system。 NULL: MySQL 不用访问表或者索引就直接能到结果。 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:2:11","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"事务 MySQL 中只有 Innodb 引擎才支持事务; 事务是一个不可分割的数据库操作序列，也是数据库并发控制的基本单位，其执行的结果必须使数据库从一种一致性状态变到另一种一致性状态。事务是逻辑上的一组操作，要么都执行，要么都不执行。 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:3:0","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"事务的实现原理 事务是基于重做日志文件(redo log)和回滚日志(undo log)实现的。 每提交一个事务必须先将该事务的所有日志写入到重做日志文件进行持久化，数据库就可以通过重做日志来保证事务的原子性和持久性。 每当有修改事务时，还会产生 undo log，如果需要回滚，则根据 undo log 找到回滚的数据位置,恢复成原来的数据。undo log 主要实现数据库的一致性。 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:3:1","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"事务的四大特性(ACID) 原子性(Atomicity) ​ 一个事务（transaction）中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。 一致性（Consistency） ​ 事务开始之前和事务结束以后，数据库的完整性没有被破坏。 即数据间的行为保持一致(比如：A向B转账，不可能A扣了钱，B却没有收到) 隔离性（Isolation） ​ 数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致; 事务隔离分为不同级别，包括读未提交（Read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（Serializable）。 持久性（Durability） ​ 事务处理结束后，对数据的修改就是永久的;即落入磁盘 ​ ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:3:2","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"事务的隔离级别 隔离级别\\解决问题 脏读 不可重复读 幻读 读未提交(Read Uncommitted) × × × 读已提交(Read Committed) √ × × 可重复读(Repeatable Read) √ √ × 串行化(Serializable) √ √ √ 读未提交(Read Uncommitted) 脏读问题: 事务A和事物B，事务A未提交的数据，事务B可以读取到;这里读取到的数据叫做“脏数据”，叫脏读 事务读不阻塞其他事务读和写，事务写阻塞其他事务写但不阻塞读。可以通过写操作加“持续-X锁”实现 读已提交(Read Committed) 不可重复读问题: 一个事务读到另一个事务修改后并提交的数据（update）。在同一个事务中，对于同一组数据读取到的结果不一致.针对update和delete 事务读不会阻塞其他事务读和写，事务写会阻塞其他事务读和写。可以通过写操作加**“持续-X”锁**，**读操作加“临时-S锁”实现**。 可重复读(Repeatable Read) 幻读问题: A事务在本次事务中对未操作的数据进行多次查询，发现第一次没有，第二次出现了就像幻觉一样。或者第一次有而第二次没有。针对delete和insert。 事务读会阻塞其他事务事务写但不阻塞读，事务写会阻塞其他事务读和写。可以通过写操作加“持续-X”锁，读操作加“持续-S锁”实现。 串行化(Serializable) 事务A和事务B，事务A在操作数据库时，事务B只能排队等待 这种隔离级别很少使用，吞吐量太低，用户体验差 这种级别可以避免“幻像读”，每一次读取的都是数据库中真实存在数据，事务A与事务B串行，而不并发。 使用“表级锁”。 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:3:3","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"锁机制 表锁的特点就是开销小、加锁快，不会出现死锁。锁粒度大，发生锁冲突的概率小，并发度相对低。 行锁的特点就是开销大、加锁慢，会出现死锁。锁粒度小，发生锁冲突的概率高，并发度搞。 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:4:0","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"行锁的种类 记录锁（Record Lock） 不加索引, 锁住的是表; 记录锁是加在索引上的,这是标准的行级锁 间隙锁（GAP Lock） ​ 在RR这个级别下，为了避免幻读，引入了间隙锁，他锁定的是记录范围，不包含记录本身，也就是不允许在范围内插入数据。 ​ 唯一索引 等值判断只会产生记录锁;范围查询会产生间隙锁;普通索引等值判断会产生间隙锁 临键锁(next-key Lock) ​ 临键锁，是记录锁与间隙锁的组合，它的封锁范围，既包含索引记录，又包含索引区间。 注：临键锁的主要目的，也是为了避免幻读(Phantom Read)。如果把事务的隔离级别降级为RC，临键锁则也会失效。 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:4:1","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"表锁 ​ 对于InnoDB表，在绝大部分情况下都应该使用行级锁，因为事务和行锁往往是我们之所以选择InnoDB表的理由。 使用表级锁的情况 事务需要更新大部分或全部数据，表又比较大，如果使用默认的行锁，不仅这个事务执行效率低，而且可能造成其他事务长时间锁等待和锁冲突，这种情况下可以考虑使用表锁来提高该事务的执行速度。 事务涉及多个表，比较复杂，很可能引起死锁，造成大量事务回滚。这种情况也可以考虑一次性锁定事务涉及的表，从而避免死锁、减少数据库因事务回滚带来的开销。 使用表锁的注意事项 表锁不是由InnoDB存储引擎层管理的，而是由其上一层ＭySQL Server负责的，仅当autocommit=0、innodb_table_lock=1（默认设置）时，InnoDB层才能知道MySQL加的表锁, ＭySQL Server才能感知InnoDB加的行锁，这种情况下，InnoDB才能自动识别涉及表级锁的死锁； 在用LOCAK TABLES对InnoDB锁时要注意，要将AUTOCOMMIT设为0，否则ＭySQL不会给表加锁；事务结束前，不要用UNLOCAK TABLES释放表锁，因为UNLOCK TABLES会隐含地提交事务；COMMIT或ROLLBACK不能释放用LOCAK TABLES加的表级锁，必须用UNLOCK TABLES释放表锁 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:4:2","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"InnoDB的锁类型 ​ InnoDB的锁类型主要有读锁(共享锁)、写锁(排他锁)、意向锁和MDL锁。 读锁 ​ 读锁（共享锁，shared lock）简称S锁。一个事务获取了一个数据行的读锁，其他事务能获得该行对应的读锁但不能获得写锁 应用情况: 自动提交模式下的select查询语句，不需加任何锁,直接返回查询结果，这就是一致性非锁定读。 通过select…. lock in share mode被读取的行记录或行记录的范围上加一个读锁,让其他事务可以读,但是要想申请加写锁,那就会被阻塞。 写锁 ​ 写锁，也叫排他锁，或者叫独占锁，简称x锁。一个事务获取了一个数据行的写锁，其他事务就不能再获取该行的其他锁与锁优先级最高。 应用情况: 1. 一些DML语句的操作都会对行记录加写锁。2 . 比较特殊的就是select for update，它会对读取的行记录上加一个写锁，那么其他任何事务不能对被锁定的行上加任何锁了，要不然会被阻塞。 MDL ​ MDL锁用于保证表中元数据的信息。在会话A中，表开启了查询事务后，会自动获得一个MDL锁，会话B就不可以执行任何DDL语句，不能执行为表中添加字段的操作，会用MDL锁来保证数据之间的一致性。 意向锁 ​ mysql的innodb引擎中，意向锁是表级锁，意向锁有两种: 意向共享锁（IS） 是指在给一个数据行加共享锁前必须获取该表的意向共享锁 意向排它锁（IX） 是指在给一个数据行加排他锁前必须获取该表的意向排他锁 意向锁和MDL锁都是为了防止在事务进行中，执行DDL语句导致数据不一致。 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:4:3","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"乐观锁和悲观锁 ​ 这是从逻辑的角度进行分类,并不是真正的的锁结构 乐观锁 ​ 乐观锁大多是基于数据版本记录机制实现，一般是给数据库表增加一个\"version\"字段。读取数据时，将此版本号一同读出，之后更新时，对此版本号加一。此时将提交数据的版本数据与数据库表对应记录的当前版本信息进行比对，如果提交的数据版本号大于数据库表当前版本号，则予以更新，否则认为是过期数据。 悲观锁 悲观锁依靠数据库提供的锁机制实现。MySQL中的共享锁和排它锁都是悲观锁。数据库的增删改操作默认都会加排他锁，而查询不会加任何锁。此处不赘述。 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:4:4","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"锁等待和死锁 锁等待 ​ 锁等待是指一个事务过程中产生的锁，其他事务需要等待上一个事务释放它的锁，才能占用该资源。如果该事务一直不释放，就需要持续等待下去，直到超过了锁等待时间，会报一个等待超时的错误。 ​ MysQL中通过innodb_lock_wait_timeout参数控制所等待的超时时间。 死锁 死锁的实例: 两行记录，至少两个事务 事务A 操作 第n行数据，并加锁 update teacher set name = 'a' where id = 1; 事务B 操作 第m行数据，并加锁 update teacher set name = 'b' where id = 2; 事务A 操作 第m行数据 update teacher set name = 'c' where id = 2; 事务B 操作 第n行数据 update teacher set name = 'd' where id = 1; 形成死锁 Deadlock found when trying to get lock; try restarting transaction InnoDB引擎可以自动检测死锁并回滚该事务 如何避免死锁 如果不同的程序会并发处理同一个表，或者涉及多行记录，尽量约定使用相同顺序访问表，可以大大减少死锁的发生。 业务中尽量采用小事务，避免使用大事务，要即使提交和回滚事务，可减少死锁产生的概率。 同一个事务中尽量做到一次锁定所需要的所有资源，减少死锁发生的概率。 对于非常容易发生死锁的业务，可以尝试使用升级锁的力度，该用表锁减少死锁的发生。 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:4:5","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"MVCC 多版本并发控制 ​ MVCC，全称Multi-Version Concurrency Control，即多版本并发控制。MVCC是一种并发控制的方法，一般在数据库管理系统中，实现对数据库的并发访问，在编程语言中实现事务。 ​ MVCC在InnoDB中的实现主要是为了提高数据库并发性能，用更好的方式去处理读-写冲突，做到即使有读写冲突时，也能做到不加锁，非阻塞并发读 当前读和快照读 当前读: 它读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行加锁. 共享锁和排他锁都是当前读 快照读: 快照读是基于提高并发性能的考虑，快照读的实现是基于多版本并发控制，即MVCC. 既然是基于多版本，即快照读可能读到的并不一定是数据的最新版本，而有可能是之前的历史版本 像不加锁的select操作就是快照读，即不加锁的非阻塞读；快照读的前提是隔离级别不是串行级别，串行级别下的快照读会退化成当前读； MVCC解决的问题 多版本并发控制（MVCC）是一种用来解决读-写冲突的无锁并发控制, 也就是为事务分配单向增长的时间戳，为每个修改保存一个版本，版本与事务时间戳关联，读操作只读该事务开始前的数据库的快照。 在并发读写数据库时，可以做到在读操作时不用阻塞写操作，写操作也不用阻塞读操作，提高了数据库并发读写的性能. 同时还可以解决脏读，幻读，不可重复读等事务隔离问题，但不能解决更新丢失问题(多次写导致上次更新丢失) MVCC实现原理 ​ 它的实现原理主要是依赖记录中的 3个隐式字段，undo日志 ，Read View 来实现的 隐式字段 ​ 每行记录除了自定义的字段外, 还有数据库隐式定义的 DB_TRX_ID,DB_ROLL_PTR,DB_ROW_ID等字段 DB_TRX_ID 6Byte; 最近修改(修改/插入)事务ID：记录创建这条记录/最后一次修改该记录的事务ID DB_ROLL_PTR 7byte; 回滚指针，指向这条记录的上一个版本（存储于rollback segment里） DB_ROW_ID 6byte; 隐含的自增ID（隐藏主键），如果数据表没有主键，InnoDB会自动以DB_ROW_ID产生一个聚簇索引 实际还有一个删除flag隐藏字段, 既记录被更新或删除并不代表真的删除，而是删除flag变了 undo日志 insert undo log 代表事务在insert新记录时产生的undo log, 只在事务回滚时需要，当事务提交后，该类型的undo日志就没用了，它占用的Undo Log Segment也会被系统回收(也就是该undo日志占用的Undo页面链表要么被重用，要么被释 放)。 update undo log 事务在进行update或delete时产生的undo log; 不仅在事务回滚时需要，在快照读时也需要；所以不能随便删除，只有在快速读或事务回滚不涉及该日志时，对应的日志才会被purge线程统一清除 purge线程 为了实现InnoDB的MVCC机制，更新或者删除操作都只是设置一下老记录的deleted_bit，并不真正将过时的记录删除。 为了节省磁盘空间，InnoDB有专门的purge线程来清理deleted_bit为true的记录。 对MVCC有帮助的实质是update undo log，undo log实际上就是存旧记录链，它的执行流程如下： 比如persion表有一条记录，记录如下，name为Jerry, age为24岁，隐式主键是1，事务ID和回滚指针，我们假设为NULL 事务1对该记录的name做出了修改，改为Tom 先对这行数据加排他锁 然后把该行数据拷贝到undo log中，作为旧记录，即在undo log中有当前行的拷贝副本 拷贝完毕后，修改该行name为Tom，并且修改隐藏字段的事务ID为当前事务1的ID, 我们默认从1开始，之后递增，回滚指针指向拷贝到undo log的副本记录，既表示我的上一个版本就是它 事务提交后，释放锁 事务2修改person表的同一个记录，将age修改为30岁 获取排他锁、加锁 把该行数据拷贝到undo log中，作为旧记录，发现该行记录已经有undo log了，那么最新的旧数据作为链表的表头，插在该行记录的undo log最前面 修改该行age为30岁，并且修改隐藏字段的事务ID为当前事务2的ID, 那就是2，回滚指针指向刚刚拷贝到undo log的副本记录 事务提交，释放锁 Read View (读视图) 设计思路: 1. READ UNCOMMITTED 隔离级别的事务，由于可以读到未提交事务修改过的记录，所以直接读取记录 的最新版本就好了。 1. SERIALIZABLE 隔离级别的事务，InnoDB规定使用加锁的方式来访问记录。 1. READ COMMITTED 和 REPEATABLE READ 隔离级别的事务，都必须保证读到已经提交了的事务修改 过的记录。 这是ReadView要解决的主要问题。 ​ Read View就是事务进行快照读操作的时候生产的读视图(Read View)，在该事务执行的快照读的那一刻，会生成数据库系统当前的一个快照，记录并维护系统当前活跃事务的ID trx_ids，当前有哪些事务正在执行，且还没有提交，这些事务的 id 就会存在这里； up_limit_id，是指 m_ids 里最小的值； low_limit_id，是指下一个要生成的事务 id。下一个要生成的事务 id 肯定比现在所有事务的 id 都大； creator_trx_id：表示生成该ReadView的事务的事务id 只有在对表中的记录做改动时（执行INSERT、DELETE、UPDATE这些语句时）才会为事务分配事务id，否则在一个只读事务中的事务id值都默认为0。 ReadView的规则 如果被访问版本的trx_id属性值与ReadView中的 creator_trx_id 值相同，意味着当前事务在访问它自己修改过的记录，所以该版本可以被当前事务访问。(这里的trx_id为每一行数据的trx_id) 如果被访问版本的trx_id属性值小于ReadView中的 up_limit_id 值，表明生成该版本的事务在当前事务生成ReadView前已经提交，所以该版本可以被当前事务访问。 如果被访问版本的trx_id属性值大于或等于ReadView中的 low_limit_id 值，表明生成该版本的事务在当前事务生成ReadView后才开启，所以该版本不可以被当前事务访问。 如果被访问版本的trx_id属性值在ReadView的 up_limit_id 和 low_limit_id 之间，那就需要判 断一下trx_id属性值是不是在 trx_ids 列表中。 如果在，说明创建ReadView时生成该版本的事务还是活跃的，该版本不可以被访问。 如果不在，说明创建ReadView时生成该版本的事务已经被提交，该版本可以被访问 在RC隔离级别下，是每个快照读都会生成并获取最新的Read View； 在RR隔离级别下，则是同一个事务中的第一个快照读才会创建Read View, 之后的快照读获取的都是同一个Read View MVCC操作流程 首先获取事务自己的版本号，也就是事务 ID; 获取 ReadView; 查询得到的数据，然后与 ReadView 中的事务版本号进行比较; 如果不符合 ReadView 规则，就需要从 Undo Log 中获取历史快照; 最后返回符合规则的数据。 InnoDB解决幻读的流程 假设现在表 student 中只有一条数据，数据内容中，主键 id=1，隐藏的 trx_id=10，它的 undo log 如下图 所示。现在有事务A和事务B并发执行， 的事务id为 20 ， 的事务id为 30 。 事务 A 开始第一次查询数据，查询的 SQL 语句如下。 select*fromstudentwhereid\u003e=1 在开始查询时,会生成一个ReadView; 内容如下 trx_id=[20,30] up_limit_id=20 low_limit_id=31 creator_trx_id=2 ​ 此时表 student 中只有一条数据，且符合 where id\u003e=1 条件，因此会查询出来。然后根据 ReadView 机制，发现该行数据的trx_id=10，小于事务 A 的 ReadView 里 up_limit_id，这表示这条数据是事务 A 开 启之前，其他事务就已经提交了的数据，因此事务 A 可以读取到。 接着事务 B(trx_id=30)，往表 student 中新插入两条数据，并提交事务。 insertintostudent(id,name)values(2,'李四');insertintostudent(id,name)values(3,'王五'); 此时表student 中就有三条数据了，对应的 undo 如下图所示: 接着事务 A 开启第二次查询，根据可重复读隔离级别的规则，此时事务 A 并不会再重新生成 ReadView。此时表 student 中的 3 条数据都满足 where id\u003e=1 的条件，因此会先查出来。然后根据 ReadView 机制，判断每条数据是不是都可以被事务 A 看到。 首先 id=1 的这条数据，前面已经说过了，可以被事务 A 看到。 然后是 id=2 的数据，它的 trx_id=30，此时事务 A 发现，这个值处于 up_limit_id 和 low_limit_id 之 间，因此还需要再判断 30 是","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:4:6","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"Undo log ​ undo log 叫做回滚日志，用于记录数据被修改前的信息。他正好跟前面所说的重做日志所记录的相反，重做日志记录数据被修改后的信息。undo log主要记录的是数据的逻辑变化，为了在发生错误时回滚之前的操作，需要将之前的操作都记录下来，然后在发生错误时才可以回滚。 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:4:7","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"Redo log InnoDB修改数据的基本流程 ​ 当我们想要修改DB上某一行数据的时候，InnoDB是把数据从磁盘读取到内存的缓冲池上进行修改。数据在内存中被修改，与磁盘中相比就存在了差异，我们称这种有差异的数据为脏页。InnoDB对脏页的处理不是每次生成脏页就将脏页刷新回磁盘，这样会产生海量的IO操作，严重影响InnoDB的处理性能。 ​ InnoDB采用Write Ahead Log策略来防止宕机数据丢失，即事务提交时，先写重做日志，再修改内存数据页，这样就产生了脏页. Redo log 工作原理 ​ redo log在数据库重启恢复的时候被使用，因为其属于物理日志的特性，恢复速度远快于逻辑日志。而我们经常使用的binlog就属于典型的逻辑日志。 CheckPoint ​ 脏页刷新的规则叫checkpoint机制。所做的事就是把脏页给刷新回磁盘。所以，当DB重启恢复时，只需要恢复checkpoint之后的数据。这样就能大大缩短恢复时间 两种checkpoint： sharp checkpoint：在数据库关闭时，刷新所有的脏页到磁盘，这里有参数控制，默认是开启的 fuzzy checkpoint：刷新一部分脏页到磁盘中。 定时刷新: Master Thread以每秒或每十秒的速度从缓冲池的脏页列表中刷新一定比例的页回磁盘;这个过程是异步的，不会阻塞查询线程。 FLUSH_LRU_LIST Checkpoint: InnoDB要保证LRU列表中有100左右空闲页可使用 Async/Sync Flush Checkpoint: 指重做日志文件不可用时，需要强制将脏页列表中的一些页刷新回磁盘。这可以保证重做日志文件可循环使用 Dirty Page too much Checkpoint: 脏页数量太多时，InnoDB引擎会强制进行Checkpoint。目的还是为了保证缓冲池中有足够可用的空闲页 LSN(Log Sequence Number) ​ LSN实际上就是InnoDB使用的一个版本标记的计数，它是一个单调递增的值。数据页和redo log都有各自的LSN。我们可以根据数据页中的LSN值和redo log中LSN的值判断需要恢复的redo log的位置和大小。 redo Log 工作原理 ​ redo log就是存储了数据被修改后的值。当我们提交一个事务时，InnoDB会先去把要修改的数据写入日志，然后再去修改缓冲池里面的真正数据页。 ​ redo log本身也由两部分所构成即重做日志缓冲(redo log buffer)和重做日志文件(redo log file)。这样的设计同样也是为了调和内存与磁盘的速度差异。InnoDB写入磁盘的策略可以通过innodb_flush_log_at_trx_commit这个参数来控制。​ 当该值为1时，当然是最安全的，但是数据库性能会受一定影响。为0时性能较好，但是可能会丢失掉master thread还没刷新进磁盘部分的数据。 master thread :后台运行的主线程; 它做的主要工作包括但不限于：刷新日志缓冲，合并插入缓冲，刷新脏页等 innodb_flush_log_at_trx_commit设为非0的值，并不是说不会在master thread中刷新日志了。master thread刷新日志是在不断进行的，所以redo log写入磁盘是在持续的写入。 宕机恢复 ​ DB宕机后重启，InnoDB会首先去查看数据页中的LSN的数值。这个值代表数据页被刷新回磁盘的LSN的大小。然后再去查看redo log的LSN的大小。如果数据页中的LSN值大说明数据页领先于redo log刷新，不需要进行恢复。反之需要从redo log中恢复数据。 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:4:8","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"主从复制 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:5:0","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"主从复制的作用 实现服务器负载均衡和读写分离,降低服务器工作负荷 通过复制实现数据的异地备份 提高数据库系统的高可用性, 主备切换不断网 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:5:1","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"主从复制原理 Master 数据库只要发生变化，立马记录到Binary log 日志文件中 Slave数据库启动一个I/O thread连接Master数据库，请求Master变化的二进制日志 Slave I/O获取到的二进制日志，保存到自己的Relay log 日志文件中。 Slave 有一个 SQL thread定时检查Realy log是否变化，变化那么就更新数据 三个线程: 主从同步的原理就是基于 binlog 进行数据同步的。在主从复制过程中，会基于 3 个线程 来操 作，一个主库线程，两个从库线程。 二进制日志转储线程 (Binlog dump thread)是一个主库线程。当从库线程连接的时候， 主库可以将二进制日志发送给从库，当主库读取事件(Event)的时候，会在 Binlog 上 加锁 ，读取完成之后，再将锁释放掉。 从库 I/O 线程会连接到主库，向主库发送请求更新Binlog。这时从库的I/O线程就可以读取到主库的二进制日志转储线程发送的 Binlog 更新部分，并且拷贝到本地的中继日志 (Relay log)。 从库 SQL 线程 会读取从库中的中继日志，并且执行日志中的事件，将从库中的数据与主库保持同步。 MySQL复制是异步的且串行化 的，而且重启后从接入点 开始复制。 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:5:2","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"同步的一致性问题 主从延迟问题 主从同步的内容是二进制日志，它是一个文件，在进行 网络传输 的过程中就一定会存在主从延迟(比如 500ms)，这样就可能造成用户在从库上读取的数据不是最新的数据，也就是主从同步中的 数据不一致性 问题。 主从延迟问题原因 ​ 主备延迟最直接的表现是，从库消费中继日志(relay log)的速度，比主库生产binlog的速度要慢。 从库的机器性能比主库要差 从库的压力大 大事务的执行 主从延迟问题解决: 降低多线程大事务并发的概率，优化业务逻辑 优化SQL，避免慢SQL， 减少批量操作 ，建议写脚本以update-sleep这样的形式完成 提高从库机器配置,减少主库写binlog和从库读binlog的效率差 减少网络延迟(距离和端口带宽) 实时性要求的业务读强制走主库，从库只做灾备，备份。 如何解决一致性问题 ​ 一致性问题, 即主库已经更新了,但从库还没有同步, 从而没办法读取到最新的数据,与主数据库不一致. 异步复制:主库在执行完客户端提交的事务后会立即将结果返给给客户端，并不关心从库是否已经接收并处理 半同步复制: 等主从同步完成之后，主库上的写请求再返回![截屏2022-08-31 下午2.45.57](https://raw.githubusercontent.com/NoobMidC/pics/main/截屏2022-08-31 下午2.45.57.png) 组复制 ​ 多个节点共同组成一个复制组，在 执行读写(RW)事务 的时候，需要通过一致性协议层的同意，也就是读写事务想要进行提交，必须要经过组里“大多数人”(对应 Node 节 点)的同意，大多数指的是同意的节点数量需要大于 (N/2+1)，这样才可以进行提交(Paxos 协议) 数据库中间件 缓存记录写key法 CUD操作: 将某个库上的某个key要发生写操作，记录在cache里，并设置“经验主从同步时间”的cache超时时间，例如500ms 修改数据库 R操作: 先到cache里查看，对应库的对应key有没有相关数据 如果cache hit，有相关数据，说明这个key上刚发生过写操作，此时需要将请求路由到主库读最新的数据 如果cache miss，说明这个key上近期没有发生过写操作，此时将请求路由到从库，继续读写分离 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:5:3","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"Binlog日志 Binlog 的录入格式 有三种格式，statement，row和 mixed。 statement 模式下，每一条会修改数据的 sql 都会记录在 binlog 中。不需要记录每一行的变化，减少了binlog日志量，节约了IO，提高性能。 row级别下，row level 的日志内容会非常清楚的记录下每一行数据修改的细节。 mixed，一种折中的方案，普通操作使用 statement 记录，当无法使用 statement 的时候使用 row。 写入机制 ​ 事务执行过程中，先把日志写到 binlog cache，事务提交的时候，再把 binlog cache 写到 binlog 文件中。一个事务的 binlog 是不能被拆开的，因此不论这个事务多大，也要确保一次性写入。这就涉及到了 binlog cache 的保存问题。 ​ 系统给 binlog cache 分配了一片内存，每个线程一个，参数 binlog_cache_size 用于控制单个线程内 binlog cache 所占内存的大小。如果超过了这个参数规定的大小，就要暂存到磁盘。每个线程有自己 binlog cache，但是共用同一份 binlog 文件。 ​ 线程将binlog日志write到page cache, 然后调用fsync(或者交给OS)持久化到操作系统;write 和 fsync 的时机，是由参数 sync_binlog 控制的： sync_binlog=0 的时候，表示每次提交事务都只 write，不 fsync sync_binlog=1 的时候，表示每次提交事务都会执行 fsync sync_binlog=N(N\u003e1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync。 Redo log和binlog对比 redo log是InnoDB引擎特有的；binlog是MySQL的Server层实现的，所有引擎都可以使用。 redo log是物理日志，记录的是“在某个数据页上做了什么修改”；binlog是逻辑日志，记录的 是这个语句的原始逻辑，比如“给ID=2这一行的c字段加1 ”。 redo log是循环写的，空间固定会用完；binlog是可以追加写入的。“追加写”是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。 两阶段提交 ​ 为了解决Redolog和binlog日志之间的逻辑一致问题，InnoDB存储引擎使用两阶段提交方案。原理很简单，将redo log的写入拆成了两个步骤prepare和commit，这就是两阶段提交。 先写入redo log时为 prepare阶段, 在提交事务前将binlog写入,然后将redo log设置为commit,这样事务便提交了 发生故障: 写入binlog时发生异常也不会有影响，因为MySQL根据redo log日志恢复数据时，发现redolog还处于prepare阶段，并且没有对应binlog日志，就会回滚该事务。 redo log设置commit阶段发生异常,并不会回滚事务，它会执行下图框住的逻辑，虽然redo log是处于prepare阶段，但是能通过事务id找到对应的binlog日志，所以MySQL认为是完整的，就会提交事务恢复数据。 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:5:4","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"三大范式 第一范式：字段(列)具有原子性,不可再分 第二范式：在第一范式的基础上，每行都有应该被唯一区分,唯一标识符为主键(都依赖于主键)。 第三范式：在第二范式的基础上，非主键列只依赖于主键，不依赖于其他非主键。(不间接依赖) 范式优缺点: 优点: 范式化, 重复冗余数据少,更新快,修改少. 缺点: 因为一个表不存在冗余重复数据，查询可能造成很多关联，效率变低，可能使一些索引策略无效，范式化将列存在不同表中，这些列若在同一个表中可以是一个索引。 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:6:0","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"什么是存储过程？有哪些优缺点？ 存储过程是一些预编译的 SQL 语句。 存储过程可以说是一个记录集，它是由一些 SQL 语句组成的代码块，这些 SQL 语句代码像一个方法一样实现一些功能（对单表或多表的增删改查），然后再给这个代码块取一个名字，在用到这个功能的时候调用他就行了。 存储过程是一个预编译的代码块，执行效率比较高,一个存储过程替代大量 SQL 语句 ，可以降低网络通信量，提高通信速率,可以一定程度上确保数据安全 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:7:0","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"mysql表的拆分 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:8:0","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"垂直拆分 ​ 垂直拆分的意思，就是把一个有很多字段的表给拆分成多个表，或者是多个库上去。每个库表的结构都不一样，每个库表都包含部分字段。一般来说，会将较少的访问频率很高的字段放到一个表里去，然后将较多的访问频率很低的字段放到另外一个表里去。因为数据库是有缓存的，你访问频率高的行字段越少，就可以在缓存里缓存更多的行，性能就越好。这个一般在表层面做的较多一些。 优点: 1 .可以使得行数据变小，在查询时减少读取的 Block 数，减少 I/O 次数。2. 可以简化表的结构，易于维 护。 缺点: 1. 主键会出现冗余，需要管理冗余列，查询所有数据需要 join 操作，可以通过在应用层进行 Join 来 解决。此外，垂直分区会让事务变得更加复杂。 适用场景: 一个表中某些列常用，另外一些列不常用 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:8:1","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"水平拆分 ​ 水平拆分的意思，就是把一个表的数据给弄到多个库的多个表里去，但是每个库的表结构都一样，只不过每个库表放的数据是不同的，所有库表的数据加起来就是全部数据。水平拆分的意义，就是将数据均匀放更多的库里，然后用多个库来抗更高的并发，还有就是用多个库的存储容量来进行扩容。 优点: 充分利用多个机器的性能,提高并发 适应场景: 表中的数据本身就有独立性，例如表中分表记录各个地区的数据或者不同时期的数据，特别是有些数据常用，有些不常用。 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:8:2","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"拆分的问题 事务支持: 分库分表后，就成了分布式事务了。如果依赖数据库本身的分布式事务管理功能去执行事 务，将付出高昂的性能代 价; 如果由应用程序去协助控制，形成程序逻辑上的事务，又会 造成编程方面的负担。 跨库 join: 只要是进行切分，跨节点 Join 的问题是不可避免的。但是良好的设计和切分却可以减少此类情况的发生。 ​ 解决这 一问题的普遍做法是分两次查询实现。在第一次查询的结果集中找出关联数据的 id, 根据这些 id 发起第二次请求得 到关联数据。 ID问题: 一旦数据库被切分到多个物理结点上，我们将不能再依赖数据库自身的主键生成机制。一 方面，某个分区数据库自 生成的 ID 无法保证在全局上是唯一的;另一方面，应用程序在 插入数据之前需要先获得 ID,以便进行 SQL 路由; ​ UUID 使用 UUID 作主键是最简单的方案，但是缺点也是非常明显的。由于 UUID 非常的 ⻓，除占用大量存储空间 外，最主要的问题是在索引上，在建立索引和基于索引进行查询 时都存在性能问题。 ​ Twitter 的分布式自增 ID 算 法 Snowflake 在分布式系统中，需要生 成全局 UID 的场合还是比较多的，twitter 的 snowflake 解决了这种需 求，实现也还是很简单的，除去配置信息，核心代码就是毫秒级时间 41 位机器 ID10位+毫秒内序列 12 位。 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:8:3","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"自增主键的理解 ​ Innodb引擎的自增值, 原本是保存在内存中 ,8.0以后则持久化, 重启后表的自增值能恢复到mysql重启前的值. mysql5.7 及以前,自增值保存内存,没有持久化.每次重启后,第一次打开表,都会去找自增值的最大值. MySQL 8.0版本，将自增值的变更记录在了redo log中，重启的时候依靠redo log恢复重启之前的值。 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:9:0","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"自增主键不连续的情况 在MySQL 5.7及之前的版本，自增值保存在内存里，并没有持久化. 事务回滚（自增值不能回退，因为并发插入数据时，回退自增ID可能造成主键冲突） 唯一键冲突（由于表的自增值已变，但是主键发生冲突没插进去，下一次插入主键=现在变了的子增值+1，所以不连续） ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:9:1","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"为什么用自增ID 主键页就会近乎于顺序的记录填满，提升了页面的最大填充率，不会有页的浪费 新插入的行一定会在原有的最大数据行下一行，mysql定位和寻址很快，不会为计算新行的位置而做出额外的消耗。 减少了页分裂和碎片的产生 如果使用uuid,会导致大量的随机IO+页分裂导致移动大量的数据+数据会有碎片 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:9:2","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"WAL(Write Ahead Log)预写日志 原子性: 事务的原子性是通过Redo Log和Undo Log保证的。 1. 每一个写事务，都会修改BufferPool，从而产生相应的Redo/Undo日志，这些日志信息会被记录到日志文件中. 2. 任何 Buffer Pool中的页被刷到磁盘之前，数据都会先写入到日志文件中 3. 如果Buffer Pool 中的数据提交(commit)，此时数据库挂了，那在数据库再次启动之后，可以通Redo日志将其恢复出来，以保证脏页写的数据不会丢失。 4. 如果数据没有提交（没有commit)，此时数据库挂了,就需要通过Undo来回滚了。 持久性: 通过Redo Log 和WAL实现的 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:10:0","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"大表怎么优化 ​ 当 MySQL 单表记录数过大时，数据库的 CRUD 性能会明显下降，一些常见的优化措施如下: 限定数据的范围: 务必禁止不带任何限制数据范围条件的查询语句。比如:我们当用户在查询订单历史的时候，我们可以控制在一个月的范围内 读/写分离: 经典的数据库拆分方案，主库负责写，从库负责读; 缓存: 使用 MySQL 的缓存，另外对重量级、更新少的数据可以考虑使用应用级别的缓存 还有就是通过分库分表的方式进行优化。主要有垂直分区、垂直分表、水平分区、水平分表、垂直分区 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:11:0","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"MyISAM 表类型将在哪里存储，并且还提供其存储格式? 每个 MyISAM 表格以三种格式存储在磁盘上: 表结构(元数据)由“.frm”文件存储 数据文件具有“.MYD”(MYData)扩展名 索引文件具有“.MYI”(MYIndex)扩展名 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:12:0","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"百万级别或以上的数据如何删除 ​ 由于索引需要额外的维护成本，因为索引文件是单独存在的文件,所以当我们对数据的增加,修改,删除,都 会产生额外的对索引文件的操作,这些操作需要消耗额外的 IO,会降低增/改/删的执行效率。 可以先删除索引(此时大概耗时三分多钟) 然后删除其中无用数据(此过程需要不到两分钟) 删除完成后重新创建索引(此时数据较少了)创建索引也非常快，约十分钟左右。 与之前的直接删除绝对是要快速很多，更别说万一删除中断,一切删除会回滚。那更是坑了 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:13:0","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"什么是临时表，何时删除临时表? ​ MySQL在执行 SQL语句的过程中通常会临时创建一些存储中间结果集的表，临时表只对当前连接可见，在连接关闭时，临时表会被删除并释放所有表空间。 ​ 临时表分为两种:一种是内存临时表，一种是磁盘临时表，什么区别呢?内存临时表使用的是 MEMORY存储引擎，而 临时表采用的是 MylSAM 存储引擎。 ​ MySQL会在下面这几种情况产生临时表: 使用 UNION查询:UNION有两种，一种是 UNION，一种是 UNION ALL，它们都用于联合查询;区别是使用 UNION会去掉两个表中的重复数据，相当于对结果集做了一下去重(distinct)。使用 UNIONALL，则不会排重，返回所有的行。使用 UNION查询会产生临时表。 使用UNION查询中的视图。意味这要 MySQL要先创建好一个临时表，然后将结果放到临时表中去，然后再使用这个临 时表进行相应的查询。 ORDER BY和 GROUPBY的子句不一样时也会产生临时表。 DISTINCT 查询并且加上 ORDER BY时; FROM中的子查询; EXPLAIN 查看执行计划结果的 Extra 列中，如果使用 Using Temporary 就表示会用到临时表。 ","date":"2022-08-28","objectID":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/:14:0","tags":[],"title":"Mysql八股文","uri":"/mysql%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"计算机网络 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:0:0","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"为什么要对网络协议分层？ ​ 网络协议是计算机在通信过程中要遵循的一些约定好的规则。 ​ 网络分层的原因： 易于实现和维护，因为各层之间是独立的，层与层之间不会收到影响。 有利于标准化的制定 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:1:0","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"协议模型 OSI七层协议模型包括: 应用-表示-会话-传输-网络-数据链路-物理层 五层协议模型包括: 应用-传输-网络-数据链路-物理层 物理层 ​ 主要解决两台物理机之间的通信，通过二进制比特流的传输来实现，二进制数据表现为电流电压上的强弱，到达目的地再转化为二进制机器码。网卡、集线器工作在这一层。 数据链路层 ​ 在不可靠的物理介质上提供可靠的传输，接收来自物理层的位流形式的数据，并封装成帧，传送到上一层;同样，也将来自上层的数据帧，拆装为位流形式的数据转发到物理层。这一层在物理层提供的比特流的基础上，通过差错控制、流量控制方法，使有差错的物理线路变为无差错的数据链路。提供物理地址寻址功能。交换机工作在这一层。 网络层 ​ 将网络地址翻译成对应的物理地址，并决定如何将数据从发送方路由到接收方，通过路由选择算法为分组通过通信子网选择最佳路径。路由器工作在这一层。常见的协议有IP协议，ARP协议、ICMP协议。 传输层 ​ 传输层提供了进程间的逻辑通信，传输层向高层用户屏蔽了下面网络层的核心细节，使应用程序看起来像是在两个传输层实体之间有一条端到端的逻辑通信信道。主要协议为TCP、UDP协议 会话层 建立会话:身份验证，权限鉴定等; 保持会话:对该会话进行维护，在会话维持期间两者可以随时使用这条会话传输数据; 断开会话:当应用程序或应用层规定的超时时间到期后，OSI会话层才会释放这条会话。 表示层 ​ 对数据格式进行编译，对收到或发出的数据根据应用层的特征进行处理，如处理为文字、图片、音频、视频、文档等，还可以对压缩文件进行解压缩、对加密文件进行解密等。 应用层 ​ 应用层的任务是通过应用进程之间的交互来完成特定的网络作用，常见的应用层协议有DNS，HTTP、FTP协议等。 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:2:0","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"[应用层]HTTP协议 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:3:0","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"HTTP 状态码 类别 描述 1xx 信息性状态码 2xx 成功状态码 3xx 重定向状态码 4xx 客户端错误状态码 5xx 服务端错误状态码 1xx 100 Continue：表示正常，客户端可以继续发送请求 101 Switching Protocols：切换协议，服务器根据客户端的请求切换协议。 2xx 200 OK：请求成功 201 Created：已创建，表示成功请求并创建了新的资源 202 Accepted：已接受，已接受请求，但未处理完成。 204 No Content：无内容，服务器成功处理，但未返回内容。 205 Reset Content：重置内容，服务器处理成功，客户端应重置文档视图。 206 Partial Content：表示客户端进行了范围请求，响应报文应包含Content-Range指定范围的实体内容 3xx 301 Moved Permanently：永久性重定向 302 Found：临时重定向 303 See Other：和301功能类似，但要求客户端采用get方法获取资源 304 Not Modified：所请求的资源未修改，服务器返回此状态码时，不会返回任何资源。 305 Use Proxy：所请求的资源必须通过代理访问 307 Temporary Redirect： 临时重定向，与302类似，要求使用get请求重定向。 4xx 400 Bad Request：客户端请求的语法错误，服务器无法理解。 401 Unauthorized：表示发送的请求需要有认证信息。 403 Forbidden：服务器理解用户的请求，但是拒绝执行该请求 404 Not Found：服务器无法根据客户端的请求找到资源。 405 Method Not Allowed：客户端请求中的方法被禁止 406 Not Acceptable：服务器无法根据客户端请求的内容特性完成请求 408 Request Time-out：服务器等待客户端发送的请求时间过长，超时 5xx 500 Internal Server Error：服务器内部错误，无法完成请求 501 Not Implemented：服务器不支持请求的功能，无法完成请求 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:3:1","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"HTTP版本 HTTP1.0 ​ HTTP1.0 使用的是非持久连接，主要缺点是客户端必须为每一个待请求的对象建立并维护一个新的连接，即每请求一个文档就要有两倍RTT 的开销。因为同一个页面可能存在多个对象，所以非持久连接可能使一个页面的下载变得十分缓慢，而且这种 短连接增加了网络传输的负担。 RTT(Round Trip Time)：一个连接的往返时间，即数据发送时刻到接收到确认的时刻的差值； HTTP1.1 支持长连接。 在HTTP1.0的基础上引入了更多的缓存控制策略。 引入了请求范围设置，优化了带宽。 在错误通知管理中新增了错误状态响应码。 增加了Host头处理，可以传递主机名（hostname） http keep-alive Connection: Keep-Alive Http1.0需要显示添加 http1.1以及之后的http连接都是默认有此选项的。 优势 减少了tcp连接的数量 运行请求和应答的流水线(数据流) 报告错误无需关闭tcp连接 劣势 多于不断被不同客户端请求的资源 可能会占用不必要的资源 HTTP1.X优化（SPDY） ​ SPDY 并不是新的一种协议，而是在 HTTP 之前做了一层会话层。为了达到减少页面加载时间的目标，SPDY 引入了一个新的二进制分帧数据层，以实现优先次序、最小化及消除不必要的网络延迟，目的是更有效地利用底层 TCP 连接。 多路复用，为多路复用设立了请求优先级。 对header部分进行了压缩。 引入了HTTPS加密传输。 客户端可以在缓存中取到之前请求的内容。 HTTP2.0（SPDY的升级版） HTTP2.0支持明文传输，而HTTP 1.X强制使用SSL/TLS加密传输。 和HTTP 1.x使用的header压缩方法不同。 HTTP2.0 基于二进制格式进行解析，而HTTP 1.x基于文本格式进行解析。增加二进程的传输方式，相对于文本传输更加安全. 多路复用，HTTP1.1是多个请求串行化单线程处理，HTTP 2.0是并行执行，一个请求超时并不会影响其他请求。 请求划分优先级 HTTP 3.0 (QUIC) QUIC (Quick UDP Internet Connections), 快速 UDP 互联网连接。QUIC是基于UDP协议的。两个主要特性： 线头阻塞(HOL)问题的解决更为彻底： ​ 基于TCP的HTTP/2，尽管从逻辑上来说，不同的流之间相互独立，不会相互影响，但在实际传输方面，数据还是要一帧一帧的发送和接收，一旦某一个流的数据有丢包，则同样会阻塞在它之后传输的流数据传输。而基于UDP的QUIC协议则可以更为彻底地解决这样的问题，让不同的流之间真正的实现相互独立传输，互不干扰。 切换网络时的连接保持 ​ 当前移动端的应用环境，用户的网络可能会经常切换，比如从办公室或家里出门，WiFi断开，网络切换为3G或4G。基于TCP的协议，由于切换网络之后，IP会改变，因而之前的连接不可能继续保持。而基于UDP的QUIC协议，则可以内建与TCP中不同的连接标识方法，从而在网络完成切换之后，恢复之前与服务器的连接。 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:3:2","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"HTTP方法 方法 作用 GET 获取资源 POST 传输实体主体 PUT 上传文件 DELETE 删除文件 HEAD 和GET方法类似，但只返回报文首部，不返回报文实体主体部分 PATCH 对资源进行部分修改 OPTIONS 查询指定的URL支持的方法 CONNECT 要求用隧道协议连接代理 TRACE 服务器会将通信路径返回给客户端 为了方便记忆，可以将PUT、DELETE、POST、GET理解为客户端对服务端的增删改查。 PUT：上传文件，向服务器添加数据，可以看作增 DELETE：删除文件 POST：传输数据，向服务器提交数据，对服务器数据进行更新。 GET：获取资源，查询服务器资源 GET和POST的区别 作用GET用于获取资源，POST用于传输实体主体 参数位置GET的参数放在URL中，POST的参数存储在实体主体中，并且GET方法提交的请求的URL中的数据做多是2048字节，POST请求没有大小限制。 安全性GET方法因为参数放在URL中，安全性相对于POST较差一些 幂等性GET方法是具有幂等性的，而POST方法不具有幂等性。这里幂等性指客户端连续发出多次请求，收到的结果都是一样的. ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:3:3","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"HTTP和HTTPS的区别 HTTP HTTPS 端口 80 443 安全性 无加密 有加密机制、安全性较高 资源消耗 较少 由于加密处理，资源消耗更多 是否需要证书 不需要 需要 协议 运行在TCP协议之上 运行在SSL协议之上，SSL运行在TCP协议之上 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:3:4","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"HTTPS的加密过程 HTTPS使用的是对称加密和非对称加密的混合加密算法。具体做法就是使用非对称加密来传输对称密钥来保证安全性，使用对称加密来保证通信的效率。 简化的工作流程：服务端生成一对非对称密钥，将公钥发给客户端。客户端生成对称密钥，用服务端发来的公钥进行加密，加密后发给服务端。服务端收到后用私钥进行解密，得到客户端发送的对称密钥。通信双方就可以通过对称密钥进行高效地通信了。 HTTPS的详细加密过程： 客户端向服务端发起第一次握手请求，告诉服务端客户端所支持的SSL的指定版本、加密算法及密钥长度等信息。 服务端将自己的公钥发给数字证书认证机构，数字证书认证机构利用自己的私钥对服务器的公钥进行数字签名，并给服务器颁发公钥证书。 服务端将证书发给客服端。 客服端利用数字认证机构的公钥，向数字证书认证机构验证公钥证书上的数字签名，确认服务器公开密钥的真实性。 客服端使用服务端的公钥加密自己生成的对称密钥，发给服务端。 服务端收到后利用私钥解密信息，获得客户端发来的对称密钥。 通信双方可用对称密钥来加密解密信息。 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:3:5","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"[应用层]DNS协议 DNS : 域名系统；DNS系统采用的是分布式的层次数据数据库模式，还有缓存的机制。 ​ 工作流程 主机向本地域名服务器的查询一般是采用递归查询，而本地域名服务器向根域名的查询一般是采用迭代查询 递归查询，是服务器向上级服务器发送请求报文，返回给你ip地址 迭代查询，是服务器通知你，需要向哪个上级服务器发请求报文，请求ip. 实例: 在浏览器中输入百度域名，操作系统会先检查自己本地的hosts文件是否有这个域名的映射关系，如果有，就先调用这个IP地址映射，完成域名解析。 如果hosts文件中没有，则查询本地DNS解析器缓存，如果有，则完成地址解析。 如果本地DNS解析器缓存中没有，则去查找本地DNS服务器，如果查到，完成解析。 如果没有，则本地服务器会向根域名服务器发起查询请求。根域名服务器会告诉本地域名服务器去查询哪个顶级域名服务器。 本地域名服务器向顶级域名服务器发起查询请求，顶级域名服务器会告诉本地域名服务器去查找哪个权限域名服务器。 本地域名服务器向权限域名服务器发起查询请求，权限域名服务器告诉本地域名服务器百度所对应的IP地址。 本地域名服务器告诉主机百度所对应的IP地址。 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:4:0","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"[传输层]TCP/UDP协议详解 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:5:0","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"TCP 数据结构 ​ TCP头部: 前20个字节是固定的，后面有4n个字节是根据需而增加的选项，所以TCP首部最小长度为20字节。 序号：seq，占32位，用来标识从发送端到接收端发送的字节流。(一般来说在0 - 2^32-1之间) 确认号：ack，占32位，只有ACK标志位为1时，确认序号字段才有效，ack=seq+1。 标志位： SYN：发起一个新连接。 FIN：释放一个连接。 ACK：确认序号有效。 TCP可靠传输 主要有校验和、序列号、超时重传、流量控制及拥塞避免等几种方法。 校验和: 在发送端和接收端分别计算数据的校验和，如果两者不一致，则说明数据在传输过程中出现了差错，TCP将丢弃和不确认此报文段。 序列号: TCP会对每一个发送的字节进行编号，接收方接到数据后，会对发送方发送确认应答(ACK报文)，并且这个ACK报文中带有相应的确认编号，告诉发送方，下一次发送的数据从编号多少开始发。如果发送方发送相同的数据，接收端也可以通过序列号判断出，直接将数据丢弃. 超时重传: 在上面说了序列号的作用，但如果发送方在发送数据后一段时间内（可以设置重传计时器规定这段时间）没有收到确认序号ACK，那么发送方就会重新发送数据。 这里发送方没有收到ACK可以分两种情况： 如果是发送方发送的数据包丢失了，接收方收到发送方重新发送的数据包(序列号大于了丢失的数据的序列号)后会马上重新给发送方发送(原丢失数据的)ACK； 如果是接收方之前接收到了发送方发送的数据包，而返回给发送方的ACK丢失了，这种情况，发送方重传后，接收方会直接丢弃发送方重传的数据包，然后再次发送ACK响应报文。如果数据被重发之后还是没有收到接收方的确认应答，则进行再次发送。此时，等待确认应答的时间将会以2倍、4倍的指数函数延长，直到最后关闭连接。 流量控制: 如果发送端发送的数据太快，接收端来不及接收就会出现丢包问题。 ​ 为了解决这个问题，TCP协议利用了滑动窗口进行了流量控制。在TCP首部有一个16位字段大小的窗口，窗口的大小就是接收端接收数据缓冲区的剩余大小。接收端会在收到数据包后发送ACK报文时，将自己的窗口大小填入ACK中，发送方会根据ACK报文中的窗口大小进而控制发送速度。如果窗口大小为零，发送方会停止发送数据。 拥塞控制: 如果网络出现拥塞，则会产生丢包等问题，这时发送方会将丢失的数据包继续重传，网络拥塞会更加严重，所以在网络出现拥塞时应注意控制发送方的发送数据，降低整个网络的拥塞程度。 拥塞控制主要有四部分组成：慢开始、拥塞避免、快重传、快恢复 （这里的发送方会维护一个拥塞窗口的状态变量，它和流量控制的滑动窗口是不一样的，滑动窗口是根据接收方数据缓冲区大小确定的，而拥塞窗口是根据网络的拥塞情况动态确定的，一般来说发送方真实的发送窗口为滑动窗口和拥塞窗口中的最小值） 慢开始: 为了避免一开始发送大量的数据而产生网络阻塞，会先初始化cwnd为1，当收到ACK后到下一个传输轮次，cwnd为2，以此类推成指数形式增长。 拥塞避免: 因为cwnd的数量在慢开始是指数增长的，为了防止cwnd数量过大而导致网络阻塞，会设置一个慢开始的门限值ssthresh，当cwnd\u003e=ssthresh时，进入到拥塞避免阶段，cwnd每个传输轮次加1。但网络出现超时，会将门限值ssthresh变为出现超时cwnd数值的一半，cwnd重新设置为1，如上图，在第12轮出现超时后，cwnd变为1，ssthresh变为12。 快重传：在网络中如果出现超时或者阻塞，则按慢开始和拥塞避免算法进行调整。但如果只是丢失某一个报文段，如下图，则使用快重传算法。 但是根据快重传算法，要求在这种情况下，需要快速向发送端发送M2的确认报文，在发送方收到三个M2的确认报文后，无需等待重传计时器所设置的时间，可直接进行M3的重传，这就是快重传。 快恢复: 当发送收到三个重复的ACK，会进行快重传和快恢复。快恢复是指将ssthresh设置为发生快重传时的cwnd数量的一半，而cwnd不是设置为1而是设置为为门限值ssthresh，并开始拥塞避免阶段。 TCP三次握手 发送端状态：CLOSED、SYN-SENT、ESTABLISHED 接收端状态：LISTEN、SYN-RCVD、ESTABLISHED 对于客户端而言,第二次握手就已经确定了建立链接,因此第三次握手实际上也算是数据传输的一次, 所以第一个数据包序列号为x+1 TCP连接队列 半连接队列: 服务端收到客户端发起的 SYN 请求后，内核会把该连接存储到半连接队列（SYN队列），并向客户端响应 SYN+ACK. 全连接队列: 服务端收到第三次握手的ACK后，内核会把连接从半连接队列移除，然后创建新的完全的连接，并将其添加到accept队列，等待进程调用accept 函数时把连接取出来。 为什么握手需要三次? 假设建立TCP连接仅需要两次握手，那么如果第二次握手时，服务端返回给客户端的确认报文丢失了，客户端这边认为服务端没有和他建立连接，而服务端却以为已经和客户端建立了连接，并且可能服务端已经开始向客户端发送数据，但客户端并不会接收这些数据，浪费了资源。如果是三次握手，不会出现双方连接还未完全建立成功就开始发送数据的情况。 如果服务端接收到了一个早已失效的来自客户端的连接请求报文，会向客户端发送确认报文同意建立TCP连接。但因为客户端并不需要向服务端发送数据，所以此次TCP连接没有意义并且浪费了资源。 如果是一次握手,则退化成了UDP SYN洪泛攻击，以及解决策略是什么? ​ 因为服务器端的资源分配是在二次握手时分配的，而客户端的资源是在完成三次握手时分配的，所以服务器容易受到SYN洪泛攻击。 洪泛攻击: SYN攻击就是Client在短时间内伪造大量不存在的IP地址，并向Server不断地发送SYN包，Server则回复确认包，并等待Client确认，由于源地址不存在，因此Server需要不断重发直至超时，这些伪造的SYN包将长时间占用半连接队列，导致正常的SYN请求因为队列满而被丢弃，从而引起网络拥塞甚至系统资源被占用完而瘫痪。SYN 攻击是一种典型的 DoS/DDoS 攻击 查看检测 SYN 攻击非常的方便，当你在服务器上看到大量的半连接状态时，特别是源IP地址是随机的，基本上可以断定这是一次SYN攻击。 netstat -n -p TCP | grep SYN_RECV 常见的解决办法: 缩短超时（SYN Timeout）时间 增加最大半连接数: 可以保存更多的半连接数,防止丢弃新连接 增加过滤网关防护 SYN cookies技术: 可以在不使用SYN半连接队列的情况下成功建立连接; ​ 原理是，在TCP服务器接收到TCP SYN包并返回TCP SYN + ACK包时，不分配一个专门的数据区，而是根据这个SYN包计算出一个cookie值。这个cookie作为将要返回的SYN ACK包的初始序列号。当客户端返回一个ACK包时，根据包头信息计算cookie，与返回的确认序列号(初始序列号 + 1)进行对比，如果相同，则是一个正常连接，然后，分配资源，建立连接。 TCP四次挥手 客户端状态：ESTABLISHED、FIN-WAIT-1、FIN-WAIT-2、TIME-WAIT、CLOSED 服务器状态：ESTABLISHED、CLOSE-WAIT、LAST-ACK、CLOSED 为什么要time_wait状态, 以及等待2MSL的时间? ​ MSL(Maximum Segment LifeTime)是报文最大生成时间，它是任何报文在网络上存在的最长时间，超过这个时间的报文将被丢弃。可以从两方面考虑： 客户端发送第四次挥手中的报文后，再经过2MSL，可使本次TCP连接中的所有报文全部消失，不会出现在下一个TCP连接中。 考虑丢包问题，如果第四挥手发送的报文在传输过程中丢失了，那么服务端没收到确认ack报文就会重发第三次挥手的报文。如果客户端发送完第四次挥手的确认报文后直接关闭，而这次报文又恰好丢失，则会造成服务端无法正常关闭。 TIME_WAIT的作用 保证客户端发送的最后一个ack报文到达服务器 保证本次连接的报文在网络里消失 time-wait定为2msl是为了保证服务端请求重传的报文到达 tcp_tw_reuse、tcp_tw_recycle、tcp_timestamp可用于优化time_wait状态 TIME_WAIT和CLOSE_WAIT的区别在哪? CLOSE_WAIT是被动关闭形成的，当客户端发送FIN报文，服务端返回ACK报文后进入CLOSE_WAIT。 TIME__WAIT_是主动关闭形成的，当第四次挥手完成后，客户端进入TIME_WAIT状态 TCP中的timewait状态过多会怎样? 占用过多的系统资源,占用服务器端口,导致无法使用, 建立链接失败 解决timewait状态过多的方法 : 允许timewait状态的端口被重用 减小timewait的时长 客户端头部设置keep-alive 出现了大量的CLOSE_WAIT状态怎么解决? ​ 大量 CLOSE_WAIT 表示程序出现了问题，对方的 socket 已经关闭连接，而我方忙于读或写没有及时关闭连接，需 要检查代码，特别是释放资源的代码，或者是处理请求的线程配置。 为什么挥手需要四次? ​ 由于TCP的**半关闭(half-close)**造成的。半关闭是指：TCP提供了连接的一方在结束它的发送后还能接受来自另一端数据的能力。通俗来说，就是不能发送数据，但是还可以接受数据。 ​ 当服务端发送完数据后还需","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:5:1","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"UDP 数据结构 UDP的首部只有8个字节，源端口号、目的端口号、长度和校验和各两个字节。TCP和UDP对比 是否面向连接 可靠性 传输形式 传输效率 资源消耗 应用场景 首部字节 TCP 是 可靠 字节流 慢 多 文件/邮件传输 20-60 UDP 否 不可靠 数据报文段 快 少 语音/视频 8 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:5:2","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"[网络层]ARP协议 ​ 主要作用是实现从IP地址转换为MAC地址。 ​ 网络层实现的是主机之间的通信，而链路层实现的是链路之间的通信，所以从下图可以看出，在数据传输过程中，IP数据报的源地址(IP1)和目的地址(IP2)是一直不变的，而MAC地址(硬件地址)却一直随着链路的改变而改变。ARP的工作流程: 在局域网内，主机A要向主机B发送IP数据报时，首先会在主机A的ARP缓存表中查找是否有IP地址及其对应的MAC地址，如果有，则将MAC地址写入到MAC帧的首部，并通过局域网将该MAC帧发送到MAC地址所在的主机B。 如果主机A的ARP缓存表中没有主机B的IP地址及所对应的MAC地址，主机A会在局域网内广播发送一个ARP请求分组。局域网内的所有主机都会收到这个ARP请求分组。 主机B在看到主机A发送的ARP请求分组中有自己的IP地址，会向主机A以单播的方式发送一个带有自己MAC地址的响应分组。 主机A收到主机B的ARP响应分组后，会在ARP缓存表中写入主机B的IP地址及其IP地址对应的MAC地址。 如果主机A和主机B不在同一个局域网内，即使知道主机B的MAC地址也是不能直接通信的，必须通过路由器转发到主机B的局域网才可以通过主机B的MAC地址找到主机B。并且主机A和主机B已经可以通信的情况下，主机A的ARP缓存表中存的并不是主机B的IP地址及主机B的MAC地址，而是主机B的IP地址及该通信链路上的下一跳路由器的MAC地址。这就是上图中的源IP地址和目的IP地址一直不变，而MAC地址却随着链路的不同而改变。 如果主机A和主机B不在同一个局域网，参考上图中的主机H1和主机H2，这时主机H1需要先广播找到路由器R1的MAC地址，再由R1广播找到路由器R2的MAC地址，最后R2广播找到主机H2的MAC地址，建立起通信链路。 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:6:0","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"[网络层]IP协议 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:7:0","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"TCP分段和IP分片 分段分片的目的，都是为了能够传输上层交付的、数据量超过本层传输能力上限的数据，不得已才做的数据切分. ​ 最大传输单元(Maximum Transmission Unit)，即MTU，为数据链路层的最大载荷上限。 ​ 最大报文段长度(Maximum Segment Size)，即MSS，为TCP传输层的最大载荷上限(即应用层数据最大长度) MTU = MSS + TCP首部长度 + IP首部长度 分片发生在IP层，分段发生在tcp层 IP层分片的原因是mtu的限制，tcp层分段的原因是mss的限制 udp不进行分段会在ip层进行分片 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:7:1","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"有了IP地址，为什么还要用MAC地址？ ​ 标识网络中的一台计算机，比较常用的就是IP地址和MAC地址，但计算机的IP地址可由用户自行更改，管理起来相对困难，而MAC地址不可更改，所以一般会把IP地址和MAC地址组合起来使用。 ​ 随着网络中的设备越来越多，整个路由过程越来越复杂，便出现了子网的概念。对于目的地址在其他子网的数据包，路由只需要将数据包送到那个子网即可，这个过程就是上面说的ARP协议。 ​ 如果只是用MAC地址,路由器则需要记住每个MAC地址在哪个子网，这需要路由器有极大的存储空间，是无法实现的。如果只是用IP地址,没办法标志多个子网中唯一的设备. ​ IP地址可以比作为地址，MAC地址为收件人，在一次通信过程中，两者是缺一不可的 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:7:2","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"[网络层]ICMP协议 ​ 网络层协议，主要是实现 IP 协议中未实现的部分功能，是一种网络层协议。该协议并不传输数据，只传输控制信息来辅助网络层通信. 应用: ping ping的作用是测试两个主机的连通性。工作过程: 向目的主机发送多个ICMP回送请求报文 根据目的主机返回的回送报文的时间和成功响应的次数估算出数据包往返时间及丢包率。 TraceRoute ​ 其主要用来跟踪一个分组从源点耗费最少 TTL 到达目的地的路径。TraceRoute 通过逐渐增大 TTL 值并重复发送数据报来实现其功能.(TTL, Time To live生存时间) 首先，TraceRoute 会发送一个 TTL 为 1 的 IP 数据报到目的地，当路径上的第一个路由器收到这个数据报时，它将 TTL 的值减 1，此时 TTL = 0，所以路由器会将这个数据报丢掉，并返回一个差错报告报文， 之后源主机会接着发送一个 TTL 为 2 的数据报，并重复此过程，直到数据报能够刚好到达目的主机。此时 TTL = 0，因此目的主机要向源主机发送 ICMP 终点不可达差错报告报文，之后源主机便知道了到达目的主机所经过的路由器 IP 地址以及到达每个路由器的往返时间。 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:8:0","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"JWT ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:9:0","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"Session、Cookie和Token的主要区别 Cookie ​ Cookie是保存在客户端一个小数据块，其中包含了用户信息。当客户端向服务端发起请求，服务端会像客户端浏览器发送一个Cookie，客户端会把Cookie存起来，当下次客户端再次请求服务端时，会携带上这个Cookie，服务端会通过这个Cookie来确定身份。 Session ​ Session是通过Cookie实现的，和Cookie不同的是，Session是存在服务端的。当客户端浏览器第一次访问服务器时，服务器会为浏览器创建一个sessionid，将sessionid放到Cookie中，存在客户端浏览器。比如浏览器访问的是购物网站，将一本《图解HTTP》放到了购物车，当浏览器再次访问服务器时，服务器会取出Cookie中的sessionid，并根据sessionid获取会话中的存储的信息，确认浏览器的身份是上次将《图解HTTP》放入到购物车那个用户。 Token ​ 客户端在浏览器第一次访问服务端时，服务端生成的一串字符串作为Token发给客户端浏览器，下次浏览器在访问服务端时携带token即可无需验证用户名和密码，省下来大量的资源开销。 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:9:1","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"客户端禁止 cookie 能实现 session 还能用吗 ​ 可以，Session的作用是在服务端来保持状态，通过sessionid来进行确认身份，但sessionid一般是通过Cookie来进行传递的。如果Cooike被禁用了，可以通过在URL中传递sessionid。 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:9:2","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"NAT ​ NAT（Network Address Translation），即网络地址转换，它是一种把内部私有网络地址翻译成公有网络 IP 地址的技术。 ​ 该技术不仅能解决 IP 地址不足的问题，而且还能隐藏和保护网络内部主机，从而避免来自外部网络的攻击。 NAT 的实现方式主要有三种： 静态转换：内部私有 IP 地址和公有 IP 地址是一对一的关系，并且不会发生改变。通过静态转换，可以实现外部网络对内部网络特定设备的访问，这种方式原理简单，但当某一共有 IP 地址被占用时，跟这个 IP 绑定的内部主机将无法访问 Internet。 动态转换：采用动态转换的方式时，私有 IP 地址每次转化成的公有 IP 地址是不唯一的。当私有 IP 地址被授权访问 Internet 时会被随机转换成一个合法的公有 IP 地址。当 ISP 通过的合法 IP 地址数量略少于网络内部计算机数量时，可以采用这种方式。 端口多路复用：该方式将外出数据包的源端口进行端口转换，通过端口多路复用的方式，实现内部网络所有主机共享一个合法的外部 IP 地址进行 Internet 访问，从而最大限度地节约 IP 地址资源。同时，该方案可以隐藏内部网络中的主机，从而有效避免来自 Internet 的攻击。 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:10:0","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"URI 和URL的区别 URI(Uniform Resource Identifier)：中文全称为统一资源标志符，主要作用是唯一标识一个资源。 URL(Uniform Resource Location)：中文全称为统一资源定位符，主要作用是提供资源的路径。 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:11:0","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"路由器和交换机的区别？ 所属网络模型的层级 功能 路由器 网络层 识别IP地址并根据IP地址转发数据包，维护数据表并基于数据表进行最佳路径选择 交换机 数据链库层 识别MAC地址并根据MAC地址转发数据帧 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:12:0","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"在浏览器中输⼊url地址到显示主页的过程 对输入到浏览器的url进行DNS解析，将域名转换为IP地址。 和目的服务器建立TCP连接 向目的服务器发送HTTP请求 服务器处理请求并返回HTTP报文 浏览器解析并渲染页面 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:13:0","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"一个主机可以建立多少连接 客户端 ​ 每一个ip可建立的TCP连接理论受限于ip_local_port_range参数，也受限于65535。但可以通过配置多ip的方式来加大自己的建立连接的能力。 服务器 ​ 每一个监听的端口虽然理论值很大，但这个数字没有实际意义。最大并发数取决你的内存大小，每一条静止状态的TCP连接大约需要吃3.3K的内存 ","date":"2022-08-28","objectID":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/:14:0","tags":[],"title":"计算机网络八股文","uri":"/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"操作系统 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:0:0","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"进程管理 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:1:0","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"进程和线程 进程组成 进程控制块PCB，是进程存在的唯一标志，包含进程标识符PID，进程当前状态，程序和数据地址，进程优先级、CPU现场保护区(用于进程切换)，占有的资源清单等。 程序段 数据段 进程创建、终止 进程创建的方法 系统初始化（init） 正在运行的程序执行了创建进程的系统调用（比如 fork） 用户请求创建一个新进程 初始化一个批处理工作 进程终止的方法 正常退出：exit() 发生程序错误后退出(自愿的) 被其他进程杀死(如发送信号kill) 进程和线程的区别 ​ 一个线程只能属于一个进程，而一个进程可以有多个线程，但至少有一个线程。线程依赖于进程而 存在。 调度: 进程是资源管理的基本单位，线程是程序执行的基本单位 切换: 线程上下文切换比进程上下文切换要快得多 拥有资源:进程是拥有资源的一个独立单位，线程不拥有系统资源，但是可以访问隶属于进程的资源。 系统开销:创建或撤销进程时，系统都要为之分配或回收系统资源，如内存空间，I/O 设备等，OS所付出的 开销显著大于在创建(只有栈的开销)或撤销线程时的开销，进程切换的开销也远大于线程切换的开销。 ​ 左侧为进程中每个线程共享的内容，右侧为线程单独的内容 协程，进程，线程的区别 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:1:1","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"进程状态 ​ 进程一共有5 种状态，分别是创建、就绪、运行(执行)、终止、阻塞。 运行状态就是进程正在 CPU上运行。在单处理机环境下，每一时刻最多只有一个进程处于运行状态。 就绪状态就是说进程已处于准备运行的状态，即进程获得了除 CPU之外的一切所需资源，一旦得到 CPU即可 运行。 阻塞状态就是进程正在等待某一事件而暂停运行，比如等待某资源为可用或等待 I/O 完成。即使 CPU空闲， 该进程也不能运行。 运行态→阻塞态:往往是由于等待外设，等待主存等资源分配或等待人工干预而引起的。 阻塞态→就绪态:则是等待的条件已满足，只需分配到处理器后就能运行。 运行态→就绪态:不是由于自身原因，而是由外界原因使运行状态的进程让出处理器，这时候就变成就绪态。例如 时间片用完，或有更高优先级的进程来抢占处理器等。 就绪态→运行态:系统按某种策略选中就绪队列中的一个进程占用处理器，此时就变成了运行态。 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:1:2","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"进程和线程的切换流程 进程切换: 切换页表以使用新的地址空间，一旦去切换上下文，处理器中所有已经缓存的内存地址一瞬间都作废了。 切换内核栈和硬件上下文。 线程切换 ​ 线程切换时因为其共享所在进程的虚拟地址空间的, 所以不需要切换地址空间,只需要切换内核栈和上下文 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:1:3","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"为什么虚拟空间的切换特别耗时? ​ 进程都有自己的虚拟地址空间，把虚拟地址转换为物理地址需要查找页表，页表查找是一个很慢的过程，因此通常使用 Cache 来缓存常用的地址映射，这样可以加速页表查找，这个 Cache 就是 TLB(translation Lookaside Buffer， TLB本质上就是一个 Cache，是用来加速页表查找的),即快表. ​ 显然每个进程都有自己的页表，那么当进程切换后页表也要进行切换，页表切换后 TLB就失效了，Cache 失效导致命 中率降低，那么虚拟地址转换为物理地址就会变慢，表现出来的就是程序运行会变慢 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:1:4","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"进程通信方式 管道 (速度慢，容量有限;) 管道可以分为两类:匿名管道和命名管道。匿名管道是单向的，只能在有亲缘关系的进程间通信;命名管道FIFO以磁盘文件的方式存在，可以实现本机任意两个进程通信。 信号 常用信号: SIGHUP: 用户从终端注销，所有已启动进程都将收到该进程。系统缺省状态下对该信号的处理是终止进程。 SIGINT: 程序终止信号。程序运行过程中，按 Ctrl+C 键将产生该信号。 SIGQUIT:程序退出信号。程序运行过程中，按 Ctrl+\\键将产生该信号 SIGBUS和 SIGSEGV:进程 访问非法地址。 SIGKILL:用户终止进程执行信号。shell 下执行 kill -9 发送该信号。 信号量: 信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程 正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手 段。(不能传递复杂消息，只能用来同步;) 消息队列。 (容量受到系统限制，且要注意第一次读的时候，要考虑上一次没有读完数据的问题;) 共享内存:共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都 可以访问。共享内存是最快的 IPC 方式(能够很容易控制容量，速度快，但要保持同步) Socket: 不同机器间的进程间通信 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:1:5","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"进程间同步的方式 临界区 ​ 通过对多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问。 ​ 优点: 保证在某一时刻只有一个线程能访问数据的简便办法 ​ 缺点: 虽然然临界区同步速度很快，但却只能用来同步 本进程内的线程，而不可用来同步多个进程中的线程。 ​ ​ 冲突解决: 如果有若干进程要求进入空闲的临界区，一次仅允许一个进程进入，如已有进程进入自己的临界区，则其它所 有试图进入临界区的进程必须等待; 进入临界区的进程要在有限时间内退出。 如果进程不能进入自己的临界区，则应让出 CPU，避免进程出现“忙等”现象。 互斥量 ​ 互斥量跟临界区很相似，比临界区复杂，互斥对象只有一个，只 有拥有互斥对象的线程才具有访问资源的权限。 ​ 优点: 使用互斥不仅仅能够在同一应用程序不同线程中实现资源的 安全共享，而且可以在不同进程的线程之间实现对资源的安全共享。 ​ 缺点: 1. 消耗的资源较多 2. 只能针对一个资源进行同步访问,没办法计数 信号量 ​ 为控制一个具有有限数量用户资源而设计。它允许多个线程在同一时刻访问同一资源，但是需要限制在同 一时刻访问此资源的最大线程数目。互斥量是信号量的一种特殊情况，当信号量的最大资源数=1就是互斥量了。 ​ 优点: 适用于对 Socket(套接字)程序中线程的同步。 ​ 缺点: 1. 必须有公共内存，不能用于分布式操作系统，这是它最大的弱点; 2. 对信号量的操作分散，而且难以控制，读写和维护都很困难 ​ ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:1:6","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"线程同步方式 临界区: 当多个线程访问一个独占性共享资源时，可以使用临界区对象。拥有临界区的线程可以访问被保护起来的 资源或代码段，其他线程若想访问，则被挂起，直到拥有临界区的线程放弃临界区为止，以此达到用原子方式操作 共享资源的目的 事件机制: 事件机制，则允许一个线程在处理完一个任务后，主动唤醒另外一个线程执行任务 互斥量: 互斥对象和临 界区对象非常相似，只是其允许在进程间使用，而临界区只限制与同一进程的各个线程之间使用，但是更节省资 源，更有效率 信号量: 当需要一个计数器来限制可以使用某共享资源的线程数目时,可以使用信号量 a. 互斥量与临界区的作用非常相似，但互斥量是可以命名的，也就是说互斥量可以跨越进程使用，但创建互斥量需要的资源更多，所以如果只为了在进程内部是用的话使用临界区会带来速度上的优势并能够减少资源占用 量. b. 互斥量，信号量，事件都可以被跨越进程使用来进行同步数据操作。 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:1:7","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"死锁和死锁产生的条件 ​ 两个或者多个并发进程中，如果每个进程持有某种资源而又等待其它进程释放它或它们现在保持着 的资源，在未改变这种状态之前都不能向前推进，称这一组进程产生了死锁. 四个必要条件 互斥条件:一个资源一次只能被一个进程使用 请求与保持条件:一个进程因请求资源而阻塞时，对已获得资源保持不放 非抢占: 进程获得的资源，在未完全使用完之前，不能强行抢占 循环等待条件:若干进程之间形成一种头尾相接的环形等待资源关系 死锁问题解决: 资源一次性分配，这样就不会再有请求了(破坏请求条件)。 只要有一个资源得不到分配，也不给这个进程分配其他的资源(破坏占有并等待条件)。 可抢占资源:即当进程新的资源未得到满足时，释放已占有的资源，从而破坏不可抢占的条件。 资源有序分配法:系统给每类资源赋予一个序号，每个进程按编号递增的请求资源，释放则相反，从而破坏环路等待的条件 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:1:8","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"进程调度策略 先来先服务: 非抢占式的调度算法，按照请求的顺序进行调度。 ​ 有利于长作业，但不利于短作业，因为短作业 必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很⻓时间，造成了短作业等待时间过长。 另外，对 I/O 密集型进程也不利，因为这种进程每次进行 I/O 操作之后又得重新排队. ​ 短作业优先: 非抢占式的调度算法，按估计运行时间最短的顺序进行调度 ​ 长作业有可能会饿死，处于一直等 待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度 最短剩余时间优先: 最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度 ​ 当一个新的作业到达时， 其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。 时间片轮转: 将所有就绪进程按 FCFS的原则排成一个队列，每次调度时，把 CPU时间分配给队首进程，该进程可 以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU时间分配给队 首的进程。 ​ a. 时间片轮转算法的效率和时间片的大小有很大关系:因为进程切换都要保存进程的信息并且载入新进程的信 息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。而如果时间片过长，那么实时性就不能得到保证。 ​ b. 优先级调度:为每个进程分配一个优先级，按优先级进行调度。为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。 多级队列调度算法: 将系统中的进程就绪队列从一个拆分为若干个，将不同类型或性质的进程固定分配在不同的就绪队列，不同的就绪队列采用不同的调度算法，一个就绪队列中的进程可以设置不同的优先级，不同的就绪队列本身也可以设置不同的优先级。 多级反馈队列调度算法: 为就绪队列赋予不同的优先级数，不同的时间片，按照优先级抢占CPU的调度算法; 优先权越高，队列的时间片越小. 首先调度优先级高的队列中的进程。若高优先级中队列中已没有调度的进程，则调度次优先级队列中的进程 同一个队列中的各个进程，按照 时间片轮转法调度 在低优先级的队列中的进程在运行时，又有新到达的作业，那么在运行完这个时间片后，CPU马上分配给新到达的作业即抢占式调度CPU ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:1:9","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"孤儿进程和僵尸进程 孤儿进程: 父进程已退出，但子进程还在运行的这些子进程都是孤儿进程，孤儿进程将被init进程(1号进程)所收养，并由init进程对他们完成状态收集工作。 僵尸进程: 进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait 获waitpid 获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中的这些进程是僵尸进程。 危害:僵尸进程会占用系统资源, 没有回收导致内存泄漏 避免: 手动杀死父进程,让子进程变成孤儿进程由init进程回收; 严格回收子进程 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:1:10","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"IO多路复用 ​ IO多路复用是指内核一旦发现进程指定的一个或者多个 IO条件准备读取，它就通知该进程。 适用场景 当客户处理多个描述字时(一般是交互式输入和网络套接口)，必须使用 I/O 复用。 当一个客户同时处理多个套接口时，而这种情况是可能的，但很少出现。 如果一个 TCP服务器既要处理监听套接口，又要处理已连接套接口，一般也要用到 I/O 复用。 如果一个服务器即要处理 TCP，又要处理 UDP，一般要使用 I/O 复用。 如果一个服务器要处理多个服务或多个协议，一般要使用 I/O 复用。 与多进程和多线程技术相比，I/O 多路复用技术的最大优势是系统开销小，系统不必创建进程/线程，也不必 维护这些进程/线程，从而大大减小了系统的开销。 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:1:11","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"写时复制 如果进程从来就不需要修改资源，则不需要进行复制,每个进程只要保存一 个指向这个资源的指针就可以了。惰性算法的好处 就在于它们尽量推迟代价高昂的操作，直到必要的时刻才会去执行。 在使用虚拟内存的情况下，写时复制(Copy-On-Write)是以页为基础进行的。所以，只要进程不 修改它全部的地址空间，那么就不必复制整个地址空间。在fork()调用结束后，父进程和子进程都相信它们有一个自己的地址空间，但实际上它们共享父进程的原始页，接下来这些页又可以被其他的父进程或子进程共享。 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:1:12","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"中断 ​ 简单来说就是CPU停下当前的工作任务，去处理其他事情，处理完后回来继续执行刚才的任务，这一过程便是中断。 中断的处理过程**?** 保护现场:将当前执行程序的相关数据保存在寄存器中，然后入栈。 开中断:以便执行中断时能响应较高级别的中断请求。 中断处理 关中断:保证恢复现场时不被新中断打扰 恢复现场:从堆栈中按序取出程序数据，恢复中断前的执行状态。 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:1:13","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"优先级反转问题 ​ 由于多进程共享资源，具有最高优先权的进程被低优先级进程阻塞，反而使具有中优先级的进程先于高 优先级的进程执行，导致系统的崩溃。这就是所谓的优先级反转(Priority Inversion)。 ​ 解决: 优先级继承(priority inheritance) :是指将低优先级任务的优先级提升到等待它所占有的资 源的最高优先级任务的优先级.当高优先级任务由于等待资源而被阻塞时,此时资源的拥有者的优先 级将会自动被提升。 优先级天花板(priority ceilings):是指将申请某资源的任务的优先级提升到可能访问该资 源的所有任务中最高优先级任务的优先级 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:1:14","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"内存管理 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:2:0","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"1. 分页 ​ 把内存空间划分为大小相等且固定的块，作为主存的基本单位。因为程序数据存储在不同的页面中，而页面又离散的分布在内存中，因此需要一个页表来记录映射关系，以实现从页号到物理块号的映射。访问分页系统中内存数据 需要两次的内存访问(一次是从内存中访问页表，从中找到指定的物理块号，加上页内偏移得到实际物理地址;第二 次就是根据第一次得到的物理地址访问内存取出数据)。 ​ 分片是由于分段的粒度太大,容易产生大量外部碎片. 而且对于某一个段进行内存置换代价也过大,因此进行段页式内存管理. ​ 每个页为4KB, 如果要规避分段,只需要跟linux一样将每个段的首地址设置为0,这样寻址则从内存开始出寻址,跟没分段一样. 多级页表 一个进程的页表可能很大, 一次性加载到内存中会浪费空间, 因此产生了多级页表, 一次只加载所需要的页表,用于节省内存空间. 快表 快表（TLB）：提高变换速度→用高速缓冲存储器存放常用的页表项 MMU: 即内存管理单元，该硬件负责处理虚拟地址到物理地址的转化工作。快表也存储在MMU上。 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:2:1","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"2. 分段 ​ 分段是为了满足程序员在编写代码的时候的一些逻辑需求(比如数据共享，数据保 护，动态链接等)。分段内存管理当中，地址是二维的，一维是段号，二维是段内地址;由于分段管理中，每个段内部是连续内存分配，但是段和段之间是离散 分配的，因此也存在一个逻辑地址到物理地址的映射关系，相应的就是段表机制。 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:2:2","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"3. 分段分页的区别 分页对程序员是透明的，但是分段需要程序员显式划分每个段。 分页的地址空间是一维地址空间，分段是二维的。 页的大小不可变，段的大小可以动态改变。 分页主要用于实现虚拟内存，从而获得更大的地址空间;分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护。 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:2:3","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"4. 交换空间是什么 ​ 操作系统把物理内存(physical RAM)分成一块一块的小内存，每一块内存被称为页(page)。当内存资源不足时， Linux 把某些页的内容转移至硬盘上的一块空间上，以释放内存空间。硬盘上的那块空间叫做交换空间(swap space),而这一过程被称为交换(swapping)。物理内存和交换空间的总容量就是虚拟内存的可用容量。 ​ 用途: 物理内存不足时一些不常用的页可以被交换出去，腾给系统。 程序启动时很多内存页被用来初始化，之后便不再需要，可以交换出去。 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:2:4","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"5. 页面置换算法 ​ 在程序运行过程中，如果要访问的页面不在内存中，就发生缺页中断从而将该页调入内存中。此时如果内存已无空闲空间，系统必须从内存中调出一个页面到磁盘对换区中来腾出空间。 最佳算法:所选择的被换出的页面将是最长时间内不再被访问，通常可以保证获得最低的缺页率。这是一种理论上的算法，因为无法知道一个页面多长时间不再被访问。 (先进先出)FIFO: 思路:置换最先调入内存的页面，即置换在内存中驻留时间最久的页面。 实现:按照进入内存的先后次序排列成队列，从队尾进入，从队首删除。 特点:实现简单;性能较差，调出的页面可能是经常访问的 (最近最少使用)LRU: LRU将最近最久未使用的页面换出。 为了实现 LRU，需要在内存中维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。因为每次访问都需要更新链表，因此这种方式实现的 LRU代价很高。 特点:可能达到最优的效果，维护这样的访问链表开销比较大 时钟算法:时钟算法使用环形链表将页面连接起来，再使用一个指针指向最开始的页面。当需要进行页面置换时，时钟指针开始转动寻找可置换页面，直到遇到访问位为0的页号为止。在这个过程中，将遇到的访问位为1的页全部置为0.时钟指针寻找到要被置换的页面后，将新页放于那个位置。 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:2:5","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"6. 缓冲区 ​ 缓冲区又称为缓存，它是内存空间的一部分。也就是说，在内存空间中预留了一定的存储空间，这些存储空间用来缓冲输入或输出的数据，这部分预留的空间就叫做缓冲区 缓冲区溢出 冲区溢出是指当计算机向缓冲区填充数据时超出了缓冲区本身的容量，溢出的数据覆盖在合法数据上。 危害有以下两点: 程序崩溃，导致拒绝服务 跳转并且执行一段恶意代码造成缓冲区溢出的主要原因是程序中没有仔细检查用户输入 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:2:6","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"7. 虚拟内存 ​ 在操作系统中，进程是以页为单位加载到内存中的，按需分页是一种虚拟内存的管理方式。在使用请求分页的系统中，只有在尝试访问页面所在的磁盘并且该页面尚未在内存中时，也就发生了缺页异常，操作系统才会将磁盘页面复制到内存中。 虚拟内存就是说，让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。虚拟内存使用部分加载的技术，让一个进程或者资源的某些页面加载进内存，从而能够加载更多的进程，甚至能加载比内存大的进程，这样看起来好像内存变大了，这部分内存其实包含了磁盘或者硬盘，并且就叫做虚拟内存。 虚拟内存是一种对主存的抽象概念,其为每个进程提供了一个全物理内存的、一致的和私有的地址空间 虚拟内存主要能力: 它将主存看成是一个存储在磁盘上的地址空间的高速缓存，在主存中只保存活动区域，并根据需要 在磁盘和主存之间来回传送数据，通过这种方式，它高效地使用了主存。 操作系统为每个进程提供了一个独立的页表(一致的地址空间)，也就是独立的虚拟地 址空间。多个虚拟页面可以映射到同一个物理页面上。从而简化了内存管理。 它保护了每个进程的地址空间不被其他进程破坏。 为什么引入虚拟内存? 简化链接: 独立的地址空间允许每个进程的内存映像使用相同的基本格式，而不管代码和数据 实际存放在物理内存的何处 简化加载: 加载器从不在磁盘到内存实际复制任何数据，在每个页初次被引用时，虚拟内存系统会按照需要自动的调入数据页 简化共享: 一般来说, 每个进程有各自私有的代码，数据，堆栈，是不和其他进程共享的，这样OS创建页表，将虚拟页映射到不连续的物理页面。 某些情况下，需要进程来共享代码和数据。例如每个进程调用相同的操作系统内核代码， 或者C标准库函数。OS会把不同进程中适当的虚拟页面映射到相同的物理页面。 简化内存分配: 虚拟地址转换到物理地址的过程 ​ 虚拟地址由虚拟页号和页偏移两部分组成。通过虚拟地址的页面号，首先在快表中查询是否有该映射，查询成功，在页表中找到该页对应的物理地址。然后通过页物理地址+页偏移，得到真实的物理地址 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:2:7","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"8. 内存分配和回收 ​ 为了防止内存碎片，把所有的空闲页框分组为11个块链表，每个块链表分别包含大小为1，2，4，8，16，32，64，128，256，512和1024个连续页框的页框块。 ​ 假设要申请一个256个页框的块，先从256个页框的链表中查找空闲块，如果没有，就去512个页框的链表中找，找到了则将页框块分为2个256个页框的块，一个分配给应用，另外一个移到256个页框的链表中。如果512个页框的链表中仍没有空闲块，继续向1024个页框的链表查找，如果仍然没有，则返回错误。页框块在释放时，会主动将两个连续的页框块合并为一个较大的页框块。 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:2:8","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"系统管理 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:3:0","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"1. 内核态和用户态切换 系统调用: 系统调用是操作系统的最小功能单位，是操作系统提供的用户接口，系统调用本身是一种软中断. 异常: 也叫做内中断，是由错误引起的，如文件损坏、缺页故障等。 外部中断: 是通过两根信号线来通知处理器外设的状态变化，是硬中断。 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:3:1","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"2. 内核态和用户态的区别 处于内核态的进程可以访问系统的所有数据，并且cpu不会发生抢占。 处于用户态的进程只能受限得访问内存，并且cpu会被抢占。 操作系统从用户态跳转到内核态 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:3:2","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"3. OS启动过程 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:3:3","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"4. 系统调用 调用 说明 pid = fork() 创建与父进程相同的子进程 pid = waitpid(pid, \u0026statloc,options) 等待一个子进程终止 s = execve(name,argv,environp) 替换一个进程的核心映像 exit(status) 终止进程执行并返回状态 fork()， 它创建一个原有进程的副本，包括所有的文件描述符、寄存器等内容。fork 调用会返回一个值，在子进程中该值为 0 ，并且在父进程中等于子进程的 进程标识符(Process IDentified,PID)。使用返回的 PID，就可以看出来哪个是父进程和子进程。 waitpid：为了等待子进程完成，父进程需要执行 waitpid 系统调用，父进程会等待直至子进程终止（若有多个子进程的话，则直至任何一个子进程终止）。waitpid 可以等待一个特定的子进程，或者通过将第一个参数设为 -1 的方式，等待任何一个比较老的子进程。 ","date":"2022-08-26","objectID":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/:3:4","tags":[],"title":"操作系统八股文","uri":"/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"Linux ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:0:0","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"基础命令 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:0","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"1. 怎么查看当前进程？怎么执行退出？怎么查看当前路径？ ​ 查看当前进程：ps、执行退出：exit、查看当前路径：pwd ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:1","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"2. 查看当前用户id [root@cx-ali ~]# id uid=0(root) gid=0(root) groups=0(root) # 用户id、组id、所属附加群组的id ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:2","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"3. 建立软链接和硬链接 ln -s src dist ln src dist 硬链接就是在目录下创建一个条目，记录着文件名与 inode 编号，这个 inode 就是源文件的 inode。删除任 意一个条目，文件还是存在，只要引用数量不为0。但是硬链接有限制，它不能跨越文件系统，也不能对目录 进行链接。 软链接又叫符号链接文件, 保存着源文件所在的绝对路径，在读取时会定位到源文件上，可以理解为 Windows的快捷方 式。当源文件被删除了，链接文件就打不开了。因为记录的是路径，所以可以为目录建立符号链接。 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:3","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"4. 查看文件命令 vi filename #编辑方式查看，可修改 cat filename #显示全部文件内容 more filename #分页显示文件内容 less filename #与 more 相似，更好的是可以往前翻页 tail filename #仅查看尾部，还可以指定行数 head filename #仅查看头部,还可以指定行数 # 一页一页查看大文件命令 cat filename | more ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:4","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"5.统计文件内容命令 [root@cx-ali ~]# wc -c -l -w .viminfo 47 148 770 .viminfo # -c 统计字节数 -l 统计行数 -w 统计字数 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:5","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"6. grep搜索命令 grep -i \"error\" #忽略大小写区分 grep -v \"grep\" #忽略grep命令本身，在文档中过滤掉包含有grep字符的行 grep [^string] filename #正则表达式搜索 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:6","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"7. 后台运行命令 ​ 使用 \u0026 在命令结尾来让程序自动运行。 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:7","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"8. 查看所有进程 ps -ef # system v 输出 ps -aux # bsd 格式输出 ps -ef | grep pid ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:8","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"9. 查看后台任务 jobs -l ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:9","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"10. 把后台任务调到前台执行使用什么命令?把停下的后台任务在后台执行起来用什么命令? fg # 把后台任务调到前台执行 bg # 把停下的后台任务在后台执行起来 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:10","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"11. 终止进程用什么命令? # kill [-s \u003c信息名称或编号\u003e][程序] 或 kill [-l \u003c信息编号\u003e] kill -9 pid kill -l # 查看系统支持的所有信号 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:11","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"12. 搜索文件的命令 # find \u003c指定目录\u003e \u003c指定条件\u003e \u003c指定动作\u003e # find 直接搜索磁盘，较慢。 find / -name \"string*\" locate 只加文件名 whereis # whereis [-bfmsu][-B \u003c目录\u003e...][-M \u003c目录\u003e...][-S \u003c目录\u003e...][文件...] #-b 只查找二进制文件。 #-B\u003c目录\u003e 只在设置的目录下查找二进制文件。-f 不显示文件名前的路径名称。 #-m 只查找说明文件。 #-M\u003c目录\u003e 只在设置的目录下查找说明文件。-s 只查找原始代码文件。 #-S\u003c目录\u003e 只在设置的目录下查找原始代码文件。-u 查找不包含指定类型的文件。 #which 指令会在 PATH 变量指定的路径中，搜索某个系统命令的位置，并且返回第一个搜索结果。 #-n 指定文件名长度，指定的长度必须大于或等于所有文件中最长的文件名。 #-p 与-n 参数相同，但此处的包括了文件的路径。-w 指定输出时栏位的宽度。 #-V 显示版本信息 #which 只能查可执行文件 #whereis 只能查二进制文件、说明文档，源文件等 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:12","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"13. 使用什么命令查看磁盘使用空间？ [root@cx-ali ~]# df -hl Filesystem Size Used Avail Use% Mounted on # 文件系统 容量 已用 可用 已用% 挂载点 devtmpfs 1.8G 0 1.8G 0% /dev # du 和 df 的定义，以及区别？ # du 显示目录或文件的大小 # df 显示每个\u003c文件\u003e所在的文件系统的信息，默认是显示所有文件系统。 # df 命令获得真正的文件系统数据，而 du 命令只查看文件系统的部分情况。 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:13","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"14. 查看网络 netstat netstat -nlpt # 查看tcp的网络信息 # 查看端口占用 lsof -i:port netstat -tunlp|grep port ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:14","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"15. 对命令取别名 alias la='ls -a' ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:15","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"16. awk cat /etc/passwd |awk -F ':' '{print $1\"\\t\"$7}' # -F 的意思是以':'分隔 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:16","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"17. 列出所有支持的命令 compgen -c ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:17","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"18. 不重启机器的条件下，有什么方法可以把所有正在运行的进程移除呢？ disown -r ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:18","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"19. 定时任务 crontab [-u username]　#省略用户表表示操作当前用户的crontab -e (编辑工作表) -l (列出工作表里的命令) -r (删除工作作) # 实例 * * * * * myCommand # 每分钟执行 3,15 8-11 * * * myCommand # 在上午8点到11点的第3和第15分钟执行 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:19","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"20. 查看路由表 route -n nestat -rn ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:20","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"21. 查看系统资源占用 top # top 命令 第一行 — 任务队列信息: top - 20:45:10 up 10:08, 1 user, load average: 0.00, 0.01, 0.05 内容 意义 20:45:10 当前时间 up 10:08 系统运行时间（10小时08分钟） 1 user 当前登录用户数 load average: 0.00, 0.01, 0.05 系统负载（任务队列的平均长度），分别是1分钟、5分钟、15分钟到现在的平均值 第二行 — 进程信息: Tasks: 105 total, 1 running, 104 sleeping, 0 stopped, 0 zombie 内容 意义 105 total 进程总数 1 running 正在运行的进程数 104 sleeping 睡眠进程数 0 stopped 停止进程数 0 zombie 僵尸进程数 第三行 — CPU信息: Cpu(s): 0.0%us, 0.1%sy, 0.0%ni, 99.9%id, 0.0%wa, 0.0%hi, 0.0%si, 0.0%st 内容 意义 0.0%us 用户空间占CPU百分比 0.1%sy 内核空间占CPU百分比 0.0%ni 用户进程空间内改变过优先级的进程占用CPU百分比 99.9%id 空闲CPU百分比 0.0%wa 等待输入输出的CPU时间百分比 0.0%hi 硬件中断占CPU时间百分比 0.0%si 软件终端占CPU时间百分比 0.0%st 提供给虚拟化环境执行占CPU时间百分比 第四行 — 内存信息: Mem: 288428k total, 257956k used, 30472k free, 40160k buffers 内容 意义 288428k total 物理内存总量 257956k used 使用的物理内存总量 30472k free 空闲内存总量 40160k buffers 用作内核缓存的内存量 第五行 — 内存交换区信息: Swap: 1046524k total, 3856k used, 1042668k free, 82000k cached 内容 意义 1046524k total 交换区总容量 3856k used 使用交换区的总量 1042668k free 空闲交换区总量 82000k cached 缓冲交换区总量 进程信息: PID 进程ID S 进程状态 USER 进程所有者用户名 %CPU CPU 时间占用百分比 PR 优先级 %MEM 进程使用物理内存百分比 NI nice值,负数表示高优先级 TIME+ 进程使用的CPU时间总计 VIRT 进程使用虚拟内存总量（以KB为单位） VIRT=SWAP+RES COMMAND 命令名/命令行 RES 进程使用的未被换出的物理内存大小（以KB为单位） RES=CODE+DATA SHR 共享内存总大小 lsof ​ lsof表示文件列表，我们可以知道哪个进程打开了哪个文件。 查看系统负载 [root@cx-ali ~]# w 12:57:02 up 27 days, 22:54, 1 user, load average: 0.01, 0.02, 0.05 USER TTY FROM LOGIN@ IDLE JCPU PCPU WHAT root pts/0 113.246.112.27 11:35 6.00s 0.06s 0.00s w [root@cx-ali ~]# uptime 12:57:34 up 27 days, 22:55, 1 user, load average: 0.00, 0.02, 0.05 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:21","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"22. 查看物理CPU和CPU核数 cat /proc/cpuinfo|grep -c 'physical id' # CPU数 cat /proc/cpuinfo|grep -c 'processor' # 核数 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:22","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"23. 查看内存信息 [root@centos6 ~ 10:57 #39]# vmstat procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 0 0 0 1783964 13172 106056 0 0 29 7 15 11 0 0 99 0 0 [root@cx-ali ~]# free -m total used free shared buff/cache available Mem: 3733516 1493136 196568 616 2043812 1960704 Swap: 0 # cat /proc/meminfo r即running，表示正在跑的任务数; b即blocked，表示被阻塞的任务数; si表示有多少数据从交换分区读入内存; so表示有多少数据从内存写入交换分区; bi表示有多少数据从磁盘读入内存; bo表示有多少数据从内存写入磁盘 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:23","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"24.网络修改 编辑/etc/sysconfig/network-scripts/ifcft-eth0 文件。重启网络服务service network restart 给一个网卡配置多个ip, 新建一个ifcfg-eth0:1文件,将DEVICE名称改为eth0:1 ,修改ip,重启网络服务即可 在文件 /etc/resolv.conf 中设置DNS ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:1:24","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"系统管理 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:2:0","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"1. 终端是哪个文件夹下的哪个文件？黑洞文件是哪个文件夹下的哪个命令？ 终端 /dev/tty 黑洞文件 /dev/null ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:2:1","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"2. Linux 中进程有哪几种状态？在 ps 显示出来的信息中，分别用什么符号表示的？ (D)不可中断状态：进程处于睡眠状态，但是此刻进程是不可中断的。不可中断， 指进程不响应异步信号.() (T)停止状态/跟踪状态：向进程发送一个 SIGSTOP 信号，它就会因响应该信号 而进入 TASK_STOPPED 状态;当进程正在被跟踪时，它处于 TASK_TRACED 这个特殊的状态。“正在被跟踪”指的是进程暂停下来，等待跟踪它的进程对它进行操作 就绪状态： (R)运行状态：在 run_queue 队列里的状态 (S)可中断睡眠状态：处于这个状态的进程因为等待某某事件的发生（比如等待 socket 连接、等待信号量），而被挂起 (Z)僵尸 状态：父亲没有通过 wait 系列的系统调用会顺便将子进程的尸体（task_struct）也释放掉 (X)退出状态 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:2:2","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"3. 进程管理 父子进程通信 父进程通过使用管道，套接字，消息队列等与子进程进行通信。 僵尸进程 这是一个执行已完成但进程表中甚至存在信息的进程。由于父进程需要读取子进程的状态，因此发生在父进程中。一旦使用wait系统调用完成了该任务，则僵尸进程将从进程表中删除。这被称为僵尸进程。 异步和非阻塞的区别 异步:调用在发出之后，这个调用就直接返回，不管有无结果;异步是过程。 非阻塞:关注的是程序在等待调用结果(消息，返回值)时的状态，指在不能立刻得到结果之前，该调用不会阻塞当前线程。 进程状态 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:2:3","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"4. 内存管理 buffer和cache如何区分? ​ **Cache是加速“读”，**而buffer是缓冲“写 ​ buffer和cache都是内存中的一块区域，当需要写数据到磁盘时，由于磁盘速度比较慢，所以CPU先把数据存进buffer，然后CPU去执行其他任务，buffer中的数据会定期写入磁盘；当需要从磁盘读入数据时，由于磁盘速度比较慢，可以把即将用到的数据提前存入cache，CPU直接从Cache中拿数据要快的多。 Swap空间 交换空间的主要功能是当全部的 RAM 被占用并且需要更多内存时，用磁盘空间代替 RAM 内存。Linux 计算机中的内存总量是 RAM + 交换分区，交换分区被称为虚拟内存. 内存数据段 预留内存地址（操作系统维护的内存地址，不可访问） 代码段（codesegment/textsegment）：又称文本段，用来存放指令，运行代码的一块内存空间，此空间大小在代码运行前就已经确定。 数据段（datasegment）：可读可写，存储初始化的全局变量和初始化的 static 变量。 bss段（bsssegment）：可读可写，存储未初始化的全局变量和未初始化的 static 变量。 rodata段：只读数据，常量区 栈（stack）：可读可写，存储的是函数或代码中的局部变量(非 static 变量)。 堆（heap）：可读可写，存储的是程序运行期间动态分配的 malloc/realloc 的空间。 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:2:4","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"源码和原理分析 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:3:0","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"1. 进程和线程API 进程API 线程API 描述 fork pthread_create 创建新的控制流 exit pthread_exit 从现有的控制流中退出 waitpid pthread_join 从控制流中得到退出状态 atexit pthread_cancel_push 注册在退出控制流时调用的函数 getpid pthread_self 获取控制流的ID abort pthread_cancel 请求控制流的非正常退出 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:3:1","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"2. select、poll、epoll原理 ​ IO 多路复用的本质是通过一种机制，让单个进程可以监视多个描述符，当发现某个描述符就绪之后，能够通知程序进行相应的读写操作。 ​ select，poll，epoll 都是同步 IO。所谓同步 IO，便是读写是阻塞的，需要在读写事件就绪后自己负责读写，而异步 IO 会把数据从内核拷贝到用户空间，并不需要自己负责读写。 select: ​ 遍历监听的fd_set（1024位的bitmap数组存储） ​ 调用 select 函数时，内核会根据 IO 状态对 fd_set 的内容进行修改，从而通知执行 select 函数的进程哪一个文件或者 Socket 是可读的。select 函数与同步阻塞模型并无过多区别，甚至还多出了一部分操作（监视 socket /调用 select 函数），导致更低的效率。 优点：用户可以在一个线程内同时处理多个 socket 的 IO 请求。用户可以注册多个 socket，然后调用 select 函数读取被激活的 socket，从而实现在同一个线程内同时处理多个 IO 请求，在这点上select 函数与同步阻塞模型不同，因为在同步阻塞模型中需要通过多线程才能达到这个目的。 缺点： 调用 select 函数时，需要把 fd__set_ 集合从用户态拷贝到内核态，当 fd_set 集合很大时，这个开销将会非常巨大 调用 select 函数时，需要在内核遍历传递进来的所有 fd__set_，当 fd_set 集合很大时，这个开销将会非常巨大 内核对被监控的 fd_set 集合大小做了限制 poll ​ 就是对fd_set（链表存储）没有1024的限制了 epoll ​ epoll采用IO多路复用技术,采用事件回调的方式，可以非常高效的处理数以百万计的Socket句柄. ​ epoll 使用一个文件描述符管理多个描述符，它将文件描述符的事件放入内核的一个事件表中，从而在用户空间和内核空间的复制操作只用实行一次即可。 ​ 在获取事件时，epoll 无需遍历整个被监听的描述符集，而是只需遍历被内核 IO 事件异步唤醒而加入 Ready 队列的描述符集合即可。因此，epoll 能显著提高程序在大量并发连接中只有少量活跃的情况下的系统 CPU 利用率。 核心数据结构 ​ epoll的核心数据结构在于红黑树+双向链表 首先调用epoll_create时内核帮我们在epoll文件系统里建了个file结点. 在内核cache里建立红黑树用于存储以后epoll_ctl传来的socket，当有新的socket连接来时，先遍历红黑书中有没有这个socket存在，如果有就立即返回，没有就插入红黑数 然后给内核中断处理程序注册一个钩子函数，每当有事件发生时就通过钩子函数把这些文件描述符放到用来存储就绪事件的链表中。 epoll_wait并不监听文件句柄，而是等待就绪链表不空or收到信号or超时这三种条件后返回。 优点: 没有最大并发连接的限制 不采取轮询的方式，效率高，只会处理活跃的连接，与连接总数无关 select、poll、epoll 总结对比 效率: select 只知道有 IO 事件发生，却不知道是哪几个流，只能采取轮询所有流的方式，故其具有 O(n) 的无差别轮询复杂度，处理的流越多，无差别轮询时间就越长 poll 与 select 并无区别，它的时间复杂度也是 O(n) epoll 会将哪个流发生了怎样的 IO 事件通知我们（当描述符就绪时，系统注册的回调函数会被调用，将就绪描述符放到 readyList 里面），它是事件驱动的，其时间复杂度为 O(1) 操作方式: select 和 poll 都是采取遍历的方式，而 epoll 则是采取了回调的方式 底层实现 select 的底层实现为数组，poll 的底层实现为链表，而 epoll 的底层实现为红黑树 最大链接 select 的最大连接数为 1024 或 2048，而 poll 和 epoll 是无上限的 对文件描述符的拷贝 select 和 poll 每次被调用时都会把描述符集合从用户态拷贝到内核态 epoll 在调用 epoll_ctl 时会拷贝进内核并保存，之后每次 epoll_wait 时不会拷贝 性能 epoll 在绝大多数情况下性能远超 select 和 poll，但在连接数少并且连接都十分活跃的情况下，select 和 poll 的性能可能比 epoll 好，因为 epoll 的通知机制需要很多函数回调 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:3:2","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"3. 编译 编译过程 预处理阶段：处理以 # 开头的预处理命令； 编译阶段：翻译成汇编文件； 汇编阶段：将汇编文件翻译成可重定位目标文件； 链接阶段：将可重定位目标文件和 printf.o 等单独预编译好的目标文件进行合并，得到最终的可执行目标文件。 动态链接和静态链接的过程 静态链接 符号解析：每个符号对应于一个函数、一个全局变量或一个静态变量，符号解析的目的是将每个符号引用与一个符号定义关联起来。 重定位：链接器通过把每个符号定义与一个内存位置关联起来，然后修改所有对这些符号的引用，使得它们指向这个内存位置。 将所有需要的二进制代码都包含到可执行文件中. 动态链接 在给定的文件系统中一个库只有一个文件，所有引用该库的可执行目标文件都共享这个文件，它不会被复制到引用它的可执行文件中； 在内存中，一个共享库的 .text 节（已编译程序的机器代码）的一个副本可以被不同的正在运行的进程共享。 ","date":"2022-08-26","objectID":"/linux%E5%85%AB%E8%82%A1%E6%96%87/:3:3","tags":[],"title":"Linux八股文","uri":"/linux%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"Golang ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:0:0","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"基础数据结构 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:0","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"1. go的指针和c的指针 ​ 相同点: ​ 运算符相同, \u0026为取地址, *为解引用 ​ 不同点: 数组名和数组首地址. c语言中arr、\u0026arr[0]为数组的首个元素地址,单位偏移量为元素大小; \u0026arr为数组的首地址,单位偏移量为数组大小. golang中\u0026arr[0]和\u0026arr与c语言中相同, 但是arr表示为整个数组的值. // C int arr[5] = {1, 2, 3, 4, 5}; // Go // 需要指定长度，否则类型为切片 arr := [5]int{1, 2, 3, 4, 5} 指针运算. c语言中指针本质为无符号整数,代表内存地址, 可以进行加减运算. Golang中指针为 *uint32类型非数字,不可以加减运算. Go 标准库中提供了一个 unsafe 包用于编译阶段绕过 Go 语言的类型系统，直接操作内存 uintptr : Go 的内置类型。是一个无符号整数，用来存储地址，支持数学运算。常与 unsafe.Pointer 配合做指针运算 unsafe.Pointer : 表示指向任意类型的指针，可以和任何类型的指针互相转换（类似 C 语言中的 void* 类型的指针），也可以和 uintptr 互相转换 unsafe.Sizeof : 返回操作数在内存中的字节大小，参数可以是任意类型的表达式，例如 fmt.Println(unsafe.Sizeof(uint32(0)))的结果为 4 unsafe.Offsetof : 函数的参数必须是一个字段 x.f，然后返回 f 字段相对于 x 起始地址的偏移量，用于计算结构体成员的偏移量 golang中不能被寻址的类型:(不可变的，临时结果和不安全的。) 常量、字符串、函数或方法、map中的元素… ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:1","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"2. String的底层结构 type StringHeader struct { // 16 字节 Data uintptr Len int } 本质为byte类型的数组 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:2","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"3.slice和array的区别和底层结构 ​ array 为定长数组, slice为不定长数组 底层结构 type slice struct { array unsafe.Pointer // array指针指向底层array的某一个元素，其决定slice所能控制的内存片段的起始位置，这里需要注意的是，array不一定指向底层array的首元素，这与slice的创建有关。 len int //len 代表当前切片的长度,限定slice可直接通过索引(下标)存取元素的范围 cap int // cap 是当前切片的容量,表示slice所引用的array片段的真实大小 } // slice 扩张: slice扩容规则是：在1024字节以内，扩容一倍，大于1024时，增加cap的1/4 初始化方式: // 数组 // 切片 a := [3]int{1,2,3} //指定长度 s := make([]int, 3) //指定长度 a := [...]int{1,2,3} //不指定长度 s := []int{1,2,3} //不指定长度 函数传递 当切片和数组作为参数在函数（func）中传递时，数组传递的是值，而切片传递的是指针。因此当传入的切片在函数中被改变时，函数外的切片也会同时改变。相同的情况，函数外的数组则不会发生任何变化。 nil切片和空切片最大的区别在于指向的数组引用地址是不一样的 所有的空切片指向的数组引用地址都是一样的 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:3","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"4. Map底层结构 用于存储一系列无序的键值对,hashmap作为底层实现 Map基本数据结构: // hashmap的简称 type hmap struct { count int //元素个数 flags uint8 //标记位 B uint8 //buckets的对数, 说明包含2^B个bucket noverflow uint16 //溢出的bucket的个数 hash0 uint32 //hash种子 buckets unsafe.Pointer //指向buckets数组的指针，数组个数为2^B oldbuckets unsafe.Pointer //扩容时使用，buckets长度是oldbuckets的两倍 nevacuate uintptr //扩容进度，小于此地址的buckets已经迁移完成 extra *mapextra //扩展信息 } //当map的key和value都不是指针，并且size都小于128字节的情况下，会把 bmap 标记为不含指针，这样可以避免gc时扫描整个hmap。但是，我们看bmap其实有一个overflow的字段，是指针类型的，破坏了bmap不含指针的设想，这时会把overflow移动到extra字段来。 type mapextra struct { overflow *[]*bmap oldoverflow *[]*bmap //用于扩容 nextOverflow *bmapx //prealloc的地址 } // bucket type bmap struct { tophash [bucketCnt]uint8 //bucketCnt = 8,用于记录8个key哈希值的高8位，这样在寻找对应key的时候可以更快，不必每次都对key做全等判断 // keys [8]keytype // values [8]valuetype // pad uintptr // overflow uintptr } ​ hmap结构图 如何扩容 ​ 触发条件: 1. 装填因子大于6.5(装填因子为2^B); 2. overflow bucket 太多 ​ 解决办法: 双倍扩容:扩容采取了一种称为“渐进式”地方式，原有的 key 并不会一次性搬迁完毕，每次最多只会搬迁2 个 bucket.(条件1) 等量扩容:重新排列，极端情况下，重新排列也解决不了，map成了链表，性能大大降低，此时哈希种子 hash0 的设置，可以降低此类极端场景的发生。(条件2) 赋值操作 在查找key之前，会做异常检测，校验map是否未初始化，或正在并发写操作，如果存在，则抛出异常：（这就是为什么map 并发写回panic的原因） 需要计算key 对应的hash 值，如果buckets 为空（初始化的时候小于一定长度的map 不会初始化数据）还需要初始化一个bucket 通过hash 值，获取对应的bucket。如果map 还在迁移数据，还需要在oldbuckets中找对应的bucket，并搬迁到新的bucket。 拿到bucket之后，还需要按照链表方式一个一个查，找到对应的key， 可能是已经存在的key，也可能需要新增。 插入数据前，会先检查数据太多了，需要扩容，如果需要扩容，那就从第③开始拿到新的bucket，并查找对应的位置。 如果没有空的位置，那就需要在链表后追加一个bucket，拿到kv 最后更新tophash 和 key 的字面值, 并解除hashWriting 约束 数据迁移 先要判断当前bucket是不是已经转移。 (oldbucket 标识需要搬迁的bucket 对应的位置) 如果没有被转移，那就要迁移数据了。数据迁移时，可能是迁移到大小相同的buckets上，也可能迁移到2倍大的buckets上。这里xy 都是标记目标迁移位置的标记：x 标识的是迁移到相同的位置，y 标识的是迁移到2倍大的位置上。 确定bucket位置后，需要按照kv 一条一条做迁移。（目的就是清除空闲的kv） 数据查找 ​ Go语言中 map采用的是哈希查找表，由一个 key 通过哈希函数得到哈希值，64 位系统中就生成一个64bit 的哈希值，由这个哈希值将 key 对应到不同的桶bucket中，当有多个哈希映射到相同的的桶中时，使用链表解决哈希冲突。key 经过 hash 后共64 位，根 据 hmap中 B的值，计算它到底要落在哪个桶时，桶的数量为2^B，如 B=5，那么用64 位最后5 位表示第几号桶，在用 hash 值的高8 位确定在 bucket 中的存储位置，当前 bmap中的 bucket 未找到，则查询对应的 overflow bucket，对应位置有数据则对比完整的哈希值，确定是否是要查找的数据。如果两个不同的 key 落在的同一个桶上，hash 冲突使用链表法接近，遍历 bucket 中的 key ;如果当前处于 map进 行了扩容，处于数据搬移状态，则优先从 oldbuckets 查找。 根据key计算出hash值。 如果存在old table, 首先在old table中查找，如果找到的bucket已经evacuated，转到步骤3。 反之，返回其对应的value。 在new table中查找对应的value。 map 顺序读取方法 ​ 给key排序后读取 set实现 map[string]bool //会有bool的空间占用，可以替换成空结构体 type void struct{} var member void set := make(map[string]void) set[\"test\"] = member ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:4","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"5. Channel 底层结构 type hchan struct { qcount uint // 队列中的数据个数 dataqsiz uint // 环形队列的大小，channel本身是一个环形队列 buf unsafe.Pointer // 存放实际数据的指针，用unsafe.Pointer存放地址，为了避免gc elemsize uint16 closed uint32 // 标识channel是否关闭 elemtype *_type // 数据 元素类型 sendx uint // send的 index recvx uint // recv 的 index recvq waitq // 阻塞在 recv 的队列 sendq waitq // 阻塞在 send 的队列 lock mutex // 锁 } channel本身是一个环形缓冲区，数据存放到堆上面，channel的同步是通过锁实现的，并不是想象中的lock-free的方式，channel中有两个队列，一个是发送阻塞队列，一个是接收阻塞队列。当向一个已满的channel发送数据会被阻塞，此时发送协程会被添加到sendq中，同理，当向一个空的channel接收数据时，接收协程也会被阻塞，被置入recvq中。 创建channel 缓冲区大小为0: 只需要分配hchansize大小的内存就ok; 缓冲区大小不为0，且channel的类型不包含指针: buf为hchanSize+元素大小*元素个数的连续内存 缓冲区大小不为0，且channel的类型包含指针，则不能简单的根据元素的大小去申请内存，需要通过mallocgc去分配内存(即内存逃逸) channel特性 \u003e 1. 给一个 nil channel 发送数据，造成永远阻塞 从一个 nil channel 接收数据，造成永远阻塞 关闭一个 nil channel 将会发生 panic 给一个已经关闭的 channel 发送数据，引起 panic 当 c.closed != 0 则为通道关闭，此时执行写，源码提示直接 panic，输出的内容就是上面提到的 \"send on closed channel\"。 从一个已经关闭的 channel 接收数据，如果缓冲区中为空，则返回一个零值 c.closed != 0 \u0026\u0026 c.qcount == 0 指通道已经关闭，且缓存为空的情况下（已经读完了之前写到通道里的值） 如果接收值的地址 ep 不为空 那接收值将获得是一个该类型的零值 typedmemclr 会根据类型清理相应地址的内存 这就解释了上面代码为什么关闭的 chan 会返回对应类型的零值 无缓冲的 channel 是同步的，而有缓冲的 channel 是非同步的 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:5","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"6. interface // interface 分为空接口和非空接口，分别用eface 和 iface实现。 // eface type eface struct { _type *_type data unsafe.Pointer //指向数据的数据指针 } //_type 定义 type _type struct { size uintptr // 类型的大小 ptrdata uintptr // size of memory prefix holding all pointers hash uint32 // 类型的Hash值 tflag tflag // 类型的Tags align uint8 // 结构体内对齐 fieldalign uint8 // 结构体作为field时的对齐 kind uint8 // 类型编号 定义于runtime/typekind.go alg *typeAlg // 类型元方法 存储hash和equal两个操作。map key便使用key的_type.alg.hash(k)获取hash值 gcdata *byte // GC相关信息 str nameOff // 类型名字的偏移 ptrToThis typeOff } // iface type iface struct { tab *itab data unsafe.Pointer } // 非空接口的类型信息 type itab struct { inter *interfacetype // 接口定义的类型信息 _type *_type // 接口实际指向值的类型信息 link *itab bad int32 inhash int32 fun [1]uintptr // 接口方法实现列表，即函数地址列表，按字典序排序 } // 非空接口类型，接口定义，包路径等。 type interfacetype struct { typ _type pkgpath name mhdr []imethod // 接口方法声明列表，按字典序排序 } // 接口的方法声明 type imethod struct { name nameOff // 方法名 ityp typeOff // 描述方法参数返回值等细节 } 非空interface与eface不同的，所有空interface的结构是一样的，而非空interface每个都不一样，因为彼此定义的方法可以不一样的，所以相对eface，iface的定义复杂多。 具体的可以参考: https://www.jianshu.com/p/30e5cb755529 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:6","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"7. reflect t := reflect.TypeOf(stru).Elem() for i := 0; i \u003c t.NumField(); i++ { // 获取Tag t.Field(i).Name, t.Field(i).Tag.Get(\"json\"), t.Field(i).Tag.Get(\"otherTag\") } //reflect.TypeOf(stru).Elem()获取指针指向的值对应的结构体内容。 //NumField()可以获得该结构体的含有几个字段。 //遍历结构体内的字段，通过t.Field(i).Tag.Get(\"json\")可以获取到tag为json的字段。 json包里不能导出私有变量的tag是因为json包里认为私有变量为不可导出的Unexported，所以跳过获取名为json的tag的内容 动态类型判断: 类型开关是在运行时检查变量类型的最佳方式 //1. 类型识别 var data interface{} = \"hello\" strValue, ok := data.(string) if ok { fmt.Printf(\"%s is string type\\n\", strValue) } //2. 类型获取 var str string = \"hello\" fmt.Println(reflect.TypeOf(str)) //3. 类型判断 func typeJudge(x interface{}) { switch x.(type){ case int,int8,int64,int16,int32,uint,uint8,uint16,uint32,uint64: fmt.Println(\"整型变量\") case float32,float64: fmt.Println(\"浮点型变量\") case []byte,[]rune,string: fmt.Println(\"字符串变量\") default: fmt.Println(\"不清楚...\") } } ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:7","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"8. new 和make的区别 new(T) 返回的是 T 的指针：new(T) 为一个 T 类型新值分配空间并将此空间初始化为 T类型的零值，返回的是新值的地址，也就是 T 类型的指针 *T，该指针指向 T 的新分配的零值。 make 只能用于 slice,map,channel，返回值是经过初始化之后的 T 的引用 make 分配空间后，会进行初始化 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:8","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"9.struct能不能比较 ​ go中的struct能不能比较取决于struct内部存储的数据，如果struct中的字段都是可比较的，那么该struct就是可比较的，如果其中的字段是不可比较的，那么该struct不可比较。slice,map就无法比较。 struct字段顺序要一致才能比较 数组的长度是类型的一部分，如果数组长度不同，无法比较。 interface{}类型的比较包含该接口变量存储的值和值的类型两部分组成，分别称为接口的动态类型和动态值。只有动态类型和动态值都相同时，两个接口变量才相同。 slice在go设计之初为了和数组区分，不让其可以比较（浅层指针比较没有意义） 1、引用类型，比较地址没有意义。 2、切片有len，cap，比较的维度不好衡量，因此go设计的时候就不允许切片可比较。 3、map的value, 函数均可以包含slice,因而均不可比较 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:9","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"10. defer defer关键字定义的函数是在调用函数返回之后执行，而不是在代码块退出之后执行。defer的执行顺序是先创建的后执行。看做是一个 FILO(First In Last Out) 栈. 所有传入defer函数的参数都是在创建的时候预先计算处理的，而不是调用函数退出的时候计算的 defer等到包含它的程序返回时(包含它的函数执行了return语句、运行到函数结尾自动返回、对应的goroutine panic）defer函数才会被执行。通常用于资源释放、打印日志、异常捕获等 defer 关键字对应的 runtime.deferproc 会将延迟调用函数与调用方所在 Goroutine 进行关联。所以当程序发生崩溃时只会调用当前 Goroutine 的延迟调用函数 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:10","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"11. init函数 整个golang程序初始化顺序 先调用osinit，再调用schedinit，创建就绪队列并新建一个G，接着就是mstart 即设置好本地线程存储，设置好main函数参数，根据环境变量GOMAXPROCS设置好使用的procs，初始化调度器和内存管理等等。 main.main之前的准备 sysmon :Go语言的runtime库会初始化一些后台任务，其中一个任务就是sysmon. 它由物理线程运行.主要处理两个事件：对于网络的epoll以及抢占式调度的检测. 释放闲置超过5 分钟的 span 物理内存; 如果超过2 分钟没有垃圾回收，强制执行; 将长时间未处理的 netpoll 添加到全局队列; 向长时间运行的 G 任务发出抢占调度(超过10ms的 g，会进行 retake); 收回因 syscall 长时间阻塞的 P; scavenger: 只是由goroutine运行.用于执行heap的内存回收给os ​ 先于main函数执行，实现包级别的一些初始化操作 ​ 主要作用: 初始化不能采用初始化表达式初始化的变量; 程序运行前的注册 实现sync.Once功能 ​ 主要特点: init函数先于main函数自动执行，不能被其他函数调用； init函数没有输入参数、返回值； 每个包可以有多个init函数； 包的每个源文件也可以有多个init函数，这点比较特殊； 同一个包的init执行顺序，golang没有明确定义，编程时要注意程序不要依赖这个执行顺序 不同包的init函数按照包导入的依赖关系决定执行顺序 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:11","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"12.包的循环引用 为什么不允许循环引用 ​ 加快编译速度、规范框架设计，使项目结构更加清晰明了 解决办法: 1. mvc 结构,将包规划好 1. 新建公共接口包(父包), 将需要循环调用的函数或方法抽象为接口 1. 新建公共组合包(子包), 在组合包中组合调用 1. 全局存储需要相互依赖的函数, 通过关键字进行调用 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:12","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"13. SELECT select可以用来等待多个channel的可读可写，其中select中的case表达式必须都是channel的读写操作。 当存在default时，select执行的就是非阻塞收发，当不存在时，必须等待某一个channel可读或可写。 当多个channel都可读可写时，会随机选择一个分支。 如果有一个channel已关闭,则每次都执行到这个case; 如果只有一个case,则出现死循环. var c1, c2, c3 chan int var i1, i2 int select { case i1 = \u003c-c1: fmt.Printf(\"received \", i1, \" from c1\\n\") case c2 \u003c- i2: fmt.Printf(\"sent \", i2, \" to c2\\n\") case i3, ok := (\u003c-c3): // same as: i3, ok := \u003c-c3 if ok { fmt.Printf(\"received \", i3, \" from c3\\n\") } else { fmt.Printf(\"c3 is closed\\n\") } default: fmt.Printf(\"no communication\\n\") } x, ok := \u003c-ch,如果ch已经关闭,则ok为false,置ch为nil,则可以继续阻塞. 保证case的优先级 for { select { case \u003c-stopCh: return case job1 := \u003c-ch1: fmt.Println(job1) case job2 := \u003c-ch2: priority: // label for { select { case job1 := \u003c-ch1: fmt.Println(job1) default: break priority } } fmt.Println(job2) } } ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:13","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"14. for range 循环 { for_temp := slice1 len_temp := len(for_temp) for index_temp := 0; index_temp \u003c len_temp; index_temp++ { value_temp := for_temp[index_temp] // index = index_temp // value = value_temp // origin body } } // 新的语句块结束 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:14","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"15. Panic和Recover panic ​ panic的作用是制造一次宕机，宕机就代表程序运行终止，但是已经“生效”的(当前 Goroutine )延迟函数仍会执行（即已经压入栈的defer延迟函数，panic之前的）。 先调用panic对应的gopanic函数, 由gopanic函数去执行延迟函数，所以“先触发panic函数的执行，然后调用延迟函数”是正确的。 // 嵌套崩溃 func main() { defer fmt.Println(\"in main\") defer func() { defer func() { panic(\"panic again and again\") }() panic(\"panic again\") }() panic(\"panic once\") } $ go run main.go in main panic: panic once panic: panic again panic: panic again and again goroutine 1 [running]: ... exit status 2 recover ​ recover 只有在发生 panic 之后调用才会生效。然而在上面的控制流中，recover 是在 panic 之前调用的，并不满足生效的条件，所以需要在 defer 中使用 recover 关键字。 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:15","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"16. golang函数调用规则 通过堆栈传递参数，入栈的顺序是从右到左，而参数的计算是从左到右 函数返回值通过堆栈传递并由调用者预先分配内存空间； 调用函数时都是传值，接收方会对入参进行复制再计算； ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:16","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"17. go相比于c++线程的优势 开销更小 切换更方便 C线程的上下文切换涉及到模式转换-从用户态到内核态 go的协程中的上下文切换只是在用户态的操作 用户可控制（用户态） 高级调度策略: 任务窃取和减少阻塞 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:1:17","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"进阶原理 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:2:0","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"1. GMP模型和golang调度原理 ​ go中调度采用GMP算法，G表示一个goroutine，M表示machine一个真实的线程，P表示processor表示一个调度器 P由启动时环境变量 $GOMAXPROCS 或者是由 runtime 的方法 GOMAXPROCS() 决定。这意味着在程序执行的任意时刻都只有 $GOMAXPROCS 个 goroutine 在同时运行。最大256 M的最大限制是10000个，但是内核很难支持这么多的线程数，所以这个限制可以忽略; 一般为CPU数 在P没有足够的M绑定运行时,则会创建一个M;每次创建一个M都会同步创建一个G0，它负责调度其它的G，每个M都有一个G0 每个 P有个局部队列，局部队列保存待执行的 goroutine(流程2)，当 M绑定的 P的的局部队列已经满了之后就 会把 goroutine 放到全局队列(流程2-1) 每个 P和一个 M绑定，M是真正的执行 P中 goroutine 的实体(流程3)，M 从绑定的 P中的局部队列获取 G来 执行 当 M绑定的 P的局部队列为空时，M会从全局队列获取到本地队列来执行 G(流程3.1)，当从全局队列中没有获取到可执行的 G时候，M会从其他 P 的局部队列中偷取 G来执行(流程3.2)，这种从其他 P偷的方式称为 work stealing 当 G因系统调用(syscall)阻塞时会阻塞 M，此时 P会和 M解绑即 hand off，并寻找新的 idle 的 M，若没有 idle 的 M就会新建一个 M(流程5.1)。 当 G因 channel 或者 network I/O 阻塞时，不会阻塞 M，M会寻找其他 runnable 的 G;当阻塞的 G恢复后会重新进入 runnable 进入 P队列等待执行(流程5.3) Work stealing ​ 当本线程无可运行的 G 时，尝试从其他线程绑定的 P 偷取 G，而不是销毁线程。 Hand off 本线程因为 G 进行系统调用阻塞时，线程释放绑定的 P，把 P 转移给其他空闲的线程执行。 利用并行：GOMAXPROCS 设置 P 的数量，最多有 GOMAXPROCS 个线程分布在多个 CPU 上同时运行。GOMAXPROCS 也限制了并发的程度，比如 GOMAXPROCS = 核数/2，则最多利用了一半的 CPU 核进行并行。 抢占：在 coroutine 中要等待一个协程主动让出 CPU 才执行下一个…在 Go 中，一个 goroutine 最多占用 CPU 10ms，防止其他 goroutine 被饿死，这就是 goroutine 不同于 coroutine 的一个地方。 如果没有P或怎样? 调度器把 G都分配到 M上，不同的 G在不同的 M并发运行时，都需要向系统申请资源，比如堆栈内存等，因为资源 是全局的，就会因为资源竞争照成很多性能损耗。 GMP 调度过程中存在哪些阻塞 I/O, select block on syscall channel 等待锁 runtime.Gosched() 抢占式调度 sysmon。这个函数会周期性地做epoll操作，同时它还会检测每个P是否运行了较长时间。如果检测到某个P状态处于syscall超过了一个sysmon的时间周期(20us)，并且还有其它可运行的任务，则切换P。 如果检测到某个P的状态为running，并且它已经运行了超过10ms，则会将P的当前的G的stackguard设置为StackPreempt。这个操作其实是相当于加上一个标记，通知这个G在合适时机进行调度。 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:2:1","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"2. 垃圾回收(GC) 垃圾回收常用方法 ​ 1. 引用计数(reference counting) ​ 如C++中的智能指针:shard_ptr; 优点：简单直接，回收速度快 缺点：需要额外的空间存放计数，无法处理循环引用的情况； 标记-清除(mark and sweep) ​ 标记出所有不需要回收的对象，在标记完成后统一回收掉所有未被标记的对象。 优点：简单直接，速度快，适合可回收对象不多的场景 缺点：会造成不连续的内存空间（内存碎片），导致有大的对象创建的时候，明明内存中总内存是够的，但是空间不是连续的造成对象无法分配； 分代搜集(generation) ​ java的jvm 就使用的分代回收的思路。在面向对象编程语言中，绝大多数对象的生命周期都非常短。分代收集的基 本思想是，将堆划分为两个或多个称为代(generation)的空间。新创建的对象存放在称为新生代(young generation)中(一般来说，新生代的大小会比 老年代小很多)，随着垃圾回收的重复执行，生命周期较⻓的对 象会被提升(promotion)到老年代中(这里用到了一个分类的思路，这个是也是科学思考的一个基本思路)。 ​ 因此，新生代垃圾回收和老年代垃圾回收两种不同的垃圾回收方式应运而生，分别用于对各自空间中的对象执行垃 圾回收。新生代垃圾回收的速度非常快，比老年代快几个数量级，即使新生代垃圾回收的频率更高，执行效率也仍 然比老年代垃圾回收强，这是因为大多数对象的生命周期都很短，根本无需提升到老年代。 GOLANG的GC策略 ​ golang采用无分代（对象没有代际之分）、不整理（回收过程中不对对象进行移动与整理）、并发（与用户代码并发执行）的三色标记清扫算法。 ​ 原因: golang的内存分配算法tcmalloc，基本上不会造成内存碎片，因此不需要使用对象整理。 golang对于存活时间短的对象直接分配在栈上面，go程死亡后栈会被回收，不需要gc的参与。 Go 以 STW 为界限，可以将 GC 划分为五个阶段：：栈扫描（开始时STW）;第一次标记（并发）;第二次标记（STW）;清除（并发）,归还 三色标记清扫法 white，grep，black;白色为需要清理的数据，黑色则不要清理。从根对象（全局变量、执行栈、寄存器(主要是指针)）开始循环，能访问到的标记为灰色，然后从灰色队列开始遍历，自身变成黑色。后续没有访问到的直接清理掉。 没有STW的三色标记法 条件1: 一个白色对象被黑色对象引用 (白色被挂在黑色下) 条件2: 灰色对象与它之间的可达关系的白色对象遭到破坏 (灰色同时丢了该白色) 当以上两个条件同时满足时, 就会出现对象丢失现象! 屏障保护 为了减少STW的影响,又防止三色标记法出现对象丢失现象,出现屏障保护技术; 插入写屏障 ​ 垃圾收集器将根对象指向 A 对象标记成黑色并将 A 对象指向的对象 B 标记成灰色；用户程序修改 A 对象的指针，将原本指向 B 对象的指针指向 C 对象，这时触发写屏障将 C 对象标记成灰色；一种相对保守的屏障技术，它会将有存活可能的对象都标记成灰色以满足强三色不变性. ​ 写屏障只会针对堆进行限制. 删除写屏障 ​ 垃圾收集器将根对象指向 A 对象标记成黑色并将 A 对象指向的对象 B 标记成灰色；用户程序将 A 对象原本指向 B 的指针指向 C，触发删除写屏障，但是因为 B 对象已经是灰色的，所以不做改变；用户程序将 B 对象原本指向 C 的指针删除，触发删除写屏障，白色的 C 对象被涂成灰色； ​ 缺点是开始收集器时需要STW快照全局对象 混合写屏障 操作流程: ​ 1、GC开始将栈上的对象全部扫描并标记为黑色(之后不再进行第二次重复扫描，无需STW)， ​ 2、GC期间，任何在栈上创建的新对象，均为黑色。 ​ 3、被删除的对象标记为灰色。(删除写屏障) ​ 4、被添加的对象标记为灰色。(插入写屏障) 该写屏障会将被覆盖的对象标记成灰色并在当前栈没有扫描时将新对象也标记成灰色; 只需要针对堆内存扫描即可. GC触发机制 主动: 通过调用 runtime.GC 来触发 GC，此调用阻塞式地等待当前 GC 运行完毕。 被动: 使用系统监控(sysmon)，当超过两分钟没有产生任何 GC 时，强制触发 GC。 使用步调（Pacing）算法，其核心思想是控制内存增长的比例。(步调算法可以通过gogc传参设置量控制gc的时间。也是go中唯一对外开放的配置gc的参数。默认值为100，也就是达到百分百后触发gc机制) GC细节 增量垃圾收集 ​ 增量地标记和清除垃圾，降低应用程序暂停的最长时间； ​ 传统的垃圾收集算法会在垃圾收集的执行期间暂停应用程序，一旦触发垃圾收集，垃圾收集器会抢占 CPU 的使用权占据大量的计算资源以完成标记和清除工作，然而很多追求实时的应用程序无法接受长时间的 STW。增量式（Incremental）的垃圾收集是减少程序最长暂停时间的一种方案，它可以将原本时间较长的暂停时间切分成多个更小的 GC 时间片，虽然从垃圾收集开始到结束的时间更长了，但是这也减少了应用程序暂停的最大时间。 并发垃圾收集 ​ 利用多核的计算资源，在用户程序执行时并发标记和清除垃圾； GC 如何调优 通过 go tool pprof 和 go tool trace 等工具 控制内存分配的速度，限制 goroutine 的数量，从而提高赋值器对 CPU 的利用率。 减少并复用内存，例如使用 sync.Pool 来复用需要频繁创建临时对象，例如提前分配足够的内存来降低多余的 拷贝。 需要时，增大 GOGC 的值，降低 GC 的运行频率。 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:2:2","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"3. 内存模型和内存管理 内存逃逸 ​ golang程序变量会携带有一组校验数据，用来证明它的整个生命周期是否在运行时完全可知。如果变量通过了这些校验，它就可以在栈上分配。否则就说它 逃逸 了，必须在堆上分配 内存逃逸的情况: 在方法内把局部变量指针返回 发送指针或带有指针的值到 channel 中 在一个切片上存储指针或带指针的值 slice 的背后数组被重新分配了，因为 append 时可能会超出其容量( cap );slice 初始化的地方在编译时是可以知道的，它最开始会在栈上分配。如果切片背后的存储要基于运行时的数据进行扩充，就会在堆上分配。 **在 interface 类型上调用方法。**在 interface 类型上调用方法都是动态调度的 —— 方法的真正实现只能在运行时知道。 查看内存逃逸的情况: go build -gcflags=-m main.go 避免内存逃逸 Noescape函数, 可以在逃逸分析中隐藏一个指针。让这个指针在逃逸分析中不会被检测为逃逸。 func noescape(p unsafe.Pointer) unsafe.Pointer { x := uintptr(p) return unsafe.Pointer(x ^ 0) } noescape() 函数的作用是遮蔽输入和输出的依赖关系。使编译器不认为 p 会通过 x 逃逸， 因为 uintptr() 产生的引用是编译器无法理解的。 内置的 uintptr 类型是一个真正的指针类型，但是在编译器层面，它只是一个存储一个 指针地址 的 int 类型。代码的最后一行返回 unsafe.Pointer 也是一个 int。 闭包 闭包是由函数及其相关引用环境组合而成的实体(即：闭包=函数+引用环境)。 func f(i int) func() int { return func() int { i++ return i } } 不可在栈上分配: 变量i是函数f中的局部变量，假设这个变量是在函数f的栈中分配的，是不可以的。因为函数f返回以后，对应的栈就失效了，f返回的那个函数中变量i就引用一个失效的位置了。所以闭包的环境中引用的变量不能够在栈上分配。 因此以上代码在汇编中就类似于: type Closure struct { F func()() i *int } 在堆中创建结构体, 将函数地址赋值给F, 闭包环境的局部变量在堆上开辟空间,写值后再将地址赋值给i; 返回闭包时并不是单纯返回一个函数，而是返回了一个结构体，记录下函数返回地址和引用的环境中的变量地址 栈空间管理 ​ Go语言的运行环境(runtime)会在goroutine需要的时候动态地分配栈空间，而不是给每个goroutine分配固定大小的内存空间。这样就避免了需要程序员来决定栈的大小。当创建一个goroutine的时候，它会分配一个8KB的内存空间来给goroutine的栈使用。 分段栈 ​ 当检测到函数需要更多栈时，分配一块新栈，旧栈和新栈使用指针连接起来，函数返回就释放。 每个Go函数的开头都有一小段检测代码。这段代码会检查我们是否已经用完了分配的栈空 间。如果是的话，它会调用 morestack 函数。 morestack 函数分配一块新的内存作为栈空间，并且在这块栈空间 的底部填入各种信息(包括之前的那块栈地址)。在分配了这块新的栈空间之后，它会重试刚才造成栈空间不足的函数。这个过程叫做栈分裂(stack split). 在新分配的栈底有个lessstack的函数指针; 当我们从那个函数返回时，它会跳转到 lessstack 。 lessstack 函 数会查看在栈底部存放的数据结构里的信息，然后调整栈指针(stack pointer)。这样就完成了从新的栈块到老的 栈块的跳转。接下来，新分配的这个块栈空间就可以被释放掉了。 问题: 多次循环调用同一个函数会出现“hot split”问题, 即如果函数产生的返回在一个循环或者递归中, 会频繁的alloc/free,导致严重性能问题 每次分配和释放都要额外消耗 连续栈 连续栈的实现方式：当检测到需要更多栈时，分配一块比原来大一倍的栈，把旧栈数据copy到新栈，释放旧栈 栈的扩缩容何时触发? goroutine运行并用完栈空间的时候，与之前的方法一样，栈溢出检查会被触发 栈的扩缩容大小 扩容为原来的两倍,缩容为原来的1/2 栈的扩缩容过程中做了哪些事? 重新申请一块新栈，然后把旧栈的数据复制到新栈。协程占用的物理内存完全被替换了，而Go在运行时会把指针保存到内存里面，例如：gp.sched.ctxt ，gp._defer ，gp._panic，包括函数里的指针。这部分指针值会被转换成整数型uintptr，然后 + delta进行调整 如果栈空间发现不够用，会调用stackalloc分配一块新的栈，大小比原来大一倍进行扩容 ;栈的缩容主要是发生在GC期间. 内存泄漏 字符串截取: 解决办法: string和[]byte 转化 切片截取 解决办法: append 没有重置丢失的子切片元素中的指针: 原切片元素为指针类型，原切片被截取后，丢失的子切片元素中的指针元素未被置空，导致内存泄漏 解决办法:元素置空 函数数组传参: 由于数组为值类型,赋值和函数传参会复制整个数组; 如果数组较大,短时间内传递多次,会消耗大量内存又来不及gc,就会产生临时性的内存泄漏 解决办法:采用指针传递、使用切片 gorouting :有些编码不当的情况下，goroutine被长期挂住，导致该协程中的内存也无法被释放，就会造成永久性的内存泄漏。例如协程结束时协程中的channel没有关闭，导致一直阻塞；例如协程中有死循环 可见并发和sync包的使用 定时器: 定时器未到触发时间，该定时器不会被gc回收，从而导致临时性的内存泄漏，而如果定时器一直在创建，那么就造成了永久性的内存泄漏了 解决办法:创建timer定时器，每次需要启动定时器的时候，使用Reset方法重置定时器 外部资源没有办法GC的: 如打开的文件句柄 内存泄漏实例 func main() { num := 6 for index := 0; index \u003c num; index++ { resp, _ := http.Get(\"https://www.baidu.com\") _, _ = ioutil.ReadAll(resp.Body) } fmt.Printf(\"此时goroutine个数= %d\\n\", runtime.NumGoroutine()) }// 没有执行resp.Body.Close(), 一共泄漏了3个goroutine 虽然执行了 6 次循环，而且每次都没有执行 Body.Close() ,就是因为执行了ioutil.ReadAll()把内容都读出来了，连接得以复用，因此只泄漏了一个读goroutine和一个写goroutine，最后加上main goroutine，所以答案就是3个goroutine 正常情况下我们的代码都会执行 ioutil.ReadAll()，但如果此时忘了 resp.Body.Close()，确实会导致泄漏。但如果你调用的域名一直是同一个的话，那么只会泄漏一个 读goroutine 和一个写goroutine，这就是为什么代码明明不规范但却看不到明显内存泄漏的原因。 内存对齐 一个非空结构体包含有尾部size为0的变量(字段)，如果不给它分配内存，那么该变量(字段)的指针地址将指向一个超出该结构体内存范围的内存空间。这可能会导致内存泄漏，或者在内存垃圾回收过程中，程序crash掉。 为什么对齐? 操作系统并非一个字节一个字节访问内存，而是按2, 4, 8这样的字长来访问。当被访问的数据长度为 n 字节且该数据地址为n字节对齐，那么操作系统就可以高效地一次定位到数据，无需多次读取、处理对齐运算等额外操作. struct 的对齐是：如果类型 t 的对齐保证是 n，那么类型 t 的每个值的地址在运行时必须是 n 的倍数。 struct 内字段如果填充过多，可以尝试重排，使字段排列更紧密，减少内存浪费 零大小字段要避免作为 struct 最后一个字段，会有内存浪费(零大小也会补一个对齐保证的长度,防止指针错误,内存泄漏) 对齐规则: 对于任意类型的变量 x ，unsafe.Alignof(x) 至少为 1。 对于 struct 结构体类型的变量 x，计算 x 每一个字段 f 的 unsafe.Alignof(x.f)，unsafe.Alignof(x) 等于其中的最大值的倍数。 对于 array 数组类型的变量 x，unsafe.Alignof(x) 等于构成数组的元素类型的对齐倍数。 没有任何字段的空 struct{} 和没有任何元素的 array 占据的内存空间大小为 0，不同的大小为 0 的变量可能指向同一块地址。 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:2:3","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"4. 并发和sync包 Data Race ​ 同步访问共享数据是处理数据竞争的一种有效的方法. 可以使用 go run - race 或者 go build -race来进行静态检测。其在内部的实现是,开启多个协程执行同一个命令， 并且记录下每个变 量的状态. go test -race mypkg // 测试包 go run -race mysrc.go // 编译和运行程序 go build -race mycmd // 构建程序 go install -race mypkg // 安装程序 解决数据竞争的方法: 互斥锁: sync.Mutex、sync.WaitGroup 通道: channel ,channel的效率是高于互斥锁的 并发模型 通过channel通知实现并发控制 通过sync包中的WaitGroup实现并发控制 a. Add(), 可以添加或减少 goroutine的数量. b. Done(), 相当于Add(-1). c. Wait(), 执行后会堵塞主线程，直到WaitGroup 里的值减至0. 注意,在 WaitGroup 第一次使用后，不能被拷贝 func main(){ wg := sync.WaitGroup{} for i := 0; i \u003c 5; i++ { wg.Add(1) go func(wg sync.WaitGroup, i int) { fmt.Printf(\"i:%d\", i) wg.Done() }(wg, i) } wg.Wait() fmt.Println(\"exit\") } // error: all goroutines are asleep - deadlock! 因为 wg 给拷⻉传递到了 goroutine 中，导致只有 Add 操作，其实 Done操作是在 wg 的副本执行的。 可以将 传入类型改为 *sync.WaitGroup, 或者使用闭包 Context 上下文 context 包主要是用来处理多个 goroutine 之间共享数据，及多个 goroutine 的管理。Context 对象是线程安全的，你可以把一个 Context 对象传递给任意个数的 gorotuine，对它执行取消 操作时， 所有 goroutine 都会接收到取消信号。 web编程中，一个请求对应多个goroutine之间的数据交互、同步数据，主要是共享数据，如token 超时控制：请求被取消或是处理时间太长，这有可能是使用者关闭了浏览器或是已经超过了请求方规定的超时时间，请求方直接放弃了这次请求结果。这时，所有正在为这个请求工作的 goroutine 需要快速退出，因为它们的“工作成果”不再被需要了。在相关联的 goroutine 都退出后，系统就可以回收相关的资源。 上下文控制 CAS Compare And Swap，直译就是比较交换;是一种实现并发算法时常用到的技术. 作用是让 CPU先进行比较两 个值是否相等，然后原子地更新某个位置的值，其实现方式是给予硬件平台的汇编指令， func CompareAndSwapUint32(addr *uint32, old, new uint32) (swapped bool) 缺陷: CAS在共享资源竞争比较激烈的时候，每个goroutine会容易处于自旋状态，影响效率，在竞争激烈的时候推荐使用锁。 无法解决ABA问题 ABA问题是无锁结构实现中常见的一种问题，可基本表述为： 进程P1读取了一个数值A P1被挂起(时间片耗尽、中断等)，进程P2开始执行 P2修改数值A为数值B，然后又修改回A P1被唤醒，比较后发现数值A没有变化，程序继续执行。 Sync包 互斥锁: sync.Mutex //Mutex 是互斥锁， 零值是解锁的互斥锁， 首次使用后不得复制互斥锁。 type Mutex struct { state int32 sema uint32 } //Locker表示可以锁定和解锁的对象。 type Locker interface { Lock() Unlock() } //锁定当前的互斥量 //如果锁已被使用，则调用goroutine //阻塞直到互斥锁可用。 func (m *Mutex) Lock() //对当前互斥量进行解锁 //如果在进入解锁时未锁定m，则为运行时错误。 //锁定的互斥锁与特定的goroutine无关。 //允许一个goroutine锁定Mutex然后安排另一个goroutine来解锁它。 func (m *Mutex) Unlock() Mutex的几种状态: mutexLocked —表示互斥锁的锁定状态; mutexWoken —表示从正常模式被从唤醒; mutexStarving —当前的互斥锁进入饥饿状态; Mutex的正常模式和饥饿模式: 正常模式**(**非公平锁): 正常模式下，所有等待锁的 goroutine 按照 FIFO(先进先出)顺序等待。唤醒的 goroutine 不会直接拥有锁，而是会 和新请求锁的 goroutine 竞争锁的拥有。但是和正在使用cpu的goroutine相比很大可能失败. 饥饿模式**(**公平锁): 一个等待的 goroutine 超过1ms没有获取锁,或者当前队列只剩下一个 g 的时候那么它将会把锁转 变为饥饿模式。 ​ 饥饿模式下，直接由 unlock 把锁交给等待队列中排在第一位的 G(队头)，同时，饥饿模式下，新进来的 G不会参与 抢锁也不会进入自旋状态，会直接进入等待队列的尾部,这样很好的解决了老的 g 一直抢不到锁的场景 自旋锁: 循环等待锁的释放,一直处于内核态,不进行内核态和用户态切换. 锁已被占用，并且锁不处于饥饿模式 积累的自旋次数小于最大自旋次数(active_spin=4)。 cpu 核数大于1。 有空闲的 P 当前 goroutine 所挂载的 P下，本地待运行队列为空。 ​ 读写锁: sync.RWMutex 1 多个写操作之间是互斥的 2 写操作与读操作之间也是互斥的 3 多个读操作之间不是互斥的 // RWMutex是一个读/写互斥锁，可以由任意数量的读操作或单个写操作持有。 // RWMutex的零值是未锁定的互斥锁。 //首次使用后，不得复制RWMutex。 //如果goroutine持有RWMutex进行读取而另一个goroutine可能会调用Lock，那么在释放初始读锁之前， goroutine不应该期望能够获取读锁定。 //特别是，这种禁止递归读锁定。 这是为了确保锁最终变得可用; 阻止的锁定会阻止新读操作获取锁定。 type RWMutex struct { w Mutex //如果有待处理的写操作就持有 uint32 writerSem int32 // 写操作等待读操作完成的信号量 readerSem uint32 //读操作等待写操作完成的信号量 readerCount int32 // 待处理的读操作数量 readerWait int32 // number of departing readers } //对读操作的锁定 func (rw *RWMutex) RLock() //对读操作的解锁 func (rw *RWMutex) RUnlock() //对写操作的锁定 func (rw *RWMutex) Lock() //对写操作的解锁 func (rw *RWMutex) Unlock() //返回一个实现了sync.Locker接口类型的值，实际上是回调rw.RLock and rw.RUnlock. func (rw *RWMutex) RLocker() Locker ​ 通过记录 readerCount 读锁的数量来进行控制，当有一个写锁的时候，会将读锁数量设置为负数1«30。目的是让 新进入的读锁等待写锁之后释放通知读锁。同样的写锁也会等等待之前的读锁都释放完毕，才会开始进行后续的操 作。而等写锁释放完之后，会将值重新加上1«30,并通知刚才新进入的读锁(rw.readerSem)，两者互相限制。 RWMutex 的读锁不要用于递归调用，比较容易产生死锁。 写锁被解锁后，所有因操作锁定读锁而被阻塞的 goroutine 会被唤醒，并都可以成功锁定读锁。 读锁被解锁后，在没有被其他读锁锁定的前提下，所有因操作锁定写锁而被阻塞的 goroutine，其中等待时间 最⻓的一个 goroutine 会被唤醒。 安全锁: Sync.Map golang中的sync.Map是并发安全的，其实也就是sync包中golang自定义的一个名叫Map的结构体。它通过空间换时间的方式，使用 read 和 dirty 两个 map 来进行读写分离，降低锁时间来提高效率。 type Map struct { mu Mutex // 该锁用来保护dirty read atomic.Value // readOnly// 存读的数据，因为是atomic.value类型，只读类型，所以它的读是并发安全的 dirty map[interface{}]*entry //包含最新的写入的数据，并且在写的时候，会把read中未被删除的数据拷⻉到该dirty中，因为是普通的map存在并发安全问题，需要用到上面的mu字段。 misses int // 从read读数据失败的时候，会将该字段+1，当等于len(misses)的时候，会将dirty拷⻉到read中(从而提升读的性能)。 } func (m *Map) Delete(key i","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:2:4","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"5. golang编译过程 go build -gcflags -S main.go 可以生成中间的汇编代码 词法分析：源码翻译成token（分词） 语法分析：将token序列输出成AST结构 词义分析： 类型检查（类型推断等） 中间码生产：对于不同的操作系统和硬件进行处理；提高后端编译的重用 代码优化： 并行性，充分利用现在多核计算机的特性 流水线，cpu 有时候在处理 a 指令的时候，还能同时处理 b 指令 指令的选择，为了让 cpu 完成某些操作，需要使用指令，但是不同的指令效率有非常大的差别，这里会进行指令优化 利用寄存器与高速缓存，我们都知道 cpu 从寄存器取是最快的，从高速缓存取次之。这里会进行充分的利用 机器码生产： 先生成汇编代码，其汇编器使用GOARCH参数进行初始化，然后调用对应架构便携的特定方法来生成机器码，从而跨平台。 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:2:5","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"},{"categories":[],"content":"gin 框架的好处是什么？ 快速：基于 Radix 树的路由,性能非常强大。 支持中间件：内置许多中间件，如 Logger,Gzip,Authorization 等。 崩溃恢复：可以捕捉 panic 引发的程序崩溃，使 Web 服务可以一直运行。 JSON 验证：可以验证请求中 JSON 数据格式。 多种数据渲染方式：支持 HTML、JSON、YAML、XML 等数据格式的响应。 扩展性：非常简单扩展中间件。 ","date":"2022-08-21","objectID":"/golang%E5%85%AB%E8%82%A1%E6%96%87/:3:0","tags":[],"title":"Golang八股文","uri":"/golang%E5%85%AB%E8%82%A1%E6%96%87/"}]