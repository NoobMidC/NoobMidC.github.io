<!DOCTYPE html>
<html lang="zh-CN">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <title>Kafka - cx玄烨0&#39; Blog</title><meta name="Description" content="专注于golang, 云原生开发"><meta property="og:title" content="Kafka" />
<meta property="og:description" content="" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://noobmid.github.io/kafka/" /><meta property="og:image" content="https://noobmid.github.io/logo.png"/><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-08-28T12:50:11+08:00" />
<meta property="article:modified_time" content="2022-08-28T12:50:11+08:00" /><meta property="og:site_name" content="cx玄烨0&#39;s Blog" />

<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://noobmid.github.io/logo.png"/>

<meta name="twitter:title" content="Kafka"/>
<meta name="twitter:description" content=""/>
<meta name="application-name" content="我的网站">
<meta name="apple-mobile-web-app-title" content="我的网站"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="https://noobmid.github.io/kafka/" /><link rel="prev" href="https://noobmid.github.io/elasticsearch/" /><link rel="next" href="https://noobmid.github.io/grpc/" /><link rel="stylesheet" href="/css/style.min.css"><link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css"></noscript><link rel="preload" href="https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css"></noscript><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "Kafka",
        "inLanguage": "zh-CN",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https:\/\/noobmid.github.io\/kafka\/"
        },"image": ["https:\/\/noobmid.github.io\/images\/Apple-Devices-Preview.png"],"genre": "posts","wordcount":  15555 ,
        "url": "https:\/\/noobmid.github.io\/kafka\/","datePublished": "2022-08-28T12:50:11+08:00","dateModified": "2022-08-28T12:50:11+08:00","publisher": {
            "@type": "Organization",
            "name": "xxxx","logo": {
                    "@type": "ImageObject",
                    "url": "https:\/\/noobmid.github.io\/images\/avatar.png",
                    "width":  2838 ,
                    "height":  2716 
                }},"author": {
                "@type": "Person",
                "name": "cx玄烨0"
            },"description": ""
    }
    </script></head>
    <body data-header-desktop="normal" data-header-mobile="auto"><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="cx玄烨0&#39; Blog"><span id="id-1" class="typeit"></span></a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/posts/"> 所有文章 </a><a class="menu-item" href="/tags/"> 标签 </a><a class="menu-item" href="/categories/"> 分类 </a><a class="menu-item" href="/categories/documentation/"> 文档 </a><a class="menu-item" href="/about/"> 关于 </a><a class="menu-item" href="https://github.com/noobmid" title="GitHub" rel="noopener noreffer" target="_blank"><i class='fab fa-github fa-fw' aria-hidden='true'></i>  </a><span class="menu-item delimiter"></span><span class="menu-item search" id="search-desktop">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-desktop">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="Search">
                            <i class="fas fa-search fa-fw" aria-hidden="true"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="Clear">
                            <i class="fas fa-times-circle fa-fw" aria-hidden="true"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-desktop">
                            <i class="fas fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
                        </span>
                    </span><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                    <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
                </a></div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="cx玄烨0&#39; Blog"><span id="id-2" class="typeit"></span></a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><div class="search-wrapper">
                    <div class="search mobile" id="search-mobile">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-mobile">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="Search">
                            <i class="fas fa-search fa-fw" aria-hidden="true"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="Clear">
                            <i class="fas fa-times-circle fa-fw" aria-hidden="true"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-mobile">
                            <i class="fas fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
                        </span>
                    </div>
                    <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
                        Cancel
                    </a>
                </div><a class="menu-item" href="/posts/" title="">所有文章</a><a class="menu-item" href="/tags/" title="">标签</a><a class="menu-item" href="/categories/" title="">分类</a><a class="menu-item" href="/categories/documentation/" title="">文档</a><a class="menu-item" href="/about/" title="">关于</a><a class="menu-item" href="https://github.com/noobmid" title="GitHub" rel="noopener noreffer" target="_blank"><i class='fab fa-github fa-fw' aria-hidden='true'></i></a><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
            </a></div>
    </div>
</header><div class="search-dropdown desktop">
        <div id="search-dropdown-desktop"></div>
    </div>
    <div class="search-dropdown mobile">
        <div id="search-dropdown-mobile"></div>
    </div><main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">Contents</h2>
            <div class="toc-content" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animate__animated animate__flipInX">Kafka</h1><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="https://github.com/noobmid" title="Author" target="_blank" rel="noopener noreffer author" class="author"><i class="fas fa-user-circle fa-fw" aria-hidden="true"></i>cx玄烨0</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw" aria-hidden="true"></i>&nbsp;<time datetime="2022-08-28">2022-08-28</time>&nbsp;<i class="fas fa-pencil-alt fa-fw" aria-hidden="true"></i>&nbsp;15555 words&nbsp;
                <i class="far fa-clock fa-fw" aria-hidden="true"></i>&nbsp;32 minutes&nbsp;<span id="/kafka/" class="leancloud_visitors" data-flag-title="Kafka">
                        <i class="far fa-eye fa-fw" aria-hidden="true"></i>&nbsp;<span class=leancloud-visitors-count></span>&nbsp;views
                    </span>&nbsp;</div>
        </div><div class="details toc" id="toc-static"  data-kept="">
                <div class="details-summary toc-title">
                    <span>Contents</span>
                    <span><i class="details-icon fas fa-angle-right" aria-hidden="true"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#消息队列">消息队列</a>
      <ul>
        <li>
          <ul>
            <li><a href="#消息队列的模式">消息队列的模式</a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#应用场景">应用场景</a>
      <ul>
        <li><a href="#缓存消峰">缓存/消峰</a></li>
        <li><a href="#解耦">解耦</a></li>
        <li><a href="#异步通信">异步通信</a></li>
      </ul>
    </li>
    <li><a href="#kafka架构">Kafka架构</a></li>
    <li><a href="#生产者">生产者</a>
      <ul>
        <li><a href="#生产者消息发送原理">生产者消息发送原理</a></li>
        <li><a href="#生产者消息发送方式">生产者消息发送方式</a></li>
        <li><a href="#生产者分区">生产者分区</a>
          <ul>
            <li><a href="#分区的优势">分区的优势</a></li>
            <li><a href="#分区策略">分区策略</a></li>
          </ul>
        </li>
        <li><a href="#生产者优化">生产者优化</a>
          <ul>
            <li><a href="#提高吞吐量">提高吞吐量</a></li>
            <li><a href="#数据可靠性">数据可靠性</a></li>
            <li><a href="#数据去重">数据去重</a></li>
            <li><a href="#生产者事务">生产者事务</a></li>
            <li><a href="#事务">事务</a></li>
            <li><a href="#数据有序">数据有序</a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#broker">Broker</a>
      <ul>
        <li><a href="#zookeeper-存储的信息">Zookeeper 存储的信息</a></li>
        <li><a href="#broker工作流程">Broker工作流程</a></li>
        <li><a href="#开发中的节点服役退役操作">开发中的节点服役退役操作</a>
          <ul>
            <li><a href="#节点服役">节点服役</a></li>
          </ul>
        </li>
        <li><a href="#kafka副本">Kafka副本</a>
          <ul>
            <li><a href="#基本信息">基本信息</a></li>
            <li><a href="#leader选举流程">Leader选举流程</a></li>
            <li><a href="#故障处理">故障处理</a></li>
            <li><a href="#分区副本分配">分区副本分配</a></li>
            <li><a href="#leader-partition负载平衡">Leader Partition负载平衡</a></li>
            <li><a href="#增加副本因子">增加副本因子</a></li>
          </ul>
        </li>
        <li><a href="#文件存储持久化">文件存储(持久化)</a>
          <ul>
            <li>
              <ul>
                <li><a href="#文件存储机制">文件存储机制</a></li>
              </ul>
            </li>
          </ul>
        </li>
        <li><a href="#文件清除策略">文件清除策略</a>
          <ul>
            <li><a href="#清除方式">清除方式</a></li>
          </ul>
        </li>
        <li><a href="#高效读写数据">高效读写数据</a></li>
      </ul>
    </li>
    <li><a href="#消费者">消费者</a>
      <ul>
        <li><a href="#消费模式">消费模式</a></li>
        <li><a href="#工作流程">工作流程</a></li>
        <li><a href="#消费者组原理">消费者组原理</a>
          <ul>
            <li><a href="#消费者组初始化流程">消费者组初始化流程</a></li>
            <li><a href="#详细消费过程">详细消费过程</a></li>
          </ul>
        </li>
        <li><a href="#分区分配策略">分区分配策略</a>
          <ul>
            <li><a href="#range策略">Range策略</a></li>
            <li><a href="#roundrobin策略"><strong>RoundRobin</strong>策略</a></li>
            <li><a href="#sticky-策略"><strong>Sticky</strong> 策略</a></li>
          </ul>
        </li>
        <li><a href="#offset">Offset</a>
          <ul>
            <li><a href="#查看消费者offset">查看消费者offset</a></li>
            <li><a href="#自动提交">自动提交</a></li>
            <li><a href="#手动提交">手动提交</a></li>
            <li><a href="#漏消费和重复消费"><strong>漏消费和重复消费</strong></a></li>
          </ul>
        </li>
        <li><a href="#消费者事务">消费者事务</a></li>
        <li><a href="#消费者如何提高吞吐量">消费者如何提高吞吐量</a></li>
      </ul>
    </li>
    <li><a href="#kraft模式">Kraft模式</a></li>
    <li><a href="#面试题">面试题</a>
      <ul>
        <li><a href="#1-kafka-是什么主要应用场景有哪些">1. <strong>Kafka</strong> 是什么?主要应用场景有哪些?</a></li>
        <li><a href="#2-和其他消息队列相比kafka-的优势在哪里">2. 和其他消息队列相比，<strong>Kafka</strong> 的优势在哪里?</a></li>
        <li><a href="#3-kafka-的多副本机制了解吗">3. <strong>Kafka</strong> 的多副本机制了解吗?</a></li>
        <li><a href="#4-zookeeper-在-kafka-中的作用知道吗">4. <strong>Zookeeper</strong> 在 <strong>Kafka</strong> 中的作用知道吗?</a></li>
        <li><a href="#5kafka-如何保证消息的消费顺序">5.<strong>Kafka</strong> 如何保证消息的消费顺序?</a></li>
        <li><a href="#6-kafka-如何保证消息不丢失">6. <strong>Kafka</strong> 如何保证消息不丢失?</a></li>
        <li><a href="#7-判断节点活着的条件">7. 判断节点活着的条件</a></li>
        <li><a href="#8-kafka-consumer-是否可以消费指定分区消息吗">8. <strong>Kafka consumer</strong> 是否可以消费指定分区消息吗?</a></li>
        <li><a href="#9-kafka-高效文件存储设计特点是什么">9. <strong>Kafka</strong> 高效文件存储设计特点是什么?</a></li>
        <li><a href="#10-partition-的数据如何保存到硬盘">10. <strong>partition</strong> 的数据如何保存到硬盘?</a></li>
        <li><a href="#11-kafka-维护消费状态跟踪的方法有什么">11. <strong>kafka</strong> 维护消费状态跟踪的方法有什么?</a></li>
        <li><a href="#12-kafka-为什么那么快">12. <strong>Kafka</strong> 为什么那么快**?**</a></li>
        <li><a href="#13-kafka-的流处理是什么意思">13. <strong>Kafka</strong> 的流处理是什么意思?</a></li>
      </ul>
    </li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><h1 id="kafka">Kafka</h1>
<p>​		Kafka是一个开源的分布式事件流平台(Event Streaming Platform)，广泛应用于高性能数据管道、流分析、数据集成和关键任务应用;</p>
<h2 id="消息队列">消息队列</h2>
<p>​		企业中比较常见的消息队列产品主要有Kafka、ActiveMQ、RabbitMQ、RocketMQ等。在大数据场景主要采用Kafka作为消息队列</p>
<h4 id="消息队列的模式">消息队列的模式</h4>
<ol>
<li>
<p>点对点模式:  消费者主动拉取数据、消息收到后清除消息</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-03%20%E4%B8%8B%E5%8D%889.02.33.png"
        data-srcset="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-03%20%E4%B8%8B%E5%8D%889.02.33.png, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-03%20%E4%B8%8B%E5%8D%889.02.33.png 1.5x, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-03%20%E4%B8%8B%E5%8D%889.02.33.png 2x"
        data-sizes="auto"
        alt="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-03%20%E4%B8%8B%E5%8D%889.02.33.png"
        title="截屏2022-09-03 下午9.02.33" /></p>
</li>
<li>
<p>发布/订阅模式</p>
<ul>
<li>可以有多个topic主题(浏览、点赞、收藏、评论等)</li>
<li>消费者消费数据之后，不删除数据</li>
<li>每个消费者相互独立，都可以消费到数据</li>
</ul>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-03%20%E4%B8%8B%E5%8D%889.05.13.png"
        data-srcset="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-03%20%E4%B8%8B%E5%8D%889.05.13.png, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-03%20%E4%B8%8B%E5%8D%889.05.13.png 1.5x, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-03%20%E4%B8%8B%E5%8D%889.05.13.png 2x"
        data-sizes="auto"
        alt="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-03%20%E4%B8%8B%E5%8D%889.05.13.png"
        title="截屏2022-09-03 下午9.05.13" /></p>
</li>
<li></li>
</ol>
<h2 id="应用场景">应用场景</h2>
<p>传统的消息队列的主要应用场景包括：缓存/消峰**、**解耦**和**异步通信。</p>
<h3 id="缓存消峰">缓存/消峰</h3>
<p>​		有助于控制和优化数据流经过系统的速度，解决生产消息和消费消息的处理速度不一致的情况<img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-03%20%E4%B8%8B%E5%8D%888.58.05.png"
        data-srcset="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-03%20%E4%B8%8B%E5%8D%888.58.05.png, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-03%20%E4%B8%8B%E5%8D%888.58.05.png 1.5x, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-03%20%E4%B8%8B%E5%8D%888.58.05.png 2x"
        data-sizes="auto"
        alt="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-03%20%E4%B8%8B%E5%8D%888.58.05.png"
        title="截屏2022-09-03 下午8.58.05" /></p>
<h3 id="解耦">解耦</h3>
<p>​		允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。<img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-03%20%E4%B8%8B%E5%8D%888.59.54.png"
        data-srcset="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-03%20%E4%B8%8B%E5%8D%888.59.54.png, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-03%20%E4%B8%8B%E5%8D%888.59.54.png 1.5x, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-03%20%E4%B8%8B%E5%8D%888.59.54.png 2x"
        data-sizes="auto"
        alt="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-03%20%E4%B8%8B%E5%8D%888.59.54.png"
        title="截屏2022-09-03 下午8.59.54" /></p>
<h3 id="异步通信">异步通信</h3>
<p>​		允许用户把一个消息放入队列，但并不立即处理它，然后在需要的时候再去处理它们。<img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-03%20%E4%B8%8B%E5%8D%889.00.38.png"
        data-srcset="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-03%20%E4%B8%8B%E5%8D%889.00.38.png, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-03%20%E4%B8%8B%E5%8D%889.00.38.png 1.5x, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-03%20%E4%B8%8B%E5%8D%889.00.38.png 2x"
        data-sizes="auto"
        alt="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-03%20%E4%B8%8B%E5%8D%889.00.38.png"
        title="截屏2022-09-03 下午9.00.38" /></p>
<h2 id="kafka架构">Kafka架构</h2>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-03%20%E4%B8%8B%E5%8D%889.09.41.png"
        data-srcset="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-03%20%E4%B8%8B%E5%8D%889.09.41.png, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-03%20%E4%B8%8B%E5%8D%889.09.41.png 1.5x, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-03%20%E4%B8%8B%E5%8D%889.09.41.png 2x"
        data-sizes="auto"
        alt="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-03%20%E4%B8%8B%E5%8D%889.09.41.png"
        title="截屏2022-09-03 下午9.09.41" /></p>
<ol>
<li>Producer：消息生产者，就是向Kafka broker发消息的客户端;</li>
<li>Consumer：消息消费者，向Kafka broker取消息的客户端。</li>
<li>**Consumer Group（CG）：消费者组，由多个consumer组成。**消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费；消费者组之间互不影响。<strong>所有的消费者都属于某个消费者组，即</strong>消费者组是逻辑上的一个订阅者。</li>
<li>Broker：一台Kafka服务器就是一个broker。一个集群由多个broker组成。一个broker可以容纳多个topic。</li>
<li>Topic：主题, 可以理解为一个队列，生产者和消费者面向的都是一个topic。</li>
<li><strong>Partition</strong>：**为了实现扩展性，一个非常大的topic可以分布到多个broker（即服务器）上，**一个topic可以分为多个partition，每个partition是一个有序的队列。</li>
<li><strong>Replica</strong>：<strong>副本。一个topic的每个分区都有若干个副本，一个</strong>Leader<strong>和若干个</strong>Follower。</li>
<li><strong>Leader</strong>：每个分区多个副本的“主”，生产者发送数据的对象，以及消费者消费数据的对象都是Leader;</li>
<li><strong>Follower</strong>：每个分区多个副本中的“从”，实时从Leader中同步数据，保持和Leader数据的同步。Leader发生故障时，某个Follower会成为新的Leader。</li>
</ol>
<h2 id="生产者">生产者</h2>
<h3 id="生产者消息发送原理">生产者消息发送原理</h3>
<p>​		在消息发送的过程中，涉及到了两个线程——<strong>main</strong> 线程和 <strong>Sender</strong> 线程。在 main 线程 中创建了一个双端队列 <strong>RecordAccumulator</strong>。main 线程将消息发送给 RecordAccumulator， Sender 线程不断从 RecordAccumulator 中拉取消息发送到 Kafka Broker。![截屏2022-09-03 下午9.26.11](<a href="https://raw.githubusercontent.com/NoobMidC/pics/main/" target="_blank" rel="noopener noreffer ">https://raw.githubusercontent.com/NoobMidC/pics/main/</a>截屏2022-09-03 下午9.26.11.png)</p>
<p>​			主线程中，由KafkaProducer创建消息，然后通过可能的拦截器、序列化器和分区器的作用，缓存消息到消息加载器（RecordAccumulator，也称为消息收集器）中，Sender线程负责从消息加载器（RecordAccumulator）中获取消息并将其发送到Kafka中。</p>
<blockquote>
<p>拦截器: 对数据进行加工和操作; 如流量拦截和放行处理,如实现白名单</p>
<p>序列化器: 将生产出的消息kv序列化为标准协议</p>
<p>分区器: 根据其存储的元数据, 确定消息发送到哪个分区</p>
</blockquote>
<ul>
<li>
<p>消息加载器RecordAccumulator (内存中)</p>
<p>​		消息加载器（RecordAccumulator）主要用来缓存消息以便Sender线程可以批量发送，进而减少网络传输的资源消耗以提升性能。缓存大小默认为32M; 每个DQuene为发给某个partition的数据队列(一个分区对应一个队列); 即ProducerBatch;	当满足以下两个条件的任意一个之后，消息由sender线程发送。</p>
<ol>
<li>一个队列中的消息累计达到batch.size，默认是16kb。</li>
<li>等待时间达到linger.ms，默认是0毫秒。</li>
</ol>
<blockquote>
<p>RecordAccumulator 中维护一个内存池;  dqueue有数据时请求内存池, 数据发送完毕则将内存归还内存池; 避免了内存的频繁申请和释放;</p>
</blockquote>
</li>
<li>
<p>sender线程</p>
<p>​		Sender线程首先会通过sender读取数据，并创建发送的请求，针对Kafka集群里的每一个Broker，都会有一个InFlightRequests请求队列存放在NetWorkClient中，默认每个InFlightRequests请求队列中缓存5个请求。接着这些请求就会通过Selector发送到Kafka集群中。</p>
</li>
<li>
<p>kafka集群</p>
<p>​		当请求发送到发送到Kafka集群后，Kafka集群会返回对应的acks信息。生产者可以根据具体的情况选择处理acks信息。比如是否需要等有回应之后再继续发送消息，还是不管发送成功失败都继续发送消息。</p>
<ol>
<li>如果成功;  InFlightRequests清理掉对应请求; DQuene清理掉对应数据</li>
<li>如果失败; 则进行重试retires次数, 默认为int最大值 即2147483647</li>
</ol>
</li>
</ul>
<h3 id="生产者消息发送方式">生产者消息发送方式</h3>
<ul>
<li>异步发送</li>
<li>带回调的异步发送</li>
<li>同步发送</li>
</ul>
<h3 id="生产者分区">生产者分区</h3>
<h4 id="分区的优势">分区的优势</h4>
<ol>
<li>
<p><strong>便于合理使用存储资源</strong>;  每个Partition在一个Broker上存储，可以把海量的数据按照分区切割成一</p>
<p>块一块数据存储在多台Broker上。合理控制分区的任务，可以实现负载均衡的效果。</p>
</li>
<li>
<p>提高并行度，生产者可以以分区为单位发送数据;消费者可以以分区为单位进行消费数据。</p>
</li>
</ol>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%8812.06.27.png"
        data-srcset="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%8812.06.27.png, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%8812.06.27.png 1.5x, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%8812.06.27.png 2x"
        data-sizes="auto"
        alt="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%8812.06.27.png"
        title="截屏2022-09-05 下午12.06.27" /></p>
<h4 id="分区策略">分区策略</h4>
<ol>
<li>指明<strong>partition</strong>的情况下，直接将指明的值作为<strong>partition</strong>值; 例如partition=0，所有数据写入 分区0</li>
<li>没有指明<strong>partition</strong>值但有<strong>key</strong>的情况下，将<strong>key</strong>的<strong>hash</strong>值与<strong>topic</strong>的 <strong>partition</strong>数进行取余得到<strong>partition</strong>值;
例如:<strong>key1</strong>的<strong>hash</strong>值**=**5**， **key2**的**hash**值**=6，**topic**的**partition**数**=2**，那 么**key1** 对应的**value1**写入**1**号分区，**key2**对应的**value2**写入**0**号分区。</li>
<li>既没有<strong>partition</strong>值又没有<strong>key</strong>值的情况下，<strong>Kafka</strong>采用<strong>Sticky Partition</strong>(黏性分区器)，会随机选择一个分区，并尽可能一直使用该分区，待该分区的<strong>batch</strong>已满或者到linger.ms时间到之后，<strong>Kafka</strong>再随机一个分区进行使用(和上一次的分区不同)。例如:第一次随机选择<strong>0</strong>号分区，等<strong>0</strong>号分区当前批次满了(默认<strong>16k</strong>)或者<strong>linger.ms</strong>设置的时间到， <strong>Kafka</strong>再随机一个分区进行使用(如果还是<strong>0</strong>会继续随机)。</li>
</ol>
<h3 id="生产者优化">生产者优化</h3>
<h4 id="提高吞吐量">提高吞吐量</h4>
<ol>
<li>batch.size: 批次大小, 默认为16k, 可以扩大;</li>
<li>linger.ms:等待时间，修改为5-100ms;</li>
<li>compression.type:设置为snappy, 数据压缩后传输的效率提高了</li>
<li>RecordAccumulator:缓冲区大小，修改为64m</li>
</ol>
<h4 id="数据可靠性">数据可靠性</h4>
<p>ACK应答级别</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%8812.17.23.png"
        data-srcset="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%8812.17.23.png, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%8812.17.23.png 1.5x, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%8812.17.23.png 2x"
        data-sizes="auto"
        alt="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%8812.17.23.png"
        title="截屏2022-09-05 下午12.17.23" /></p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%8812.20.00.png"
        data-srcset="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%8812.20.00.png, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%8812.20.00.png 1.5x, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%8812.20.00.png 2x"
        data-sizes="auto"
        alt="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%8812.20.00.png"
        title="截屏2022-09-05 下午12.20.00" /></p>
<p>可靠性总结:</p>
<ul>
<li>
<p><strong>acks=0</strong>，生产者发送过来数据就不管了，可靠性差，效率高;</p>
</li>
<li>
<p><strong>acks=1</strong>，生产者发送过来数据<strong>Leader</strong>应答，可靠性中等，效率中等;</p>
</li>
<li>
<p><strong>acks=-1</strong>，生产者发送过来数据<strong>Leader</strong>和<strong>ISR</strong>队列里面所有<strong>Follwer</strong>应答，可靠性高，效率低;</p>
<p>​		在生产环境中，<strong>acks=0</strong>很少使用;<strong>acks=1</strong>，一般用于传输普通日志，允许丢个别数据;<strong>acks=-1</strong>，一般用于传输和钱相关的数据， 对可靠性要求比较高的场景。</p>
</li>
</ul>
<h4 id="数据去重">数据去重</h4>
<p>数据重复发送的原因</p>
<p>​		在ack = -1 时,需要isr中所有的所有节点应答后才返回客户端成功; 如果在某个follower接收到一条数据后, leader挂掉;然后这个follower被选为leader; 由于集群未应答sender成功, 因此selector回重试,这样现在的leader就会有两条相同的数据;</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%8812.34.23.png"
        data-srcset="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%8812.34.23.png, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%8812.34.23.png 1.5x, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%8812.34.23.png 2x"
        data-sizes="auto"
        alt="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%8812.34.23.png"
        title="截屏2022-09-05 下午12.34.23" /></p>
<ul>
<li>
<p>数据传输语义</p>
<ol>
<li>至少一次(保证数据不丢失,不能保证重复性): 最少发送一次,如果失败则继续发送;   <strong>ACK级别设置为-1+分区副本大于等于2+ISR里应答的最小副本数量大于等于2</strong></li>
<li>至多一次(不保证数据不丢失,能保证数据不重复): 最多发送一次, 失败成功无所谓; <strong>ACK级别设置为0</strong></li>
<li>精确一次: 对于一些非常重要的信息，比如和钱相关的数据，要求数据既不能重复也不丢失; <strong>可以使用幂等性</strong></li>
</ol>
</li>
<li>
<p>幂等性</p>
<p>​		幂等性就是指Producer不论向Broker发送多少次重复数据，Broker端都只会持久化一条，保证了不重复。</p>
<p>​		精确一次(<strong>Exactly Once</strong>) <strong>=</strong> 幂等性 <strong>+</strong> 至少一次( <strong>ack=-1 +</strong> 分区副本数**&gt;=2 + ISR**最小副本数量**&gt;=2**) ;</p>
<p>​		重复数据的判断标准:具有&lt;PID, Partition, SeqNumber&gt;相同主键的消息提交时，Broker只会持久化一条。其中PID是Kafka每次重启都会分配一个新的;Partition 表示分区号;Sequence Number是单调自增的。</p>
<p>​		所以幂等性只能保证的是<strong>在单分区单会话内不重复</strong>。</p>
</li>
</ul>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%8812.43.18.png"
        data-srcset="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%8812.43.18.png, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%8812.43.18.png 1.5x, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%8812.43.18.png 2x"
        data-sizes="auto"
        alt="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%8812.43.18.png"
        title="截屏2022-09-05 下午12.43.18" /></p>
<p>​			幂等性使用: 开启参数 <strong>enable.idempotence</strong> 默认为 true，false 关闭。</p>
<h4 id="生产者事务">生产者事务</h4>
<h4 id="事务">事务</h4>
<blockquote>
<p>开启事务，必须开启幂等性。</p>
</blockquote>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%8812.44.57.png"
        data-srcset="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%8812.44.57.png, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%8812.44.57.png 1.5x, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%8812.44.57.png 2x"
        data-sizes="auto"
        alt="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%8812.44.57.png"
        title="截屏2022-09-05 下午12.44.57" /></p>
<ul>
<li>使用场景
<ol>
<li>**生产者发送多条消息可以封装在一个事务中，形成一个原子操作。**多条消息要么都发送成功，要么都发送失败。</li>
<li>**read-process-write模式：将消息消费和生产封装在一个事务中，形成一个原子操作。**在一个流式处理的应用中，常常一个服务需要从上游接收消息，然后经过处理后送达到下游，这就对应着消息的消费和生成。</li>
</ol>
</li>
<li>事务配置
<ol>
<li>对于Producer，需要设置<code>transactional.id</code>属性，这个属性的作用下文会提到。设置了<code>transactional.id</code>属性后，<code>enable.idempotence</code>属性会自动设置为true。</li>
<li>对于Consumer，需要设置<code>isolation.level = read_committed</code>，这样Consumer只会读取已经提交了事务的消息。另外，需要设置<code>enable.auto.commit = false</code>来关闭自动提交Offset功能。</li>
</ol>
</li>
<li>事务特性</li>
</ul>
<ol>
<li>
<p>原子写</p>
<p>​          Kafka的事务特性本质上是支持了Kafka跨分区和Topic的原子写操作。在同一个事务中的消息要么同时写入成功，要么同时写入失败。我们知道，Kafka中的Offset信息存储在一个名为_consumed_offsets的Topic中，因此read-process-write模式，除了向目标Topic写入消息，还会向_consumed_offsets中写入已经消费的Offsets数据。因此read-process-write本质上就是跨分区和Topic的原子写操作。<strong>Kafka的事务特性就是要确保跨分区的多个写操作的原子性。</strong></p>
</li>
<li>
<p>拒绝僵尸实例（Zombie fencing)</p>
<p>​		在分布式系统中，一个instance的宕机或失联，集群往往会自动启动一个新的实例来代替它的工作。此时若原实例恢复了，那么集群中就产生了两个具有相同职责的实例，此时前一个instance就被称为“僵尸实例（Zombie Instance）”。在Kafka中，两个相同的producer同时处理消息并生产出重复的消息（read-process-write模式），这样就严重违反了精确一次(Exactly Once Processing)的语义。这就是僵尸实例问题。</p>
<p>​		Kafka事务特性通过<code>transaction-id</code>属性来解决僵尸实例问题。所有具有相同<code>transaction-id</code>的Producer都会被分配相同的pid，同时每一个Producer还会被分配一个递增的epoch。Kafka收到事务提交请求时，如果检查当前事务提交者的epoch不是最新的，那么就会拒绝该Producer的请求。从而达成拒绝僵尸实例的目标。</p>
</li>
<li>
<p>读事务消息</p>
<p>​               为了保证事务特性，Consumer如果设置了<code>isolation.level = read_committed</code>，那么它只会读取已经提交了的消息。在Producer成功提交事务后，Kafka会将所有该事务中的消息的<code>Transaction Marker</code>从<code>uncommitted</code>标记为<code>committed</code>状态，从而所有的Consumer都能够消费。</p>
</li>
</ol>
<ul>
<li>事务原理</li>
</ul>
<ol>
<li>
<p><strong>查找Tranaction Corordinator</strong></p>
<p>​         Producer向任意一个brokers发送 FindCoordinatorRequest请求来获取Transaction Coordinator的地址。</p>
</li>
<li>
<p><strong>初始化事务 initTransaction</strong></p>
<p>​      Producer发送InitpidRequest给Transaction Coordinator，获取pid。**Transaction Coordinator在Transaciton Log中记录这&lt;TransactionId,pid&gt;的映射关系。**另外，它还会做两件事：</p>
<ul>
<li>恢复（Commit或Abort）之前的Producer未完成的事务</li>
<li>对PID对应的epoch进行递增，这样可以保证同一个app的不同实例对应的PID是一样，而epoch是不同的。</li>
</ul>
</li>
<li>
<p><strong>开始事务beginTransaction</strong></p>
<p>​     执行Producer的beginTransacion()，它的作用是Producer在**本地记录下这个transaction的状态为开始状态。**这个操作并没有通知Transaction Coordinator，因为Transaction Coordinator只有在Producer发送第一条消息后才认为事务已经开启。</p>
</li>
<li>
<p><strong>read-process-write流程</strong></p>
<p>​		一旦Producer开始发送消息，<strong>Transaction Coordinator会将该&lt;Transaction, Topic, Partition&gt;存于Transaction Log内，并将其状态置为BEGIN</strong>。另外，如果该&lt;Topic, Partition&gt;为该事务中第一个&lt;Topic, Partition&gt;，Transaction Coordinator还会启动对该事务的计时（每个事务都有自己的超时时间）。</p>
<p>​		在注册&lt;Transaction, Topic, Partition&gt;到Transaction Log后，生产者发送数据，虽然没有还没有执行commit或者abort，但是此时消息已经保存到Broker上了。即使后面执行abort，消息也不会删除，只是更改状态字段标识消息为abort状态。</p>
</li>
<li>
<p><strong>事务提交或终结 commitTransaction/abortTransaction</strong></p>
<p>​		在Producer执行commitTransaction/abortTransaction时，Transaction Coordinator会执行一个两阶段提交：</p>
<ul>
<li><strong>第一阶段，将Transaction Log内的该事务状态设置为<code>PREPARE_COMMIT</code>或<code>PREPARE_ABORT</code></strong></li>
<li>**第二阶段，将<code>Transaction Marker</code>写入该事务涉及到的所有消息（即将消息标记为<code>committed</code>或<code>aborted</code>）。**这一步骤Transaction Coordinator会发送给当前事务涉及到的每个&lt;Topic, Partition&gt;的Leader，Broker收到该请求后，会将对应的<code>Transaction Marker</code>控制信息写入日志。</li>
</ul>
<p>​      一旦<code>Transaction Marker</code>写入完成，Transaction Coordinator会将最终的<code>COMPLETE_COMMIT</code>或<code>COMPLETE_ABORT</code>状态写入Transaction Log中以标明该事务结束。</p>
<blockquote>
<p>总结:</p>
<ul>
<li>Transaction Marker与PID提供了识别消息是否应该被读取的能力，从而实现了事务的隔离性。</li>
<li>Offset的更新标记了消息是否被读取，从而将对读操作的事务处理转换成了对写（Offset）操作的事务处理。</li>
<li>Kafka事务的本质是，将一组写操作（如果有）对应的消息与一组读操作（如果有）对应的Offset的更新进行同样的标记（Transaction Marker）来实现事务中涉及的所有读写操作同时对外可见或同时对外不可见。</li>
<li>Kafka只提供对Kafka本身的读写操作的事务性，不提供包含外部系统的事务性。</li>
</ul>
</blockquote>
</li>
</ol>
<h4 id="数据有序">数据有序</h4>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%881.42.29.png"
        data-srcset="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%881.42.29.png, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%881.42.29.png 1.5x, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%881.42.29.png 2x"
        data-sizes="auto"
        alt="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%881.42.29.png"
        title="截屏2022-09-05 下午1.42.29" /></p>
<ol>
<li>
<p>在1.x以前保证数据单分区有序; 需要设置每个连接中的InFlightRequests队列中的请求数(<strong>max.in.flight.requests.per.connection</strong>)为1</p>
</li>
<li>
<p>1.x以后, 不开启幂等性时和上面一样; 开启后设置其小于等于5;</p>
<blockquote>
<p>因为在kafka1.x以后，启用幂等后，kafka服务端会缓存producer发来的最近5个request的元数据， 故无论如何，都可以保证最近5个request的数据都是有序的。</p>
</blockquote>
</li>
</ol>
<h2 id="broker">Broker</h2>
<h3 id="zookeeper-存储的信息">Zookeeper 存储的信息</h3>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%881.52.14.png"
        data-srcset="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%881.52.14.png, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%881.52.14.png 1.5x, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%881.52.14.png 2x"
        data-sizes="auto"
        alt="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%881.52.14.png"
        title="截屏2022-09-05 下午1.52.14" /></p>
<h3 id="broker工作流程">Broker工作流程</h3>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%881.55.48.png"
        data-srcset="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%881.55.48.png, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%881.55.48.png 1.5x, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%881.55.48.png 2x"
        data-sizes="auto"
        alt="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%881.55.48.png"
        title="截屏2022-09-05 下午1.55.48" /></p>
<ol>
<li>
<p>注册: 每次启动一个broker都会到zk中注册节点信息;</p>
</li>
<li>
<p>选择controller节点:  所以节点的controller去zk抢注册; 谁先注册谁为controller_leader;</p>
</li>
<li>
<p>监听: 选举出来的controller 监听所有broker的状态</p>
</li>
<li>
<p>选举: controller_leader决定leader选举;</p>
<blockquote>
<p>选举规则: 在ISR中存活为前提, 按照AR排在前面的优先; 如AR[1,0,2], ISR为[1,0,2],则leader会按照1,0,2顺序轮询</p>
</blockquote>
</li>
<li>
<p>同步信息: controller上传节点信息到zk,其他controller从zk同步相关信息</p>
</li>
<li>
<p>重新选举: 如果leader挂掉, controller监听到节点变化, 向zk拉取节点信息(ISR等),并重新选举leader</p>
</li>
<li>
<p>更新leader和ISR</p>
</li>
</ol>
<blockquote>
<p>replica.lag.time.max.ms: ISR中，如果Follower长时间未向Leader发送通信请求或同步数据，则该Follower将被踢出ISR。该时间阈值，默认30s。</p>
</blockquote>
<h3 id="开发中的节点服役退役操作">开发中的节点服役退役操作</h3>
<h4 id="节点服役">节点服役</h4>
<ol>
<li>启动新节点</li>
<li>执行负载均衡计划,将数据重分配到每个broker上</li>
<li>执行副本存储计划, 重新分配主分区的副本位置</li>
</ol>
<p>节点退役</p>
<ol>
<li>执行负载均衡计划, 将数据重分配到后续存活的broker上</li>
<li>执行副本存储计划, 重新分配主分区的副本位置</li>
<li>关闭旧节点</li>
</ol>
<h3 id="kafka副本">Kafka副本</h3>
<h4 id="基本信息">基本信息</h4>
<ol>
<li>Kafka副本作用：提高数据可靠性。</li>
<li>Kafka默认副本1个，生产环境一般配置为2个，保证数据可靠性；太多副本会增加磁盘存储空间，增加网络上数据传输，降低效率。</li>
<li>Kafka中副本分为：Leader和Follower。Kafka生产者只会把数据发往Leader，然后Follower找Leader进行同步数据。</li>
<li>Kafka分区中的所有副本统称为AR（Assigned Repllicas）。</li>
</ol>
<blockquote>
<p>AR = ISR + OSR</p>
<p><strong>ISR</strong>，表示和Leader保持同步的Follower集合。如果Follower长时间未向Leader发送通信请求或同步数据，则该Follower将被踢出ISR。该时间阈值由<strong>replica.lag.time.max.ms</strong>参数设定，默认30s。Leader发生故障之后，就会从ISR中选举新的Leader。</p>
<p><strong>OSR</strong>，表示Follower与Leader副本同步时，延迟过多的副本。</p>
</blockquote>
<h4 id="leader选举流程">Leader选举流程</h4>
<p>​		Kafka集群中有一个broker的Controller会被选举为Controller Leader，负责管理集群broker的上下线，所有topic的分区副本分配和Leader选举等工作; Controller的信息同步工作是依赖于Zookeeper的</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%882.18.38.png"
        data-srcset="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%882.18.38.png, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%882.18.38.png 1.5x, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%882.18.38.png 2x"
        data-sizes="auto"
        alt="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%882.18.38.png"
        title="截屏2022-09-05 下午2.18.38" /></p>
<h4 id="故障处理">故障处理</h4>
<ul>
<li>Follower故障处理</li>
</ul>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%882.19.25.png"
        data-srcset="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%882.19.25.png, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%882.19.25.png 1.5x, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%882.19.25.png 2x"
        data-sizes="auto"
        alt="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%882.19.25.png"
        title="截屏2022-09-05 下午2.19.25" /></p>
<ul>
<li>Leader故障处理</li>
</ul>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%882.20.14.png"
        data-srcset="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%882.20.14.png, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%882.20.14.png 1.5x, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%882.20.14.png 2x"
        data-sizes="auto"
        alt="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%882.20.14.png"
        title="截屏2022-09-05 下午2.20.14" /></p>
<h4 id="分区副本分配">分区副本分配</h4>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%882.25.04.png"
        data-srcset="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%882.25.04.png, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%882.25.04.png 1.5x, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%882.25.04.png 2x"
        data-sizes="auto"
        alt="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%882.25.04.png"
        title="截屏2022-09-05 下午2.25.04" /></p>
<ol>
<li>leader尽可能错开, 第一个分配了则第二个broker, 循环往复</li>
<li>follower第一批和leader不间隔, 第二批和leader间隔一个broker, 后面递增</li>
<li>可以手动创建topic并指定每个分区的副本位置</li>
</ol>
<h4 id="leader-partition负载平衡">Leader Partition负载平衡</h4>
<p>​		正常情况下，Kafka本身会自动把Leader Partition均匀分散在各个机器上，来保证每台机器的读写吞吐量都是均匀的。但是如果某 些broker宕机，会导致Leader Partition过于集中在其他少部分几台broker上，这会导致少数几台broker的读写请求压力过高，其他宕机的 broker重启之后都是follower partition，读写请求很低，造成集群负载不均衡。</p>
<blockquote>
<ul>
<li>auto.leader.rebalance.enable，默认是true。 自动Leader Partition 平衡</li>
<li>leader.imbalance.per.broker.percentage， 默认是10%。每个broker允许的不平衡 的leader的比率。如果每个broker超过 了这个值，控制器会触发leader的平衡。</li>
<li>leader.imbalance.check.interval.seconds， 默认值300秒。检查leader负载是否平衡 的间隔时间。</li>
</ul>
</blockquote>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%882.32.48.png"
        data-srcset="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%882.32.48.png, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%882.32.48.png 1.5x, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%882.32.48.png 2x"
        data-sizes="auto"
        alt="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%882.32.48.png"
        title="截屏2022-09-05 下午2.32.48" /></p>
<h4 id="增加副本因子">增加副本因子</h4>
<p>​		在生产环境当中，由于某个主题的重要等级需要提升，我们考虑增加副本。副本数的增加需要先制定计划，然后根据计划执行。</p>
<ol>
<li>
<p>创建topic</p>
</li>
<li>
<p>手动增加副本存储</p>
<p>（1）创建副本存储计划（所有副本都指定存储在broker0、broker1、broker2中）。</p>
<p>（2）执行副本存储计划。</p>
</li>
</ol>
<h3 id="文件存储持久化">文件存储(持久化)</h3>
<h5 id="文件存储机制">文件存储机制</h5>
<p>​		Topic是逻辑上的概念，而partition是物理上的概念，每个partition对应于一个log文件，该log文件中存储的就是Producer生产的数据。Producer生产的数据会被不断追加到该log文件末端，为防止log文件过大导致数据定位效率低下，Kafka采取了分片和索引机制， 将每个partition分为多个segment。每个segment包括:“.index”文件、“.log”文件和.timeindex等文件。这些文件位于一个文件夹下，该 文件夹的命名规则为:topic名称+分区序号，例如:first-0。<img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%882.38.29.png"
        data-srcset="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%882.38.29.png, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%882.38.29.png 1.5x, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%882.38.29.png 2x"
        data-sizes="auto"
        alt="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%882.38.29.png"
        title="截屏2022-09-05 下午2.38.29" /></p>
<ul>
<li><strong>index</strong>文件和log文件详解</li>
</ul>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%882.41.47.png"
        data-srcset="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%882.41.47.png, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%882.41.47.png 1.5x, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%882.41.47.png 2x"
        data-sizes="auto"
        alt="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%882.41.47.png"
        title="截屏2022-09-05 下午2.41.47" /></p>
<h3 id="文件清除策略">文件清除策略</h3>
<p>Kafka中默认的日志保存时间为7天，可以通过调整如下参数修改保存时间。</p>
<ul>
<li>log.retention.hours，最低优先级小时，默认7天。</li>
<li>log.retention.minutes，分钟。</li>
<li>log.retention.ms，最高优先级毫秒。</li>
<li>log.retention.check.interval.ms，负责设置检查周期，默认5分钟</li>
</ul>
<h4 id="清除方式">清除方式</h4>
<p>Kafka中提供的日志清理策略有delete和compact两种。</p>
<ul>
<li>delete: 将过期数据删除</li>
</ul>
<p>log.cleanup.policy = delete  所有数据启用删除策略</p>
<ol>
<li>
<p>基于时间：默认打开。以segment中所有记录中的最大时间戳作为该文件时间戳。这样就能防止segment中部分超时而删除所有数据的情况;</p>
</li>
<li>
<p>基于大小：默认关闭。超过设置的所有日志总大小，删除最早的segment。log.retention.bytes，默认等于-1，表示无穷大。</p>
</li>
</ol>
<ul>
<li>compact日志压缩</li>
</ul>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%882.46.17.png"
        data-srcset="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%882.46.17.png, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%882.46.17.png 1.5x, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%882.46.17.png 2x"
        data-sizes="auto"
        alt="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%882.46.17.png"
        title="截屏2022-09-05 下午2.46.17" /></p>
<h3 id="高效读写数据">高效读写数据</h3>
<ol>
<li>
<p><strong>Kafka</strong>本身是分布式集群，可以采用分区技术，并行度高</p>
</li>
<li>
<p><strong>读数据采用稀疏索引，可以快速定位要消费的数据</strong></p>
</li>
<li>
<p><strong>顺序写磁盘</strong></p>
<p>​		Kafka的producer生产数据，要写入到log文件中，写的过程是一直追加到文件末端，为顺序写</p>
</li>
<li>
<p><strong>页缓存</strong> <strong>+</strong> <strong>零拷贝技术</strong></p>
<ul>
<li>
<p>零拷贝:Kafka的数据加工处理操作交由Kafka生产者和Kafka消费者处理。Kafka Broker应用层不关心存储的数据，所以就不用走应用层，传输效率高。</p>
</li>
<li>
<p><strong>PageCache</strong>页缓存: Kafka重度依赖底层操作系统提供的PageCache功能。当上层有写操作时，操作系统只是将数据写入 PageCache。当读操作发生时，先从PageCache中查找，如果找不到，再去磁盘中读取。实际上PageCache是把尽可能多的空闲内存 都当做了磁盘缓存来使用。</p>
</li>
</ul>
</li>
</ol>
<blockquote>
<p>log.flush.interval.messages: 强制页缓存刷写到磁盘的条数，默认是long的最大值，9223372036854775807。一般不建议修改，交给系统自己管理。</p>
<p>log.flush.interval.ms: 每隔多久，刷数据到磁盘，默认是null。一般不建议修改，交给系统自己管理。</p>
</blockquote>
<h2 id="消费者">消费者</h2>
<h3 id="消费模式">消费模式</h3>
<ol>
<li>
<p><strong>pull</strong>(拉)模式</p>
<p>consumer采用从broker中主动拉取数据。<strong>Kafka</strong>采用这种方式</p>
</li>
<li>
<p><strong>push</strong>(推)模式</p>
<p>Kafka没有采用这种方式，因为由broker 决定消息发送速率，很难适应所有消费者的消费速率;</p>
</li>
</ol>
<blockquote>
<p>pull模式不足之处是，如果Kafka没有数 据，消费者可能会陷入循环中，一直返回 空数据。</p>
</blockquote>
<h3 id="工作流程">工作流程</h3>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.00.32.png"
        data-srcset="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.00.32.png, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.00.32.png 1.5x, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.00.32.png 2x"
        data-sizes="auto"
        alt="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.00.32.png"
        title="截屏2022-09-05 下午3.00.32" /></p>
<ol>
<li>不同的消费者之前互不影响</li>
<li>一个分区只能由消费者组中的一个消费者消费; 一个消费者可以消费多个分区</li>
<li>消费者的offset由消费者提交给_consumer_offsets主题保存</li>
</ol>
<blockquote>
<p>1.x以前将offset存储在zk中, 由于需要储存每个消费者offset,每次请求都需要向zk拿取offset, 其整个网络传输的负担太大</p>
</blockquote>
<h3 id="消费者组原理">消费者组原理</h3>
<p>Consumer Group(CG):消费者组，由多个consumer组成。形成一个消费者组的条件，是所有消费者的groupid相同。</p>
<ul>
<li>消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费。</li>
<li>消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。</li>
<li>如果向消费组中添加更多的消费者，超过 主题分区数量，则有一部分消费者就会闲 置，不会接收任何消息。</li>
<li>消费者组之间互不影响。所 有的消费者都属于某个消费者组，即消费者组是逻辑上 的一个订阅者。</li>
</ul>
<h4 id="消费者组初始化流程">消费者组初始化流程</h4>
<ol>
<li>coordinator: 辅助实现消费者组的初始化和分区的分配。
coordinator节点选择 = groupid的hashcode值 % 50(consumer_offsets的分区数量)
例如: groupid的hashcode值 = 1，1% 50 = 1，那么consumer_offsets 主题的1号分区，在哪个broker上，就选择这个节点的coordinator;作为这个消费者组的老大。消费者组下的所有的消费者提交offset的时候就往这个分区去提交offset。</li>
<li>选出一个consumer作为leader</li>
<li>coordinator把要消费的topic信息发给leader</li>
<li>leader制定消费方案(即哪些消费者消费哪些分区);并将方案发给coordinator;</li>
<li>coordinator下发消费方案给每个消费者</li>
<li>消费者和coordinator保持心跳(默认3s),一旦超时(45s),消费者会被移除,触发再平衡; 或者消费者处理消息时间过长(5min),也会触发再平衡</li>
</ol>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.09.32.png"
        data-srcset="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.09.32.png, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.09.32.png 1.5x, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.09.32.png 2x"
        data-sizes="auto"
        alt="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.09.32.png"
        title="截屏2022-09-05 下午3.09.32" /></p>
<h4 id="详细消费过程">详细消费过程</h4>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.17.21.png"
        data-srcset="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.17.21.png, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.17.21.png 1.5x, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.17.21.png 2x"
        data-sizes="auto"
        alt="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.17.21.png"
        title="截屏2022-09-05 下午3.17.21" /></p>
<ol>
<li>
<p>发送抓取数据的请求</p>
<blockquote>
<ul>
<li>每批次最小的抓取大小,默认为一字节</li>
<li>一个批次数据最小未到达超时时间为500ms(未达到数据大小也拉取)</li>
<li>每批次最大抓取大小默认为50m</li>
</ul>
</blockquote>
</li>
<li>
<p>成功回调将数据发给消费者,放在消息队列中;</p>
</li>
<li>
<p>消费者每次拉取500条数据进行处理(反序列化、拦截器、处理数据)</p>
</li>
</ol>
<h3 id="分区分配策略">分区分配策略</h3>
<p>​		Kafka有四种主流的分区分配策略: Range、RoundRobin、Sticky、CooperativeSticky。 可以通过配置参数partition.assignment.strategy，修改分区的分配策略。默认策略是<strong>Range+ CooperativeSticky</strong>。Kafka可以同时使用多个分区分配策略</p>
<h4 id="range策略">Range策略</h4>
<ul>
<li>原理</li>
</ul>
<p>Range 是对每个 topic 而言的。</p>
<ol>
<li>
<p>首先对同一个 topic 里面的分区按照序号进行排序，并对消费者按照字母顺序进行排序</p>
<blockquote>
<p>假如现在有 7 个分区，3 个消费者，排序后的分区将会是0,1,2,3,4,5,6;消费者排序完之后将会是C0,C1,C2</p>
</blockquote>
</li>
<li>
<p>通过 partitions数/consumer数 来决定每个消费者应该 消费几个分区。如果除不尽，那么前面几个消费者将会多 消费 1 个分区。</p>
<blockquote>
<p>例如，7/3 = 2 余 1 ，除不尽，那么 消费者 C0 便会多 消费 1 个分区。 8/3=2余2，除不尽，那么C0和C1分别多 消费一个。</p>
</blockquote>
</li>
</ol>
<p><strong>容易产生数据倾斜!</strong><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.28.34.png"
        data-srcset="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.28.34.png, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.28.34.png 1.5x, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.28.34.png 2x"
        data-sizes="auto"
        alt="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.28.34.png"
        title="截屏2022-09-05 下午3.28.34" /></p>
<ul>
<li>
<p>再分配</p>
<p>​		一个消费者挂掉后，消费者组需要按照超时时间 45s 来判断它是否退出，所以需要等待，时间到了 45s 后，判断它真的退出就会把任务分配给其他 broker 执行。</p>
<ol>
<li>消费者挂掉后其任务会整体被分配到 某一个消费者</li>
<li>再次重新发送消息, 挂掉的被踢出消费者组，然后重新按照 range 方式分配。</li>
</ol>
</li>
</ul>
<h4 id="roundrobin策略"><strong>RoundRobin</strong>策略</h4>
<ul>
<li>原理</li>
</ul>
<p>​			RoundRobin 轮询分区策略，是把所有的 partition 和所有的 consumer 都列出来，然后按照 hashcode 进行排序，最后 通过轮询算法来分配 partition 给到各个消费者。<img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.32.07.png"
        data-srcset="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.32.07.png, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.32.07.png 1.5x, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.32.07.png 2x"
        data-sizes="auto"
        alt="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.32.07.png"
        title="截屏2022-09-05 下午3.32.07" /></p>
<ul>
<li>再分区</li>
</ul>
<ol>
<li>消费者挂掉后其任务会按照 RoundRobin 的方式，把数据轮询分成多个分区数据，分别其他的消费者消费。</li>
<li>再次重新发送消息, 挂掉的被踢出消费者组，然后重新按照 range 方式分配。</li>
</ol>
<h4 id="sticky-策略"><strong>Sticky</strong> 策略</h4>
<p>​		粘性分区定义:可以理解为分配的结果带有“粘性的”。即在执行一次新的分配之前， 考虑上一次分配的结果，尽量少的调整分配的变动，可以节省大量的开销。</p>
<p>​		粘性分区是 Kafka 从 0.11.x 版本开始引入这种分配策略，首先会尽量均衡的放置分区 到消费者上面，在出现同一消费者组内消费者出现问题的时候，会尽量保持原有分配的分 区不变化。</p>
<ul>
<li>
<p>再平衡案例</p>
<ol>
<li>
<p>按照粘性规则，尽可能均衡的随机分成 多个分区数据，分别</p>
<p>由 剩余的消费者消费</p>
</li>
<li>
<p>再次重新发送消息, 挂掉的被踢出消费者组，然保持a步骤中的分区分配不变</p>
</li>
</ol>
</li>
</ul>
<h3 id="offset">Offset</h3>
<h4 id="查看消费者offset">查看消费者offset</h4>
<p>​		在配置文件 config/consumer.properties 中添加配置 exclude.internal.topics=false， 默认是 true，表示不能消费系统主题。为了查看该系统主题数据，所以该参数修改为 false</p>
<p>然后可以指定topic为__consumer_offsets进行查看</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="o">[</span>atguigu@hadoop102 kafka<span class="o">]</span>$ bin/kafka-console-consumer.sh --topic __consumer_offsets --bootstrap-server hadoop102:9092 -- consumer.config config/consumer.properties --formatter <span class="s2">&#34;kafka.coordinator.group.GroupMetadataManager\$OffsetsMessageForm atter&#34;</span> --from-beginning
</code></pre></td></tr></table>
</div>
</div><h4 id="自动提交">自动提交</h4>
<ul>
<li><strong>enable.auto.commit</strong>:是否开启自动提交offset功能，默认是true</li>
<li><strong>auto.commit.interval.ms</strong>:自动提交offset的时间间隔，默认是5s</li>
</ul>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.44.09.png"
        data-srcset="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.44.09.png, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.44.09.png 1.5x, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.44.09.png 2x"
        data-sizes="auto"
        alt="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.44.09.png"
        title="截屏2022-09-05 下午3.44.09" /></p>
<h4 id="手动提交">手动提交</h4>
<p>​		手动提交offset的方法有两种:分别是commitSync(同步提交)和commitAsync(异步提交)。两者的相 同点是，都会将本次提交的一批数据最高的偏移量提交;不同点是，同步提交阻塞当前线程，一直到提交成 功，并且会自动失败重试(由不可控因素导致，也会出现提交失败);而异步提交则没有失败重试机制，故有可能提交失败。</p>
<ul>
<li>commitSync(同步提交):必须等待offset提交完毕，再去消费下一批数据。</li>
<li>commitAsync(异步提交) :发送完提交offset请求后，就开始消费下一批数据了。</li>
</ul>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.46.47.png"
        data-srcset="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.46.47.png, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.46.47.png 1.5x, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.46.47.png 2x"
        data-sizes="auto"
        alt="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.46.47.png"
        title="截屏2022-09-05 下午3.46.47" /></p>
<h4 id="漏消费和重复消费"><strong>漏消费和重复消费</strong></h4>
<ul>
<li>**重复消费：**已经消费了数据，但是offset没提交。</li>
<li>**漏消费：**先提交offset后消费，有可能会造成数据的漏消费。</li>
</ul>
<ol>
<li>重复消费: 自动提交引起</li>
</ol>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.49.30.png"
        data-srcset="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.49.30.png, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.49.30.png 1.5x, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.49.30.png 2x"
        data-sizes="auto"
        alt="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.49.30.png"
        title="截屏2022-09-05 下午3.49.30" /></p>
<ol start="2">
<li>
<p>漏消费: 漏消费。设置offset为手动提交，当offset被提交时，数据还在内存中未落盘，此时刚好消费者线程被kill掉，那么offset已经提交，但是数据未处理，导致这部分内存中的数据丢失</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.51.15.png"
        data-srcset="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.51.15.png, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.51.15.png 1.5x, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.51.15.png 2x"
        data-sizes="auto"
        alt="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.51.15.png"
        title="截屏2022-09-05 下午3.51.15" /></p>
</li>
</ol>
<h3 id="消费者事务">消费者事务</h3>
<p>​			如果想完成Consumer端的精准一次性消费，那么需要Kafka消费端将消费过程和提交offset 过程做原子绑定。此时我们需要将Kafka的offset保存到支持事务的自定义介质(比如 MySQL)</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.52.12.png"
        data-srcset="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.52.12.png, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.52.12.png 1.5x, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.52.12.png 2x"
        data-sizes="auto"
        alt="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.52.12.png"
        title="截屏2022-09-05 下午3.52.12" /></p>
<h3 id="消费者如何提高吞吐量">消费者如何提高吞吐量</h3>
<ol>
<li>如果是Kafka消费能力不足，则可以考虑增加Topic的分区数，并且同时提升消费组的消费者 数量，消费者数 = 分区数。(两者缺一不可)</li>
<li>如果是下游的数据处理不及时:提高每批次拉取的数量。批次拉取数据过少(拉取数据/处理时间 &lt; 生产速度)， 使处理的数据小于生产的数据，也会造成数据积压。</li>
</ol>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.54.02.png"
        data-srcset="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.54.02.png, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.54.02.png 1.5x, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.54.02.png 2x"
        data-sizes="auto"
        alt="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.54.02.png"
        title="截屏2022-09-05 下午3.54.02" /></p>
<h2 id="kraft模式">Kraft模式</h2>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.55.24.png"
        data-srcset="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.55.24.png, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.55.24.png 1.5x, https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.55.24.png 2x"
        data-sizes="auto"
        alt="https://raw.githubusercontent.com/NoobMidC/pics/main/%E6%88%AA%E5%B1%8F2022-09-05%20%E4%B8%8B%E5%8D%883.55.24.png"
        title="截屏2022-09-05 下午3.55.24" /></p>
<p>​		左图为 Kafka 现有架构，元数据在 zookeeper 中，运行时动态选举 controller，由 controller 进行 Kafka 集群管理。右图为 kraft 模式架构(实验性)，不再依赖 zookeeper 集群， 而是用三台 controller 节点代替 zookeeper，元数据保存在 controller 中，由 controller 直接进 行 Kafka 集群管理。</p>
<p>优点:</p>
<ul>
<li>Kafka不再依赖外部框架，而是能够独立运行;</li>
<li>controller管理集群时，不再需要从zookeeper中先读取数据，集群性能上升;</li>
<li>由于不依赖zookeeper，集群扩展时不再受到zookeeper读写能力限制;</li>
<li>controller 不再动态选举，而是由配置文件规定。这样我们可以有针对性的加强</li>
<li>controller 节点的配置，而不是像以前一样对随机 controller 节点的高负载束手无策。</li>
</ul>
<h2 id="面试题">面试题</h2>
<h3 id="1-kafka-是什么主要应用场景有哪些">1. <strong>Kafka</strong> 是什么?主要应用场景有哪些?</h3>
<p>Kafka 是一个分布式流式处理平台。 流平台具有三个关键功能:</p>
<ol>
<li>消息队列:发布和订阅消息流，这个功能类似于消息队列，这也是 Kafka 也被归类为消息队列的原因。</li>
<li>容错的持久方式存储记录消息流:Kafka 会把消息持久化到磁盘，有效避免了消息丢失的风险。</li>
<li>流式处理平台:在消息发布的时候进行处理，Kafka 提供了一个完整的流式处理类库。</li>
</ol>
<p>Kafka 主要有两大应用场景:</p>
<ol>
<li>消息队列:建立实时流数据管道，以可靠地在系统或应用程序之间获取数据。</li>
<li>数据处理:构建实时的流数据处理程序来转换或处理数据流。</li>
</ol>
<h3 id="2-和其他消息队列相比kafka-的优势在哪里">2. 和其他消息队列相比，<strong>Kafka</strong> 的优势在哪里?</h3>
<ul>
<li>极致的性能:基于 Scala 和 Java 语言开发，设计中大量使用了批量处理和异步的思想，最高可以每秒处理千 万级别的消息。</li>
<li>生态系统兼容性无可匹敌:Kafka 与周边生态系统的兼容性是最好的没有之一，尤其在大数据和流计算领域。</li>
</ul>
<h3 id="3-kafka-的多副本机制了解吗">3. <strong>Kafka</strong> 的多副本机制了解吗?</h3>
<p>​		Kafka 为分区(Partition)引入了多副本(Replica)机制。分区(Partition)中的多个副本之间会有一个叫做 leader 的家伙，其他副本称为 follower。我们发送的消息会被发 送到 leader 副本，然后 follower 副本才能从 leader 副本中拉取消息进行同步。</p>
<p>​		生产者和消费者只与 leader 副本交互。你可以理解为其他副本只是 leader 副本的拷贝，它们的存在只是为了保证 消息存储的安全性。当 leader 副本发生故障时会从 follower 中选举出一个 leader,但是 follower 中如果有和 leader 同步程度达不到要求的参加不了 leader 的竞选。</p>
<p>​		优势:</p>
<ol>
<li>Kafka 通过给特定 Topic 指定多个 Partition,而各个 Partition 可以分布在不同的 Broker 上,这样便能提供比较 好的并发能力(负载均衡)。</li>
<li>Partition 可以指定对应的 Replica 数,这也极大地提高了消息存储的安全性,提高了容灾能力，不过也相应的增 加了所需要的存储空间。</li>
</ol>
<h3 id="4-zookeeper-在-kafka-中的作用知道吗">4. <strong>Zookeeper</strong> 在 <strong>Kafka</strong> 中的作用知道吗?</h3>
<ul>
<li>Broker 注册:在 Zookeeper 上会有一个专门用来进行 Broker 服务器列表记录的节点。每个 Broker 在启动 时，都会到 Zookeeper 上进行注册，即到/brokers/ids 下创建属于自己的节点。每个 Broker 就会将自己的 IP 地址和端口等信息记录到该节点中去</li>
<li>Topic 注册:在 Kafka 中，同一个 Topic 的消息会被分成多个分区并将其分布在多个 Broker 上，这些分区信 息及与 Broker 的对应关系也都是由 Zookeeper 在维护。比如我创建了一个名字为 my-topic 的主题并且它有 两个分区，对应到 zookeeper 中会创建这些文件夹:/brokers/topics/my- topic/Partitions/0、/brokers/topics/my - topic/Partitions/1</li>
<li>负载均衡:上面也说过了 Kafka 通过给特定 Topic 指定多个 Partition,而各个 Partition 可以分布在不同的 Broker 上,这样便能提供比较好的并发能力。对于同一个 Topic 的不同 Partition，Kafka 会尽力将这些 Partition 分布到不同的 Broker 服务器上。当生产者产生消息后也会尽量投递到不同 Broker 的 Partition 里 面。当 Consumer 消费的时候，Zookeeper 可以根据当前的 Partition 数量以及 Consumer 数量来实现动态 负载均衡。</li>
<li>总而言之, 协助集群管理; 保存了集群的broker元数据、topic元数据, 需要时controller从这里拿取;</li>
</ul>
<h3 id="5kafka-如何保证消息的消费顺序">5.<strong>Kafka</strong> 如何保证消息的消费顺序?</h3>
<p>​			每次添加消息到 Partition(分区)的时候都会采用尾加法; Kafka 只能为我们保证 Partition(分区)中的 消息有序。消息在被追加到 Partition(分区)的时候都会分配一个特定的偏移量;</p>
<p>​		Kafka 通过偏移量(offset)来保证消息在分区内的顺序性。所以，我们就有一种很简单的保证消 息消费顺序的方法:1 个 Topic 只对应一个 Partition。这样当然可以解决问题，但是破坏了 Kafka 的设计初 衷。 Kafka 中发送1 条消息的时候，可以指定 topic, partition, key,data(数据)4 个参数。如果你发送消息 的时候指定了 Partition 的话，所有消息都会被发送到指定的 Partition。并且，同一个 key 的消息可以保证只 发送到同一个 partition，这个我们可以采用表/对象的 id 来作为 key。</p>
<p>总结:</p>
<ol>
<li>1 个 Topic 只有一个 Partition。</li>
<li>发送消息的时候指定 key/Partition。</li>
</ol>
<h3 id="6-kafka-如何保证消息不丢失">6. <strong>Kafka</strong> 如何保证消息不丢失?</h3>
<ol>
<li>副本机制</li>
<li>生产者应答机制,设置为-1, 则需要所有ISR同步后返回确认信息; 失败则重试;</li>
</ol>
<h3 id="7-判断节点活着的条件">7. 判断节点活着的条件</h3>
<ol>
<li>节点必须可以维护和 ZooKeeper 的连接，Zookeeper 通过心跳机制检查每个节点的连接;</li>
<li>如果Follower长时间未向Leader发或同步数据，则该Follower将被踢出ISR。该时间阈值，默认30s。</li>
</ol>
<h3 id="8-kafka-consumer-是否可以消费指定分区消息吗">8. <strong>Kafka consumer</strong> 是否可以消费指定分区消息吗?</h3>
<p>​		Kafa consumer 消费消息时，<strong>向 broker 发出&quot;fetch&quot;请求去消费特定分区的消息</strong>，consumer 指定消息在日志中的 偏移量(offset)，就可以消费从这个位置开始的消息，customer 拥有了 offset 的控制权，可以向后回滚去重新 消费之前的消息</p>
<h3 id="9-kafka-高效文件存储设计特点是什么">9. <strong>Kafka</strong> 高效文件存储设计特点是什么?</h3>
<ul>
<li>Kafka 把 topic 中一个 parition 大文件分成多个小文件段，通过多个小文件段，就容易定期清除或删除已经消费完文件，减少磁盘占用。</li>
<li>通过索引信息可以快速定位 message 和确定 response 的最大大小。</li>
<li>通过 index 元数据全部映射到 memory，可以避免 segment file 的 IO 磁盘操作。</li>
<li>通过索引文件稀疏存储，可以大幅降低 index 文件元数据占用空间大小。</li>
</ul>
<h3 id="10-partition-的数据如何保存到硬盘">10. <strong>partition</strong> 的数据如何保存到硬盘?</h3>
<ul>
<li>
<p>topic 中的多个 partition 以文件夹的形式保存到 broker，每个分区序号从0 递增，且消息有序。 Partition 文件下有多个 segment(xxx.index，xxx.log)</p>
</li>
<li>
<p>segment 文件里的大小和配置文件大小一致可以根据要求修改，默认为1g。如果大小大于1g 时，会滚动一个新的 segment 并且以上一个 segment 最后一条消息的偏移量命名。</p>
</li>
</ul>
<h3 id="11-kafka-维护消费状态跟踪的方法有什么">11. <strong>kafka</strong> 维护消费状态跟踪的方法有什么?</h3>
<p>offset存储在broker的consumer_offset主题中</p>
<ol>
<li>手动提交offset; 有重复消费的问题</li>
<li>自动提交offset; 有漏消费的问题</li>
</ol>
<h3 id="12-kafka-为什么那么快">12. <strong>Kafka</strong> 为什么那么快**?**</h3>
<ol>
<li>
<p><strong>Kafka</strong>本身是分布式集群，可以采用分区技术，并行度高</p>
</li>
<li>
<p><strong>读数据采用稀疏索引，可以快速定位要消费的数据</strong></p>
</li>
<li>
<p><strong>顺序写磁盘</strong></p>
<p>​		Kafka的producer生产数据，要写入到log文件中，写的过程是一直追加到文件末端，为顺序写</p>
</li>
<li>
<p><strong>页缓存</strong> <strong>+</strong> <strong>零拷贝技术</strong></p>
<ul>
<li>
<p>零拷贝: Kafka的数据加工处理操作交由Kafka生产者和Kafka消费者处理。Kafka Broker应用层不关心存储的数据，所以就不用走应用层，传输效率高。</p>
</li>
<li>
<p><strong>PageCache</strong>页缓存: Kafka重度依赖底层操作系统提供的PageCache功能。当上层有写操作时，操作系统只是将数据写入 PageCache。当读操作发生时，先从PageCache中查找，如果找不到，再去磁盘中读取。实际上PageCache是把尽可能多的空闲内存 都当做了磁盘缓存来使用。</p>
</li>
</ul>
</li>
</ol>
<h3 id="13-kafka-的流处理是什么意思">13. <strong>Kafka</strong> 的流处理是什么意思?</h3>
<p>​		连续、实时、并发和以逐记录方式处理数据的类型，我们称之为 Kafka 流处理。</p></div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>Updated on 2022-08-28</span>
            </div></div>
        <div class="post-info-line">
            <div class="post-info-md"><span>
                            <a class="link-to-markdown" href="/kafka/index.md" target="_blank">Read Markdown</a>
                        </span></div>
            <div class="post-info-share">
                <span><a href="javascript:void(0);" title="Share on Twitter" data-sharer="twitter" data-url="https://noobmid.github.io/kafka/" data-title="Kafka"><i class="fab fa-twitter fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Facebook" data-sharer="facebook" data-url="https://noobmid.github.io/kafka/"><i class="fab fa-facebook-square fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Hacker News" data-sharer="hackernews" data-url="https://noobmid.github.io/kafka/" data-title="Kafka"><i class="fab fa-hacker-news fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Line" data-sharer="line" data-url="https://noobmid.github.io/kafka/" data-title="Kafka"><i data-svg-src="https://cdn.jsdelivr.net/npm/simple-icons@7.3.0/icons/line.svg" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on 微博" data-sharer="weibo" data-url="https://noobmid.github.io/kafka/" data-title="Kafka" data-ralateuid="xxxx"><i class="fab fa-weibo fa-fw" aria-hidden="true"></i></a></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">Back</a></span>&nbsp;|&nbsp;<span><a href="/">Home</a></span>
        </section>
    </div>

    <div class="post-nav"><a href="/elasticsearch/" class="prev" rel="prev" title="Elasticsearch"><i class="fas fa-angle-left fa-fw" aria-hidden="true"></i>Elasticsearch</a>
            <a href="/grpc/" class="next" rel="next" title="GRPC">GRPC<i class="fas fa-angle-right fa-fw" aria-hidden="true"></i></a></div>
</div>
<div id="comments"><div id="valine" class="comment"></div><noscript>
                Please enable JavaScript to view the comments powered by <a href="https://valine.js.org/">Valine</a>.
            </noscript></div></article></div>
            </main><footer class="footer">
        <div class="footer-container"><div class="footer-line">Powered by <a href="https://gohugo.io/" target="_blank" rel="noopener noreffer" title="Hugo 0.87.0">Hugo</a> | Theme - <a href="https://github.com/dillonzq/LoveIt" target="_blank" rel="noopener noreffer" title="LoveIt 0.2.11"><i class="far fa-kiss-wink-heart fa-fw" aria-hidden="true"></i> LoveIt</a>
                </div><div class="footer-line" itemscope itemtype="http://schema.org/CreativeWork"><i class="far fa-copyright fa-fw" aria-hidden="true"></i><span itemprop="copyrightYear">2022</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="https://github.com/noobmid" target="_blank">cx玄烨0</a></span>&nbsp;|&nbsp;<span class="license"><a rel="license external nofollow noopener noreffer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span></div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="Back to Top">
                <i class="fas fa-arrow-up fa-fw" aria-hidden="true"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="View Comments">
                <i class="fas fa-comment fa-fw" aria-hidden="true"></i>
            </a>
        </div><link rel="stylesheet" href="/lib/valine/valine.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/css/lightgallery-bundle.min.css"><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/valine@1.5.0/dist/Valine.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/autocomplete.js@0.38.1/dist/autocomplete.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/algoliasearch@4.13.1/dist/algoliasearch-lite.umd.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/lightgallery.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/plugins/thumbnail/lg-thumbnail.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lightgallery@2.5.0/plugins/zoom/lg-zoom.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/clipboard@2.0.11/dist/clipboard.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/sharer.js@0.5.1/sharer.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/typeit@8.6.0/dist/index.umd.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"Copy to clipboard","maxShownLines":50},"comment":{"valine":{"appId":"QGzwQXOqs5JOhN4RGPOkR2mR-MdYXbMMI","appKey":"WBmoGyJtbqUswvfLh6L8iEBr","avatar":"mp","el":"#valine","emojiCDN":"https://cdn.jsdelivr.net/npm/emoji-datasource-google@14.0.0/img/google/64/","emojiMaps":{"100":"1f4af.png","alien":"1f47d.png","anger":"1f4a2.png","angry":"1f620.png","anguished":"1f627.png","astonished":"1f632.png","black_heart":"1f5a4.png","blue_heart":"1f499.png","blush":"1f60a.png","bomb":"1f4a3.png","boom":"1f4a5.png","broken_heart":"1f494.png","brown_heart":"1f90e.png","clown_face":"1f921.png","cold_face":"1f976.png","cold_sweat":"1f630.png","confounded":"1f616.png","confused":"1f615.png","cry":"1f622.png","crying_cat_face":"1f63f.png","cupid":"1f498.png","dash":"1f4a8.png","disappointed":"1f61e.png","disappointed_relieved":"1f625.png","dizzy":"1f4ab.png","dizzy_face":"1f635.png","drooling_face":"1f924.png","exploding_head":"1f92f.png","expressionless":"1f611.png","face_vomiting":"1f92e.png","face_with_cowboy_hat":"1f920.png","face_with_hand_over_mouth":"1f92d.png","face_with_head_bandage":"1f915.png","face_with_monocle":"1f9d0.png","face_with_raised_eyebrow":"1f928.png","face_with_rolling_eyes":"1f644.png","face_with_symbols_on_mouth":"1f92c.png","face_with_thermometer":"1f912.png","fearful":"1f628.png","flushed":"1f633.png","frowning":"1f626.png","ghost":"1f47b.png","gift_heart":"1f49d.png","green_heart":"1f49a.png","grimacing":"1f62c.png","grin":"1f601.png","grinning":"1f600.png","hankey":"1f4a9.png","hear_no_evil":"1f649.png","heart":"2764-fe0f.png","heart_decoration":"1f49f.png","heart_eyes":"1f60d.png","heart_eyes_cat":"1f63b.png","heartbeat":"1f493.png","heartpulse":"1f497.png","heavy_heart_exclamation_mark_ornament":"2763-fe0f.png","hole":"1f573-fe0f.png","hot_face":"1f975.png","hugging_face":"1f917.png","hushed":"1f62f.png","imp":"1f47f.png","innocent":"1f607.png","japanese_goblin":"1f47a.png","japanese_ogre":"1f479.png","joy":"1f602.png","joy_cat":"1f639.png","kiss":"1f48b.png","kissing":"1f617.png","kissing_cat":"1f63d.png","kissing_closed_eyes":"1f61a.png","kissing_heart":"1f618.png","kissing_smiling_eyes":"1f619.png","laughing":"1f606.png","left_speech_bubble":"1f5e8-fe0f.png","love_letter":"1f48c.png","lying_face":"1f925.png","mask":"1f637.png","money_mouth_face":"1f911.png","nauseated_face":"1f922.png","nerd_face":"1f913.png","neutral_face":"1f610.png","no_mouth":"1f636.png","open_mouth":"1f62e.png","orange_heart":"1f9e1.png","partying_face":"1f973.png","pensive":"1f614.png","persevere":"1f623.png","pleading_face":"1f97a.png","pouting_cat":"1f63e.png","purple_heart":"1f49c.png","rage":"1f621.png","relaxed":"263a-fe0f.png","relieved":"1f60c.png","revolving_hearts":"1f49e.png","right_anger_bubble":"1f5ef-fe0f.png","robot_face":"1f916.png","rolling_on_the_floor_laughing":"1f923.png","scream":"1f631.png","scream_cat":"1f640.png","see_no_evil":"1f648.png","shushing_face":"1f92b.png","skull":"1f480.png","skull_and_crossbones":"2620-fe0f.png","sleeping":"1f634.png","sleepy":"1f62a.png","slightly_frowning_face":"1f641.png","slightly_smiling_face":"1f642.png","smile":"1f604.png","smile_cat":"1f638.png","smiley":"1f603.png","smiley_cat":"1f63a.png","smiling_face_with_3_hearts":"1f970.png","smiling_imp":"1f608.png","smirk":"1f60f.png","smirk_cat":"1f63c.png","sneezing_face":"1f927.png","sob":"1f62d.png","space_invader":"1f47e.png","sparkling_heart":"1f496.png","speak_no_evil":"1f64a.png","speech_balloon":"1f4ac.png","star-struck":"1f929.png","stuck_out_tongue":"1f61b.png","stuck_out_tongue_closed_eyes":"1f61d.png","stuck_out_tongue_winking_eye":"1f61c.png","sunglasses":"1f60e.png","sweat":"1f613.png","sweat_drops":"1f4a6.png","sweat_smile":"1f605.png","thinking_face":"1f914.png","thought_balloon":"1f4ad.png","tired_face":"1f62b.png","triumph":"1f624.png","two_hearts":"1f495.png","unamused":"1f612.png","upside_down_face":"1f643.png","weary":"1f629.png","white_frowning_face":"2639-fe0f.png","white_heart":"1f90d.png","wink":"1f609.png","woozy_face":"1f974.png","worried":"1f61f.png","yawning_face":"1f971.png","yellow_heart":"1f49b.png","yum":"1f60b.png","zany_face":"1f92a.png","zipper_mouth_face":"1f910.png","zzz":"1f4a4.png"},"enableQQ":false,"highlight":true,"lang":"en","pageSize":10,"placeholder":"Your comment ...","recordIP":true,"serverURLs":"https://leancloud.hugoloveit.com","visitor":true}},"data":{"id-1":"cx玄烨0's Blog","id-2":"cx玄烨0's Blog"},"lightgallery":true,"search":{"algoliaAppID":"PASDMWALPK","algoliaIndex":"index.zh-cn","algoliaSearchKey":"b42948e51daaa93df92381c8e2ac0f93","highlightTag":"em","maxResultLength":10,"noResultsFound":"No results found","snippetLength":30,"type":"algolia"},"typeit":{"cursorChar":"|","cursorSpeed":1000,"data":{"id-1":["id-1"],"id-2":["id-2"]},"duration":-1,"speed":100}};</script><script type="text/javascript" src="/js/theme.min.js"></script></body>
</html>
